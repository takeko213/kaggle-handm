{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60307b7f-182d-498c-b767-2e0ce727aabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from unittest import result\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from functools import reduce\n",
    "from cuml.experimental.preprocessing import MinMaxScaler\n",
    "from cuml.preprocessing import Normalizer\n",
    "import itertools\n",
    "\n",
    "import cudf\n",
    "import cuml\n",
    "\n",
    "import builtins\n",
    "import types\n",
    "\n",
    "def imports():\n",
    "    for name, val in globals().items():\n",
    "        # module imports\n",
    "        if isinstance(val, types.ModuleType):\n",
    "            yield name, val\n",
    "\n",
    "            # functions / callables\n",
    "        if hasattr(val, '__call__'):\n",
    "            yield name, val\n",
    "\n",
    "\n",
    "def noglobal(f):\n",
    "    '''\n",
    "    ref: https://gist.github.com/raven38/4e4c3c7a179283c441f575d6e375510c\n",
    "    '''\n",
    "    return types.FunctionType(f.__code__,\n",
    "                              dict(imports()),\n",
    "                              f.__name__,\n",
    "                              f.__defaults__,\n",
    "                              f.__closure__\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6cb03a4-079a-42ce-92b5-c0c07a832ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIR = 'dataset/'\n",
    "transactions = cudf.read_parquet(INPUT_DIR + 'transactions.parquet')\n",
    "customers = cudf.read_parquet(INPUT_DIR + 'customers.parquet')\n",
    "articles = cudf.read_parquet(INPUT_DIR + 'articles.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46492cb0-f4bb-403c-ac44-e9c047bfa151",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encode_column = ['FN', 'Active', 'fashion_news_frequency', 'club_member_status', 'postal_code']\n",
    "for c in label_encode_column:\n",
    "    customers[c] = customers[c].astype(str)\n",
    "    le = cuml.preprocessing.LabelEncoder()\n",
    "    customers[c] = le.fit_transform(customers[c].fillna(''))\n",
    "\n",
    "customers['age'] = customers['age'].fillna(int(customers['age'].mean()))\n",
    "\n",
    "#  null value\n",
    "# FN 895050\n",
    "# Active 907576\n",
    "select_column = ['customer_id','club_member_status','fashion_news_frequency','age','postal_code']\n",
    "customers = customers[select_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb7679ff-4987-430e-8311-5f2722ec0c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encode_column =  ['product_type_name', 'product_group_name', 'graphical_appearance_name',\n",
    "            'colour_group_name', 'perceived_colour_value_name', 'perceived_colour_master_name', 'department_name',\n",
    "            'index_name', 'index_group_name', 'section_name', 'garment_group_name']\n",
    "\n",
    "for c in label_encode_column:\n",
    "    articles[c] = articles[c].astype(str)\n",
    "    le = cuml.preprocessing.LabelEncoder()\n",
    "    articles[c] = le.fit_transform(articles[c].fillna(''))\n",
    "\n",
    "label_encode_column.insert(0, 'article_id')\n",
    "articles = articles[label_encode_column] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde62733-7276-4ab6-a1d9-4b07bee87c51",
   "metadata": {},
   "source": [
    "## generate candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba98c489-9c51-4db3-b811-3350bb9e56bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Recommend Most Often Previously Purchased Items\n",
    "def get_customer_frequent(history, n=12, timedelta=None):\n",
    "    if timedelta is not None:\n",
    "        st_date = history['t_dat'].max() - timedelta\n",
    "        history = history[history['t_dat']>=st_date].copy()\n",
    "        \n",
    "    tmp = history.groupby(['customer_id','article_id'])['t_dat'].agg('count').reset_index()\n",
    "    tmp.columns = ['customer_id','article_id','ct']\n",
    "    tmp = tmp.sort_values(['customer_id','ct'],ascending=False)\n",
    "    tmp = tmp.to_pandas().groupby('customer_id').head(n)[['customer_id', 'article_id']]\n",
    "    result = cudf.DataFrame.from_pandas(tmp)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89ed9b7a-87f8-4a6b-8fb2-2c0a91df13fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "@noglobal\n",
    "def get_popular_article(history, n=12, timedelta=None):\n",
    "    if timedelta is not None:\n",
    "        st_date = history['t_dat'].max() - timedelta\n",
    "        history = history[history['t_dat']>=st_date].copy()\n",
    "\n",
    "    total_agg = history.groupby('article_id')['t_dat'].count().reset_index()\n",
    "    total_agg = total_agg.rename(columns={'t_dat':'cnt'})\n",
    "    total_agg = total_agg.sort_values(['cnt'], ascending=False)\n",
    "    total_agg = total_agg.head(n)\n",
    "    result = list(total_agg['article_id'].values)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "af1b5730-b710-4a73-bd40-ec6c6e2f7666",
   "metadata": {},
   "outputs": [],
   "source": [
    "@noglobal\n",
    "def add_labels(recom_result, history):\n",
    "    \"\"\"レコメンドしたデータが学習期間で購入されたかどうかのフラグを付与する\n",
    "\n",
    "    Args:\n",
    "        recom_result (_type_): レコメンド結果\n",
    "        train_tran (_type_): 学習期間のトランザクションデータ\n",
    "\n",
    "    Returns:\n",
    "        _type_: 学習期間での購入フラグを付与したレコメンド結果\n",
    "    \"\"\"\n",
    "    history = history[['customer_id', 'article_id']].drop_duplicates()\n",
    "    history['buy'] = 1\n",
    "    recom_result = recom_result.merge(history, on=['customer_id', 'article_id'], how='left')\n",
    "    recom_result['buy'] = recom_result['buy'].fillna(0)\n",
    "    return recom_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "81418d80-42d8-4f67-897c-6f43b1e8d51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@noglobal\n",
    "# def get_reccomend(target_customer_id, history, Ns, first_week_sales_pred):\n",
    "def get_reccomend(target_customer_id, history, Ns, first_week_sales_pred):\n",
    "    n = 12\n",
    "    result = cudf.DataFrame()\n",
    "    \n",
    "\n",
    "    td = None\n",
    "#     result = result.append(get_customer_frequent(history, Ns['cf_a'], td), ignore_index=True)\n",
    "    result = result.append(get_customer_frequent(history, Ns['cf_a'], td))\n",
    "#     result = result.append(get_customer_type_frequent(history, Ns['ctf_a'], td))\n",
    "#     result = result.append(get_article_type_frequent(history, 'department_name', Ns['atfd_a'], td))\n",
    "#     result = result.append(get_article_type_frequent(history, 'perceived_colour_master_name', Ns['atfp_a'], td))\n",
    "\n",
    "    popular_article = get_popular_article(history, Ns['pa_a'], td)\n",
    "#     # customerとpopular articleの全組み合わせでdataframe作成\n",
    "    popular_article = pd.DataFrame(itertools.product(target_customer_id, popular_article), columns=['customer_id', 'article_id'])\n",
    "    popular_article['article_id'] = popular_article.article_id.astype('int32')\n",
    "    result = result.append(cudf.DataFrame.from_pandas(popular_article))\n",
    "#     popular_new_article = get_popular_new_article(first_week_sales_pred, n=48)\n",
    "#     popular_new_article = pd.DataFrame(itertools.product(target_customer_id, popular_new_article), columns=['customer_id', 'article_id'])\n",
    "#     result = result.append(popular_new_article)\n",
    "\n",
    "    result = result.drop_duplicates()\n",
    "\n",
    "#     td = relativedelta(weeks=1)\n",
    "    td = np.timedelta64(7, 'D')\n",
    "    result = result.append(get_customer_frequent(history, Ns['cf_w'], td))\n",
    "#     result = result.append(get_customer_type_frequent(history, Ns['ctf_w'], td))\n",
    "#     result = result.append(get_article_type_frequent(history, 'department_name', Ns['atfd_w'], td))\n",
    "#     result = result.append(get_article_type_frequent(history, 'perceived_colour_master_name', Ns['atfp_w'], td))\n",
    "    popular_article = get_popular_article(history, Ns['pa_w'], td)\n",
    "#     # customerとpopular articleの全組み合わせでdataframe作成\n",
    "    popular_article = pd.DataFrame(itertools.product(target_customer_id, popular_article), columns=['customer_id', 'article_id'])\n",
    "    popular_article['article_id'] = popular_article.article_id.astype('int32')\n",
    "    result = result.append(cudf.DataFrame.from_pandas(popular_article))\n",
    "    result = result.drop_duplicates()\n",
    "\n",
    "    td = np.timedelta64(30, 'D')\n",
    "    result = result.append(get_customer_frequent(history, Ns['cf_m'], td))\n",
    "#     result = result.append(get_customer_type_frequent(history, Ns['ctf_m'], td))\n",
    "#     result = result.append(get_article_type_frequent(history, 'department_name', Ns['atfd_m'], td))\n",
    "#     result = result.append(get_article_type_frequent(history, 'perceived_colour_master_name', Ns['atfp_m'], td))\n",
    "    popular_article = get_popular_article(history, Ns['pa_m'], td)\n",
    "    # customerとpopular articleの全組み合わせでdataframe作成\n",
    "    popular_article = pd.DataFrame(itertools.product(target_customer_id, popular_article), columns=['customer_id', 'article_id'])\n",
    "    popular_article['article_id'] = popular_article.article_id.astype('int32')\n",
    "    result = result.append(cudf.DataFrame.from_pandas(popular_article))\n",
    "    result = result.drop_duplicates()\n",
    "\n",
    "    td = np.timedelta64(365, 'D')\n",
    "    result = result.append(get_customer_frequent(history, Ns['cf_y'], td))\n",
    "#     result = result.append(get_customer_type_frequent(history, Ns['ctf_y'], td))\n",
    "#     result = result.append(get_article_type_frequent(history, 'department_name', Ns['atfd_y'], td))\n",
    "#     result = result.append(get_article_type_frequent(history, 'perceived_colour_master_name', Ns['atfp_y'], td))\n",
    "    popular_article = get_popular_article(history, Ns['pa_y'], td)\n",
    "    # customerとpopular articleの全組み合わせでdataframe作成\n",
    "    popular_article = pd.DataFrame(itertools.product(target_customer_id, popular_article), columns=['customer_id', 'article_id'])\n",
    "    popular_article['article_id'] = popular_article.article_id.astype('int32')\n",
    "    result = result.append(cudf.DataFrame.from_pandas(popular_article))\n",
    "    result = result.drop_duplicates()\n",
    "\n",
    "    result = result[result['customer_id'].isin(target_customer_id)].copy()\n",
    "\n",
    "#     purchased_together_pair = calc_pair(history)\n",
    "#     add_result = result.copy()\n",
    "#     add_result['article_id'] = add_result['article_id'].map(purchased_together_pair)\n",
    "#     result = result.append(add_result.dropna().drop_duplicates())\n",
    "#     result = result.drop_duplicates()\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3733bd78-f7d7-4621-8304-b587d1e4bb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "@noglobal\n",
    "def add_features(df, history,customers, articles , first_week_sales_pred=None, text_svd_df=None):\n",
    "    df = df.merge(customers, on=['customer_id'], how='left')\n",
    "    df = df.merge(articles, on=['article_id'], how='left')\n",
    "    # df = df.merge(make_article_tran_features(history), on=['article_id'], how='left')\n",
    "    # df = df.merge(make_customer_tran_features(history), on=['customer_id'], how='left')\n",
    "#     df = df.merge(make_article_tran_features(history), on=['article_id'], how='left')\n",
    "#     df = df.merge(make_customer_features(customers), on=['customer_id'], how='left')\n",
    "#     df = df.merge(make_customer_tran_features(history), on=['customer_id'], how='left')\n",
    "# #     df = df.merge(make_customer_article_features(df[['customer_id', 'article_id']], history), on=['article_id', 'customer_id'], how='left')\n",
    "#     df = df.merge(make_new_article_features(first_week_sales_pred), on=['article_id'], how='left')\n",
    "#     df = df.merge(text_svd_df, on=['article_id'], how='left')\n",
    "\n",
    "#     cols = ['product_type_name', 'product_group_name', 'graphical_appearance_name',\n",
    "#             'colour_group_name', 'perceived_colour_value_name', 'perceived_colour_master_name', 'department_name',\n",
    "#             'index_name', 'index_group_name', 'section_name', 'garment_group_name']\n",
    "\n",
    "#     for c in cols:\n",
    "#         df = add_same_article_type_rate(df, history, c)\n",
    "\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1e1ea172-654a-4b5b-8c9b-0f1aa23697e8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SEED' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [29]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mboosting\u001b[39m\u001b[38;5;124m\"\u001b[39m : \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgbdt\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0.01\u001b[39m,\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetric\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary_logloss\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpu\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m----> 7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mSEED\u001b[49m\n\u001b[1;32m      8\u001b[0m }\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SEED' is not defined"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"objective\": \"binary\",\n",
    "    \"boosting\" : \"gbdt\",\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"metric\": \"binary_logloss\",\n",
    "    'device':'gpu',\n",
    "    \"seed\": 42\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e699ad51-043d-43ea-852e-63a6c63519cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apk(y_true, y_pred, K=12):\n",
    "    assert(len(y_true) == len(y_pred))\n",
    "    apks = []\n",
    "    for idx in range(len(y_true)):\n",
    "        y_i_true = y_true[idx]\n",
    "        y_i_pred = y_pred[idx]\n",
    "\n",
    "        # 予測値の数と重複の確認\n",
    "        assert(len(y_i_pred) <= K)\n",
    "        assert(len(np.unique(y_i_pred)) == len(y_i_pred))\n",
    "\n",
    "        sum_precision = 0.0\n",
    "        num_hits = 0.0\n",
    "\n",
    "        for i, p in enumerate(y_i_pred):\n",
    "            if p in y_i_true:\n",
    "                num_hits += 1\n",
    "                precision = num_hits / (i+1)\n",
    "                sum_precision += precision\n",
    "        apk = sum_precision / min(len(y_i_true), K)\n",
    "        apks.append(apk)\n",
    "    return apks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c197fb12-ba97-4fdd-8127-460fc3d04640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 学習データの作成\n",
    "# # 1週ずつローリングして学習データを生成\n",
    "# train_start = np.datetime64('2020-09-09')\n",
    "# valid_start = np.datetime64('2020-09-16')\n",
    "# valid_end = np.datetime64('2020-09-22')\n",
    "\n",
    "\n",
    "# # hist_st = np.datetime64(train_start)\n",
    "# # target_st = np.datetime64(valid_start) \n",
    "# # ml_train = pd.DataFrame()\n",
    "\n",
    "# fi = pd.DataFrame()\n",
    "# # vl_pred = np.zeros(len(ml_valid))\n",
    "# scores = []\n",
    "\n",
    "# for i in range(N_ITER):\n",
    "#     print(i)\n",
    "#     history_tran = transactions[transactions['t_dat'] < train_start].copy()\n",
    "#     target_tran = transactions[(transactions['t_dat'] >= train_start) & (transactions['t_dat'] < valid_start)].copy()\n",
    "# #     first_week_sales_pred_tmp = first_week_sales_pred[(first_week_sales_pred['1st_week_sales_dat'] >= target_tran['t_dat'].min())&(first_week_sales_pred['1st_week_sales_dat'] <= target_tran['t_dat'].max())]\n",
    "#     target_id= target_tran['customer_id'].unique().to_pandas().tolist()\n",
    "#     print(f'train target_id count: {len(target_id)}')\n",
    "#     ########## todo\n",
    "#     first_week_sales_pred_tmp = None\n",
    "#     ##########\n",
    "#     recom = get_reccomend(target_id, history_tran, Ns, first_week_sales_pred_tmp)\n",
    "#     ml_train = add_labels(recom, target_tran)\n",
    "#     ml_train = add_features(ml_train, history_tran, customers, articles).fillna(0).to_pandas()\n",
    "\n",
    "# #     # 評価データの作成\n",
    "#     history_tran = transactions[transactions['t_dat'] < valid_start].copy()\n",
    "#     target_tran = transactions[(transactions['t_dat'] >= valid_start) & (transactions['t_dat'] <= valid_end)].copy()\n",
    "#     target_id = target_tran['customer_id'].unique().to_pandas().tolist()\n",
    "#     print(f'val target_id count: {len(target_id)}')\n",
    "# #     ########## todo\n",
    "# #     first_week_sales_pred=None\n",
    "# #     ########## \n",
    "#     recom = get_reccomend(target_id, history_tran, Ns, first_week_sales_pred_tmp)\n",
    "#     ml_valid = add_labels(recom, target_tran)\n",
    "#     ml_valid = add_features(ml_valid, history_tran, customers, articles).fillna(0).to_pandas()\n",
    "\n",
    "#     target = 'buy'\n",
    "#     not_use_cols = ['customer_id', 'article_id','t_dat', target]\n",
    "#     features = [c for c in ml_train.columns if c not in not_use_cols]\n",
    "    \n",
    "#     # 学習\n",
    "#     tr_x, tr_y = ml_train[features], ml_train[target]\n",
    "#     vl_x, vl_y = ml_valid[features], ml_valid[target]\n",
    "#     tr_data = lgb.Dataset(tr_x, label=tr_y)\n",
    "#     vl_data = lgb.Dataset(vl_x, label=vl_y)\n",
    "#     model = lgb.train(params, tr_data, valid_sets=[tr_data, vl_data],\n",
    "#                     num_boost_round=20000, callbacks=[early_stopping(100), log_evaluation(1000)])\n",
    "    \n",
    "#     # 特徴量重要度\n",
    "#     fi_tmp = pd.DataFrame()\n",
    "#     fi_tmp['iter'] = N_ITER\n",
    "#     fi_tmp['feature'] = model.feature_name()\n",
    "#     fi_tmp['importance'] = model.feature_importance(importance_type='gain')\n",
    "#     fi = fi.append(fi_tmp)\n",
    "\n",
    "# #     # cv\n",
    "#     vl_pred = model.predict(vl_x, num_iteration=model.best_iteration)\n",
    "# #     # 正解データ作成\n",
    "#     valid = transactions[(transactions['t_dat'] >= valid_start) & (transactions['t_dat'] <= valid_end)].copy()\n",
    "#     valid = valid[['customer_id', 'article_id']].drop_duplicates().to_pandas()\n",
    "#     valid = valid.groupby('customer_id')['article_id'].apply(list).reset_index()\n",
    "#     valid = valid.sort_values('customer_id').reset_index(drop=True)\n",
    "    \n",
    "#     # 2値分類の出力を元に12個選定\n",
    "#     valid_pred = ml_valid[['customer_id', 'article_id']].copy()\n",
    "#     valid_pred['prob'] = vl_pred\n",
    "#     valid_pred = valid_pred.sort_values(['customer_id', 'prob'], ascending=False)\n",
    "#     valid_pred = valid_pred.groupby('customer_id').head(12)\n",
    "#     valid_pred = valid_pred.groupby('customer_id')['article_id'].apply(list).reset_index()\n",
    "#     valid_pred = valid_pred.sort_values('customer_id').reset_index(drop=True)\n",
    "#     assert(valid['customer_id'].tolist() == valid_pred['customer_id'].tolist())\n",
    "#     # MAP@12\n",
    "#     score = np.mean(apk(valid['article_id'].tolist(), valid_pred['article_id'].tolist()))\n",
    "#     print('{:.5f}'.format(score))\n",
    "# #     print(f'{valid_start.strftime(\"%Y-%m-%d\")} - {valid_end.strftime(\"%Y-%m-%d\")} : ' + '{:.5f}'.format(score))\n",
    "#     scores.append(score)\n",
    "# ##################\n",
    "# #     ml_valid['pred'] = vl_pred\n",
    "# #     ml_valid.to_csv(OUTPUT_DIR + f'{exp_name}/{exp_name}_oof{i}.csv', index=False)\n",
    "\n",
    "# #     with open(OUTPUT_DIR + f'{exp_name}/model{i}.pickle', 'wb') as f:\n",
    "# #         pickle.dump(model, f)\n",
    "\n",
    "# #     train_start = train_start - relativedelta(days=7)\n",
    "# #     valid_start = valid_start - relativedelta(days=7)\n",
    "# #     valid_end = valid_end - relativedelta(days=7)\n",
    "#     break\n",
    "# # ml_train = ml_train.reset_index(drop=True)\n",
    "# # ml_train.to_csv(OUTPUT_DIR + f'{exp_name}/ml_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc7d334-f909-40a9-b2bc-c718c57533fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fi_n = fi['feature'].nunique()\n",
    "# order = list(fi.groupby(\"feature\").mean().sort_values(\"importance\", ascending=False).index)\n",
    "# plt.figure(figsize=(10, fi_n*0.2))\n",
    "# sns.barplot(x=\"importance\", y=\"feature\", data=fi, order=order)\n",
    "# plt.title(f\"LGBM importance\")\n",
    "# plt.tight_layout()\n",
    "# # plt.savefig(OUTPUT_DIR + f'{exp_name}/lgbm_importance.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "432c16da-9069-440e-a413-a4fb4b423433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# del history_tran, target_tran, target_id, recom\n",
    "# del ml_train, ml_valid, tr_x, tr_y, vl_x, vl_y, tr_data, vl_data, valid, valid_pred\n",
    "# import gc\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa5e373-c7ae-4f7e-a564-729cbbb2d2e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
