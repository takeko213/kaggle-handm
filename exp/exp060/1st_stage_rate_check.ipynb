{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# exp060_1st_stage_rate_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import gc\n",
    "import itertools\n",
    "import pickle\n",
    "import pathlib\n",
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "sys.path.append(os.getenv('UTILS_PATH'))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cudf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import line_notify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import builtins\n",
    "import types\n",
    "\n",
    "def imports():\n",
    "    for name, val in globals().items():\n",
    "        # module imports\n",
    "        if isinstance(val, types.ModuleType):\n",
    "            yield name, val\n",
    "\n",
    "            # functions / callables\n",
    "        if hasattr(val, '__call__'):\n",
    "            yield name, val\n",
    "\n",
    "\n",
    "def noglobal(f):\n",
    "    '''\n",
    "    ref: https://gist.github.com/raven38/4e4c3c7a179283c441f575d6e375510c\n",
    "    '''\n",
    "    return types.FunctionType(f.__code__,\n",
    "                              dict(imports()),\n",
    "                              f.__name__,\n",
    "                              f.__defaults__,\n",
    "                              f.__closure__\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "RUN_INF = True # 推論処理を行うか\n",
    "BATCH_SIZE = int(1e5)\n",
    "N_ITER = 20 # 学習データのローリング数\n",
    "RUN_US = True # アンダーサンプリング実施有無\n",
    "N_SEED = 10 # seed avgの回数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "INIT_N = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ns = {}\n",
    "Ns['cf_a'] = INIT_N\n",
    "Ns['ctf_a'] = INIT_N\n",
    "Ns['atfd_a'] = INIT_N\n",
    "Ns['atfp_a'] = INIT_N\n",
    "Ns['pa_a'] = INIT_N\n",
    "\n",
    "Ns['cf_w'] = INIT_N\n",
    "Ns['ctf_w'] = INIT_N\n",
    "Ns['atfd_w'] = INIT_N\n",
    "Ns['atfp_w'] = INIT_N\n",
    "Ns['pa_w'] = INIT_N\n",
    "\n",
    "Ns['cf_m'] = INIT_N\n",
    "Ns['ctf_m'] = INIT_N\n",
    "Ns['atfd_m'] = INIT_N\n",
    "Ns['atfp_m'] = INIT_N\n",
    "Ns['pa_m'] = INIT_N\n",
    "\n",
    "Ns['cf_y'] = INIT_N\n",
    "Ns['ctf_y'] = INIT_N\n",
    "Ns['atfd_y'] = INIT_N\n",
    "Ns['atfp_y'] = INIT_N\n",
    "Ns['pa_y'] = INIT_N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ディレクトリ設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIR = os.getenv('INPUT_DIR')\n",
    "OUTPUT_DIR = os.getenv('OUTPUT_DIR')\n",
    "#exp_name = os.path.dirname(__file__).split('/')[-1]\n",
    "#exp_name = 'exp060'\n",
    "#os.makedirs(OUTPUT_DIR + exp_name, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データ読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = pd.read_csv(INPUT_DIR + 'articles.csv', dtype='object')\n",
    "customers = pd.read_csv(INPUT_DIR + 'customers.csv')\n",
    "transactions = pd.read_csv(INPUT_DIR + 'transactions_train.csv', dtype={'article_id':'str'}, parse_dates=['t_dat'])\n",
    "sample = pd.read_csv(INPUT_DIR + 'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_week_sales_pred = pd.read_csv(OUTPUT_DIR + '1st_week_sales_pred_v004/result.csv', dtype={'article_id':'str'},  parse_dates=['1st_week_sales_dat'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_CUSTOMER = customers['customer_id'].unique().tolist()\n",
    "ALL_ARTICLE = articles['article_id'].unique().tolist()\n",
    "\n",
    "customer_ids = dict(list(enumerate(ALL_CUSTOMER)))\n",
    "article_ids = dict(list(enumerate(ALL_ARTICLE)))\n",
    "\n",
    "customer_map = {u: uidx for uidx, u in customer_ids.items()}\n",
    "article_map = {i: iidx for iidx, i in article_ids.items()}\n",
    "\n",
    "articles['article_id'] = articles['article_id'].map(article_map)\n",
    "customers['customer_id'] = customers['customer_id'].map(customer_map)\n",
    "transactions['article_id'] = transactions['article_id'].map(article_map)\n",
    "transactions['customer_id'] = transactions['customer_id'].map(customer_map)\n",
    "sample['customer_id'] = sample['customer_id'].map(customer_map)\n",
    "first_week_sales_pred['article_id'] = first_week_sales_pred['article_id'].map(article_map) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 名寄せ\n",
    "customers['fashion_news_frequency'] = customers['fashion_news_frequency'].str.replace('None','NONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers['age10'] = str((customers['age'] // 10) * 10)\n",
    "customers.loc[customers['age'].isnull(), 'age10'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_encoding\n",
    "le_cols = ['product_type_name', 'product_group_name', 'graphical_appearance_name',\n",
    "            'colour_group_name', 'perceived_colour_value_name', 'perceived_colour_master_name', 'department_name',\n",
    "            'index_name', 'section_name', 'garment_group_name']\n",
    "for c in le_cols:\n",
    "    le = LabelEncoder()\n",
    "    articles[c] = le.fit_transform(articles[c].fillna(''))\n",
    "\n",
    "\n",
    "le_cols = ['club_member_status', 'fashion_news_frequency', 'postal_code', 'age10']\n",
    "for c in le_cols:\n",
    "    le = LabelEncoder()\n",
    "    customers[c] = le.fit_transform(customers[c].fillna(''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_INDEX_GROUP_NAME = articles['index_group_name'].unique().tolist()\n",
    "index_group_name_ids = dict(list(enumerate(ALL_INDEX_GROUP_NAME)))\n",
    "index_group_name_map = {u: uidx for uidx, u in index_group_name_ids.items()}\n",
    "articles['index_group_name'] = articles['index_group_name'].map(index_group_name_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers['customer_type'] = customers['FN'].fillna(0).astype(int).astype(str) + \\\n",
    "                             customers['Active'].fillna(0).astype(int).astype(str) + \\\n",
    "                             customers['club_member_status'].fillna(0).astype(int).astype(str) + \\\n",
    "                             customers['fashion_news_frequency'].fillna(0).astype(int).astype(str) + \\\n",
    "                             customers['age10'].fillna(0).astype(int).astype(str)\n",
    "\n",
    "le = LabelEncoder()\n",
    "customers['customer_type'] = le.fit_transform(customers['customer_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transactionに紐づけ\n",
    "transactions = transactions.merge(customers, on='customer_id', how='left')\n",
    "transactions = transactions.merge(articles, on='article_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データセット作成（レコメンド→対象データセット作成→特徴量エンジニアリング）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "@noglobal\n",
    "def get_customer_frequent(history, n=12, timedelta=None):\n",
    "    \"\"\"顧客ごと商品の購入数をカウントし上位の商品を抽出\n",
    "\n",
    "    Args:\n",
    "        history (dataframe): 集計対象の実績データ\n",
    "        n (int): レコメンド対象とする数\n",
    "        timedelta (dateutil.relativedelta): 指定された場合、実績データの終端からtimedelta分のデータを取得する\n",
    "\n",
    "    Returns:\n",
    "        dataframe: 抽出結果\n",
    "    \"\"\"\n",
    "    if timedelta is not None:\n",
    "        st_date = history['t_dat'].max() - timedelta\n",
    "        history = history[history['t_dat']>=st_date].copy()\n",
    "        \n",
    "    customer_agg = history.groupby(['customer_id', 'article_id'])['t_dat'].count().reset_index()\n",
    "    customer_agg = customer_agg.rename(columns={'t_dat':'cnt'})\n",
    "    customer_agg = customer_agg.sort_values(['customer_id', 'cnt'], ascending=False)\n",
    "    result = customer_agg.groupby('customer_id').head(n)\n",
    "    return result[['customer_id', 'article_id']]\n",
    "\n",
    "@noglobal\n",
    "def get_popular_article(history, n=12, timedelta=None):\n",
    "    \"\"\"全体の購入数をカウントし上位の商品を抽出\n",
    "\n",
    "    Args:\n",
    "        history (dataframe): 集計対象の実績データ\n",
    "        n (int): レコメンド対象とする数\n",
    "        timedelta (dateutil.relativedelta): 指定された場合、実績データの終端からtimedelta分のデータを取得する\n",
    "\n",
    "    Returns:\n",
    "        list: 抽出結果\n",
    "    \"\"\"\n",
    "    # 全体の購入数量\n",
    "    if timedelta is not None:\n",
    "        st_date = history['t_dat'].max() - timedelta\n",
    "        history = history[history['t_dat']>=st_date].copy()\n",
    "\n",
    "    total_agg = history.groupby('article_id')['t_dat'].count().reset_index()\n",
    "    total_agg = total_agg.rename(columns={'t_dat':'cnt'})\n",
    "    total_agg = total_agg.sort_values(['cnt'], ascending=False)\n",
    "    total_agg = total_agg.head(n)\n",
    "    result = list(total_agg['article_id'].values)\n",
    "    return result\n",
    "\n",
    "@noglobal\n",
    "def get_customer_type_frequent(history, n=12, timedelta=None):\n",
    "    if timedelta is not None:\n",
    "        st_date = history['t_dat'].max() - timedelta\n",
    "        history = history[history['t_dat']>=st_date].copy()\n",
    "\n",
    "    result = history[['customer_id', 'customer_type']].drop_duplicates().copy()\n",
    "    agg = history.groupby(['customer_type', 'article_id'])['t_dat'].count().reset_index()\n",
    "    agg = agg.rename(columns={'t_dat':'cnt'})\n",
    "    agg = agg.sort_values(['customer_type', 'cnt'], ascending=False)\n",
    "    agg = agg.groupby('customer_type').head(n)\n",
    "    result = result.merge(agg[['customer_type', 'article_id']], on='customer_type', how='left')\n",
    "    return result[['customer_id', 'article_id']]\n",
    "\n",
    "@noglobal\n",
    "def get_article_type_frequent(history, col, n=12, timedelta=None):\n",
    "    if timedelta is not None:\n",
    "        st_date = history['t_dat'].max() - timedelta\n",
    "        history = history[history['t_dat']>=st_date].copy()\n",
    "\n",
    "    result = history.groupby(['customer_id', col])['t_dat'].count().reset_index()\n",
    "    result = result.rename(columns={'t_dat':'cnt'})\n",
    "    result = result.sort_values(['customer_id', 'cnt'], ascending=False)\n",
    "    result = result.groupby(['customer_id']).head(1)[['customer_id', col]]\n",
    "\n",
    "    agg = history.groupby([col, 'article_id'])['t_dat'].count().reset_index()\n",
    "    agg = agg.rename(columns={'t_dat':'cnt'})\n",
    "    agg = agg.sort_values([col, 'cnt'], ascending=False)\n",
    "    agg = agg.groupby(col).head(n)\n",
    "    result = result.merge(agg[[col, 'article_id']], on=col, how='left')\n",
    "    return result[['customer_id', 'article_id']]\n",
    "\n",
    "@noglobal\n",
    "def get_popular_new_article(first_week_sales_pred, n=12):\n",
    "    \"\"\"新商品の初週売り上げ予測が高い商品を抽出\n",
    "    \"\"\"\n",
    "    first_week_sales_pred = first_week_sales_pred.sort_values(['1st_week_sales_pred'], ascending=False)\n",
    "    first_week_sales_pred = first_week_sales_pred.head(n)\n",
    "    result = list(first_week_sales_pred['article_id'].values)\n",
    "    return result\n",
    "\n",
    "@noglobal\n",
    "def calc_pair(history):\n",
    "    df = history[['article_id', 't_dat', 'customer_id']].copy()\n",
    "    df = cudf.from_pandas(df)\n",
    "    df['t_dat'] = df['t_dat'].factorize()[0].astype('int16')\n",
    "    dt = df.groupby(['customer_id','t_dat'])['article_id'].agg(list).rename('pair').reset_index()\n",
    "    df = df[['customer_id', 't_dat', 'article_id']].merge(dt, on=['customer_id', 't_dat'], how='left')\n",
    "    del dt\n",
    "    gc.collect()\n",
    "\n",
    "    # Explode the rows vs list of articles\n",
    "    df = df[['article_id', 'pair']].explode(column='pair')\n",
    "    gc.collect()\n",
    "        \n",
    "    # Discard duplicates\n",
    "    df = df.loc[df['article_id']!=df['pair']].reset_index(drop=True)\n",
    "    gc.collect()\n",
    "\n",
    "    # Count how many times each pair combination happens\n",
    "    df = df.groupby(['article_id', 'pair']).size().rename('count').reset_index()\n",
    "    gc.collect()\n",
    "        \n",
    "    # Sort by frequency\n",
    "    df = df.sort_values(['article_id' ,'count'], ascending=False).reset_index(drop=True)\n",
    "    gc.collect()\n",
    "\n",
    "    # pick only top1 most frequent pair\n",
    "    df = df.groupby('article_id').nth(0).reset_index()\n",
    "    pair = dict(zip(df['article_id'].to_arrow().to_pylist(), df['pair'].to_arrow().to_pylist()))\n",
    "\n",
    "    return pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "@noglobal\n",
    "def add_labels(recom_result, history):\n",
    "    \"\"\"レコメンドしたデータが学習期間で購入されたかどうかのフラグを付与する\n",
    "\n",
    "    Args:\n",
    "        recom_result (_type_): レコメンド結果\n",
    "        train_tran (_type_): 学習期間のトランザクションデータ\n",
    "\n",
    "    Returns:\n",
    "        _type_: 学習期間での購入フラグを付与したレコメンド結果\n",
    "    \"\"\"\n",
    "    history = history[['customer_id', 'article_id']].drop_duplicates()\n",
    "    history['buy'] = 1\n",
    "    recom_result = recom_result.merge(history, on=['customer_id', 'article_id'], how='left')\n",
    "    recom_result['buy'] = recom_result['buy'].fillna(0)\n",
    "    return recom_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "@noglobal\n",
    "def calc_recall(result, target_tran, recom_id):\n",
    "    result = add_labels(result, target_tran)\n",
    "    best_recall = 0.0\n",
    "    best_n = 12\n",
    "    for i in range(12):\n",
    "        n = 12 - i\n",
    "        recall = result.groupby('customer_id').head(n)['buy'].mean()\n",
    "        if recall >= best_recall:\n",
    "            best_recall = recall\n",
    "            best_n = n\n",
    "    print(f'[{recom_id}]  best_n: {best_n} | best_recall:' + '{:.3f}'.format(best_recall*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習データの作成\n",
    "# 1週ずつローリングして学習データを生成\n",
    "train_start = '2020-09-09'\n",
    "valid_start = '2020-09-16'\n",
    "valid_end = '2020-09-22'\n",
    "\n",
    "hist_st = train_start\n",
    "target_st = valid_start\n",
    "\n",
    "history_tran = transactions[transactions['t_dat'] < hist_st].copy()\n",
    "target_tran = transactions[(transactions['t_dat'] >= hist_st) & (transactions['t_dat'] < target_st)].copy()\n",
    "first_week_sales_pred_tmp = first_week_sales_pred[(first_week_sales_pred['1st_week_sales_dat'] >= target_tran['t_dat'].min())&(first_week_sales_pred['1st_week_sales_dat'] <= target_tran['t_dat'].max())]\n",
    "target_id = target_tran['customer_id'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_customer_id = target_id\n",
    "history = history_tran\n",
    "first_week_sales_pred = first_week_sales_pred_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[cf_a]  best_n: 1 | best_recall:0.049\n",
      "[ctf_a]  best_n: 1 | best_recall:0.025\n",
      "[atfd_a]  best_n: 1 | best_recall:0.019\n",
      "[atfp_a]  best_n: 1 | best_recall:0.028\n",
      "[pa_a]  best_n: 1 | best_recall:0.515\n",
      "[cf_w]  best_n: 2 | best_recall:0.264\n",
      "[ctf_w]  best_n: 1 | best_recall:0.114\n",
      "[atfd_w]  best_n: 1 | best_recall:0.280\n",
      "[atfp_w]  best_n: 1 | best_recall:0.151\n",
      "[pa_w]  best_n: 2 | best_recall:0.634\n",
      "[cf_m]  best_n: 11 | best_recall:0.261\n",
      "[ctf_m]  best_n: 3 | best_recall:0.066\n",
      "[atfd_m]  best_n: 1 | best_recall:0.121\n",
      "[atfp_m]  best_n: 1 | best_recall:0.090\n",
      "[pa_m]  best_n: 1 | best_recall:0.691\n",
      "[cf_y]  best_n: 12 | best_recall:0.058\n",
      "[ctf_y]  best_n: 1 | best_recall:0.033\n",
      "[atfd_y]  best_n: 1 | best_recall:0.037\n",
      "[atfp_y]  best_n: 1 | best_recall:0.034\n",
      "[pa_y]  best_n: 1 | best_recall:0.515\n"
     ]
    }
   ],
   "source": [
    "td = None\n",
    "result = get_customer_frequent(history, Ns['cf_a'], td)\n",
    "calc_recall(result, target_tran, 'cf_a')\n",
    "result = get_customer_type_frequent(history, Ns['ctf_a'], td)\n",
    "calc_recall(result, target_tran, 'ctf_a')\n",
    "result = get_article_type_frequent(history, 'department_name', Ns['atfd_a'], td)\n",
    "calc_recall(result, target_tran, 'atfd_a')\n",
    "result = get_article_type_frequent(history, 'perceived_colour_master_name', Ns['atfp_a'], td)\n",
    "calc_recall(result, target_tran, 'atfp_a')\n",
    "popular_article = get_popular_article(history, Ns['pa_a'], td)\n",
    "# customerとpopular articleの全組み合わせでdataframe作成\n",
    "result = pd.DataFrame(itertools.product(target_customer_id, popular_article), columns=['customer_id', 'article_id'])\n",
    "calc_recall(result, target_tran, 'pa_a')\n",
    "\n",
    "td = relativedelta(weeks=1)\n",
    "result = result.append(get_customer_frequent(history, Ns['cf_w'], td))\n",
    "calc_recall(result, target_tran, 'cf_w')\n",
    "result = get_customer_type_frequent(history, Ns['ctf_w'], td)\n",
    "calc_recall(result, target_tran, 'ctf_w')\n",
    "result = get_article_type_frequent(history, 'department_name', Ns['atfd_w'], td)\n",
    "calc_recall(result, target_tran, 'atfd_w')\n",
    "result = get_article_type_frequent(history, 'perceived_colour_master_name', Ns['atfp_w'], td)\n",
    "calc_recall(result, target_tran, 'atfp_w')\n",
    "popular_article = get_popular_article(history, Ns['pa_w'], td)\n",
    "# customerとpopular articleの全組み合わせでdataframe作成\n",
    "result = pd.DataFrame(itertools.product(target_customer_id, popular_article), columns=['customer_id', 'article_id'])\n",
    "calc_recall(result, target_tran, 'pa_w')\n",
    "\n",
    "td = relativedelta(months=1)\n",
    "result = result.append(get_customer_frequent(history, Ns['cf_m'], td))\n",
    "calc_recall(result, target_tran, 'cf_m')\n",
    "result = get_customer_type_frequent(history, Ns['ctf_m'], td)\n",
    "calc_recall(result, target_tran, 'ctf_m')\n",
    "result = get_article_type_frequent(history, 'department_name', Ns['atfd_m'], td)\n",
    "calc_recall(result, target_tran, 'atfd_m')\n",
    "result = get_article_type_frequent(history, 'perceived_colour_master_name', Ns['atfp_m'], td)\n",
    "calc_recall(result, target_tran, 'atfp_m')\n",
    "popular_article = get_popular_article(history, Ns['pa_m'], td)\n",
    "# customerとpopular articleの全組み合わせでdataframe作成\n",
    "result = pd.DataFrame(itertools.product(target_customer_id, popular_article), columns=['customer_id', 'article_id'])\n",
    "calc_recall(result, target_tran, 'pa_m')\n",
    "\n",
    "td = relativedelta(years=1)\n",
    "result = result.append(get_customer_frequent(history, Ns['cf_y'], td))\n",
    "calc_recall(result, target_tran, 'cf_y')\n",
    "result = get_customer_type_frequent(history, Ns['ctf_y'], td)\n",
    "calc_recall(result, target_tran, 'ctf_y')\n",
    "result = get_article_type_frequent(history, 'department_name', Ns['atfd_y'], td)\n",
    "calc_recall(result, target_tran, 'atfd_y')\n",
    "result = get_article_type_frequent(history, 'perceived_colour_master_name', Ns['atfp_y'], td)\n",
    "calc_recall(result, target_tran, 'atfp_y')\n",
    "popular_article = get_popular_article(history, Ns['pa_y'], td)\n",
    "# customerとpopular articleの全組み合わせでdataframe作成\n",
    "result = pd.DataFrame(itertools.product(target_customer_id, popular_article), columns=['customer_id', 'article_id'])\n",
    "calc_recall(result, target_tran, 'pa_y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
