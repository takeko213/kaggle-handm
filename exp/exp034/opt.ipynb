{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# exp034"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import gc\n",
    "import itertools\n",
    "import pickle\n",
    "import pathlib\n",
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "sys.path.append(os.getenv('UTILS_PATH'))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import optuna\n",
    "\n",
    "import line_notify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import builtins\n",
    "import types\n",
    "\n",
    "def imports():\n",
    "    for name, val in globals().items():\n",
    "        # module imports\n",
    "        if isinstance(val, types.ModuleType):\n",
    "            yield name, val\n",
    "\n",
    "            # functions / callables\n",
    "        if hasattr(val, '__call__'):\n",
    "            yield name, val\n",
    "\n",
    "\n",
    "def noglobal(f):\n",
    "    '''\n",
    "    ref: https://gist.github.com/raven38/4e4c3c7a179283c441f575d6e375510c\n",
    "    '''\n",
    "    return types.FunctionType(f.__code__,\n",
    "                              dict(imports()),\n",
    "                              f.__name__,\n",
    "                              f.__defaults__,\n",
    "                              f.__closure__\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "N_ITER = 1\n",
    "RUN_INF = False # 推論処理を行うか\n",
    "BATCH_SIZE = int(5e5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ns = {}\n",
    "Ns['cf_a'] = 12\n",
    "Ns['ctf_a'] = 12\n",
    "Ns['atfd_a'] = 12\n",
    "Ns['atfp_a'] = 12\n",
    "Ns['pa_a'] = 12\n",
    "\n",
    "Ns['cf_w'] = 12\n",
    "Ns['ctf_w'] = 12\n",
    "Ns['atfd_w'] = 12\n",
    "Ns['atfp_w'] = 12\n",
    "Ns['pa_w'] = 12\n",
    "\n",
    "Ns['cf_m'] = 12\n",
    "Ns['ctf_m'] = 12\n",
    "Ns['atfd_m'] = 12\n",
    "Ns['atfp_m'] = 12\n",
    "Ns['pa_m'] = 12\n",
    "\n",
    "Ns['cf_y'] = 12\n",
    "Ns['ctf_y'] = 12\n",
    "Ns['atfd_y'] = 12\n",
    "Ns['atfp_y'] = 12\n",
    "Ns['pa_y'] = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = 0.0025\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ディレクトリ設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIR = os.getenv('INPUT_DIR')\n",
    "OUTPUT_DIR = os.getenv('OUTPUT_DIR')\n",
    "#exp_name = os.path.dirname(__file__).split('/')[-1]\n",
    "#exp_name = 'exp034'\n",
    "#os.makedirs(OUTPUT_DIR + exp_name, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データ読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = pd.read_csv(INPUT_DIR + 'articles.csv', dtype='object')\n",
    "customers = pd.read_csv(INPUT_DIR + 'customers.csv')\n",
    "transactions = pd.read_csv(INPUT_DIR + 'transactions_train.csv', dtype={'article_id':'str'}, parse_dates=['t_dat'])\n",
    "sample = pd.read_csv(INPUT_DIR + 'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_CUSTOMER = customers['customer_id'].unique().tolist()\n",
    "ALL_ARTICLE = articles['article_id'].unique().tolist()\n",
    "\n",
    "customer_ids = dict(list(enumerate(ALL_CUSTOMER)))\n",
    "article_ids = dict(list(enumerate(ALL_ARTICLE)))\n",
    "\n",
    "customer_map = {u: uidx for uidx, u in customer_ids.items()}\n",
    "article_map = {i: iidx for iidx, i in article_ids.items()}\n",
    "\n",
    "articles['article_id'] = articles['article_id'].map(article_map)\n",
    "customers['customer_id'] = customers['customer_id'].map(customer_map)\n",
    "transactions['article_id'] = transactions['article_id'].map(article_map)\n",
    "transactions['customer_id'] = transactions['customer_id'].map(customer_map)\n",
    "sample['customer_id'] = sample['customer_id'].map(customer_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 名寄せ\n",
    "customers['fashion_news_frequency'] = customers['fashion_news_frequency'].str.replace('None','NONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers['age10'] = str((customers['age'] // 10) * 10)\n",
    "customers.loc[customers['age'].isnull(), 'age10'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_encoding\n",
    "le_cols = ['product_type_name', 'product_group_name', 'graphical_appearance_name',\n",
    "            'colour_group_name', 'perceived_colour_value_name', 'perceived_colour_master_name', 'department_name',\n",
    "            'index_name', 'index_group_name', 'section_name', 'garment_group_name']\n",
    "for c in le_cols:\n",
    "    le = LabelEncoder()\n",
    "    articles[c] = le.fit_transform(articles[c].fillna(''))\n",
    "\n",
    "\n",
    "le_cols = ['club_member_status', 'fashion_news_frequency', 'postal_code', 'age10']\n",
    "for c in le_cols:\n",
    "    le = LabelEncoder()\n",
    "    customers[c] = le.fit_transform(customers[c].fillna(''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers['customer_type'] = customers['FN'].fillna(0).astype(int).astype(str) + \\\n",
    "                             customers['Active'].fillna(0).astype(int).astype(str) + \\\n",
    "                             customers['club_member_status'].fillna(0).astype(int).astype(str) + \\\n",
    "                             customers['fashion_news_frequency'].fillna(0).astype(int).astype(str) + \\\n",
    "                             customers['age10'].fillna(0).astype(int).astype(str)\n",
    "\n",
    "le = LabelEncoder()\n",
    "customers['customer_type'] = le.fit_transform(customers['customer_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transactionに紐づけ\n",
    "transactions = transactions.merge(customers, on='customer_id', how='left')\n",
    "transactions = transactions.merge(articles, on='article_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データセット作成（レコメンド→対象データセット作成→特徴量エンジニアリング）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "@noglobal\n",
    "def get_customer_frequent(history, n=12, timedelta=None):\n",
    "    \"\"\"顧客ごと商品の購入数をカウントし上位の商品を抽出\n",
    "\n",
    "    Args:\n",
    "        history (dataframe): 集計対象の実績データ\n",
    "        n (int): レコメンド対象とする数\n",
    "        timedelta (dateutil.relativedelta): 指定された場合、実績データの終端からtimedelta分のデータを取得する\n",
    "\n",
    "    Returns:\n",
    "        dataframe: 抽出結果\n",
    "    \"\"\"\n",
    "    if timedelta is not None:\n",
    "        st_date = history['t_dat'].max() - timedelta\n",
    "        history = history[history['t_dat']>=st_date].copy()\n",
    "        \n",
    "    customer_agg = history.groupby(['customer_id', 'article_id'])['t_dat'].count().reset_index()\n",
    "    customer_agg = customer_agg.rename(columns={'t_dat':'cnt'})\n",
    "    customer_agg = customer_agg.sort_values(['customer_id', 'cnt'], ascending=False)\n",
    "    result = customer_agg.groupby('customer_id').head(n)\n",
    "    return result[['customer_id', 'article_id']]\n",
    "\n",
    "@noglobal\n",
    "def get_popular_article(history, n=12, timedelta=None):\n",
    "    \"\"\"全体の購入数をカウントし上位の商品を抽出\n",
    "\n",
    "    Args:\n",
    "        history (dataframe): 集計対象の実績データ\n",
    "        n (int): レコメンド対象とする数\n",
    "        timedelta (dateutil.relativedelta): 指定された場合、実績データの終端からtimedelta分のデータを取得する\n",
    "\n",
    "    Returns:\n",
    "        list: 抽出結果\n",
    "    \"\"\"\n",
    "    # 全体の購入数量\n",
    "    if timedelta is not None:\n",
    "        st_date = history['t_dat'].max() - timedelta\n",
    "        history = history[history['t_dat']>=st_date].copy()\n",
    "\n",
    "    total_agg = history.groupby('article_id')['t_dat'].count().reset_index()\n",
    "    total_agg = total_agg.rename(columns={'t_dat':'cnt'})\n",
    "    total_agg = total_agg.sort_values(['cnt'], ascending=False)\n",
    "    total_agg = total_agg.head(n)\n",
    "    result = list(total_agg['article_id'].values)\n",
    "    return result\n",
    "\n",
    "@noglobal\n",
    "def get_customer_type_frequent(history, n=12, timedelta=None):\n",
    "    if timedelta is not None:\n",
    "        st_date = history['t_dat'].max() - timedelta\n",
    "        history = history[history['t_dat']>=st_date].copy()\n",
    "\n",
    "    result = history[['customer_id', 'customer_type']].drop_duplicates().copy()\n",
    "    agg = history.groupby(['customer_type', 'article_id'])['t_dat'].count().reset_index()\n",
    "    agg = agg.rename(columns={'t_dat':'cnt'})\n",
    "    agg = agg.sort_values(['customer_type', 'cnt'], ascending=False)\n",
    "    agg = agg.groupby('customer_type').head(n)\n",
    "    result = result.merge(agg[['customer_type', 'article_id']], on='customer_type', how='left')\n",
    "    return result[['customer_id', 'article_id']]\n",
    "\n",
    "@noglobal\n",
    "def get_article_type_frequent(history, col, n=12, timedelta=None):\n",
    "    if timedelta is not None:\n",
    "        st_date = history['t_dat'].max() - timedelta\n",
    "        history = history[history['t_dat']>=st_date].copy()\n",
    "\n",
    "    result = history.groupby(['customer_id', col])['t_dat'].count().reset_index()\n",
    "    result = result.rename(columns={'t_dat':'cnt'})\n",
    "    result = result.sort_values(['customer_id', 'cnt'], ascending=False)\n",
    "    result = result.groupby(['customer_id']).head(1)[['customer_id', col]]\n",
    "\n",
    "    agg = history.groupby([col, 'article_id'])['t_dat'].count().reset_index()\n",
    "    agg = agg.rename(columns={'t_dat':'cnt'})\n",
    "    agg = agg.sort_values([col, 'cnt'], ascending=False)\n",
    "    agg = agg.groupby(col).head(n)\n",
    "    result = result.merge(agg[[col, 'article_id']], on=col, how='left')\n",
    "    return result[['customer_id', 'article_id']]\n",
    "\n",
    "@noglobal\n",
    "def get_reccomend(target_customer_id, history, Ns):\n",
    "    result = pd.DataFrame()\n",
    "    \n",
    "    td = None\n",
    "    result = result.append(get_customer_frequent(history, Ns['cf_a'], td))\n",
    "    result = result.append(get_customer_type_frequent(history, Ns['ctf_a'], td))\n",
    "    result = result.append(get_article_type_frequent(history, 'department_name', Ns['atfd_a'], td))\n",
    "    result = result.append(get_article_type_frequent(history, 'perceived_colour_master_name', Ns['atfp_a'], td))\n",
    "    popular_article = get_popular_article(history, Ns['pa_a'], td)\n",
    "    # customerとpopular articleの全組み合わせでdataframe作成\n",
    "    popular_article = pd.DataFrame(itertools.product(target_customer_id, popular_article), columns=['customer_id', 'article_id'])\n",
    "    result = result.append(popular_article)\n",
    "    result = result.drop_duplicates()\n",
    "\n",
    "    td = relativedelta(weeks=1)\n",
    "    result = result.append(get_customer_frequent(history, Ns['cf_w'], td))\n",
    "    result = result.append(get_customer_type_frequent(history, Ns['ctf_w'], td))\n",
    "    result = result.append(get_article_type_frequent(history, 'department_name', Ns['atfd_w'], td))\n",
    "    result = result.append(get_article_type_frequent(history, 'perceived_colour_master_name', Ns['atfp_w'], td))\n",
    "    popular_article = get_popular_article(history, Ns['pa_w'], td)\n",
    "    # customerとpopular articleの全組み合わせでdataframe作成\n",
    "    popular_article = pd.DataFrame(itertools.product(target_customer_id, popular_article), columns=['customer_id', 'article_id'])\n",
    "    result = result.append(popular_article)\n",
    "    result = result.drop_duplicates()\n",
    "\n",
    "    td = relativedelta(months=1)\n",
    "    result = result.append(get_customer_frequent(history, Ns['cf_m'], td))\n",
    "    result = result.append(get_customer_type_frequent(history, Ns['ctf_m'], td))\n",
    "    result = result.append(get_article_type_frequent(history, 'department_name', Ns['atfd_m'], td))\n",
    "    result = result.append(get_article_type_frequent(history, 'perceived_colour_master_name', Ns['atfp_m'], td))\n",
    "    popular_article = get_popular_article(history, Ns['pa_m'], td)\n",
    "    # customerとpopular articleの全組み合わせでdataframe作成\n",
    "    popular_article = pd.DataFrame(itertools.product(target_customer_id, popular_article), columns=['customer_id', 'article_id'])\n",
    "    result = result.append(popular_article)\n",
    "    result = result.drop_duplicates()\n",
    "\n",
    "    td = relativedelta(years=1)\n",
    "    result = result.append(get_customer_frequent(history, Ns['cf_y'], td))\n",
    "    result = result.append(get_customer_type_frequent(history, Ns['ctf_y'], td))\n",
    "    result = result.append(get_article_type_frequent(history, 'department_name', Ns['atfd_y'], td))\n",
    "    result = result.append(get_article_type_frequent(history, 'perceived_colour_master_name', Ns['atfp_y'], td))\n",
    "    popular_article = get_popular_article(history, Ns['pa_y'], td)\n",
    "    # customerとpopular articleの全組み合わせでdataframe作成\n",
    "    popular_article = pd.DataFrame(itertools.product(target_customer_id, popular_article), columns=['customer_id', 'article_id'])\n",
    "    result = result.append(popular_article)\n",
    "    result = result.drop_duplicates()\n",
    "\n",
    "    result = result[result['customer_id'].isin(target_customer_id)].copy()\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "@noglobal\n",
    "def add_labels(recom_result, history):\n",
    "    \"\"\"レコメンドしたデータが学習期間で購入されたかどうかのフラグを付与する\n",
    "\n",
    "    Args:\n",
    "        recom_result (_type_): レコメンド結果\n",
    "        train_tran (_type_): 学習期間のトランザクションデータ\n",
    "\n",
    "    Returns:\n",
    "        _type_: 学習期間での購入フラグを付与したレコメンド結果\n",
    "    \"\"\"\n",
    "    history = history[['customer_id', 'article_id']].drop_duplicates()\n",
    "    history['buy'] = 1\n",
    "    recom_result = recom_result.merge(history, on=['customer_id', 'article_id'], how='left')\n",
    "    recom_result['buy'] = recom_result['buy'].fillna(0)\n",
    "    return recom_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "@noglobal\n",
    "def make_article_features(articles):\n",
    "    cols = ['product_type_name', 'product_group_name', 'graphical_appearance_name',\n",
    "            'colour_group_name', 'perceived_colour_value_name', 'perceived_colour_master_name', 'department_name',\n",
    "            'index_name', 'index_group_name', 'section_name', 'garment_group_name']\n",
    "    return articles[['article_id']+cols]\n",
    "\n",
    "@noglobal\n",
    "def make_article_tran_features(history):\n",
    "    df = history.groupby('article_id').agg({'t_dat':['count', 'max', 'min'],\n",
    "                                            'price':['max', 'min', 'mean'], \n",
    "                                            'age':['max', 'min', 'mean', 'std']}).reset_index()\n",
    "    df.columns = ['article_id','article_total_cnt', 'article_total_latest_buy', 'article_total_1st_buy', 'article_price_max', 'article_price_min', 'article_price_mean', 'article_age_max', 'article_age_min', 'article_age_mean', 'article_age_std']\n",
    "    df['article_total_1st_buy'] = (history['t_dat'].max() - df['article_total_1st_buy']).dt.days\n",
    "    df['article_total_latest_buy'] = (history['t_dat'].max() - df['article_total_latest_buy']).dt.days\n",
    "    return df\n",
    "\n",
    "\n",
    "@noglobal\n",
    "def make_customer_features(customers):\n",
    "    return customers\n",
    "\n",
    "@noglobal\n",
    "def make_customer_tran_features(history):\n",
    "    df = history.groupby('customer_id').agg({'t_dat':['count', 'max', 'min'],\n",
    "                                            'price':['max', 'min', 'mean']}).reset_index()\n",
    "    df.columns = ['customer_id','customer_total_cnt', 'customer_total_latest_buy', 'customer_total_1st_buy', 'customer_price_max', 'customer_price_min', 'customer_price_mean']\n",
    "    df['customer_total_1st_buy'] = (history['t_dat'].max() - df['customer_total_1st_buy']).dt.days\n",
    "    df['customer_total_latest_buy'] = (history['t_dat'].max() - df['customer_total_latest_buy']).dt.days\n",
    "    return df\n",
    "\n",
    "@noglobal\n",
    "def make_customer_article_features(target, history):\n",
    "    df = target.merge(history, on=['customer_id', 'article_id'], how='inner')\n",
    "    df = df.groupby(['customer_id', 'article_id']).agg({'t_dat':['count', 'min', 'max']}).reset_index()\n",
    "    df.columns = ['customer_id', 'article_id', 'count', '1st_buy_date_diff', 'latest_buy_date_diff']\n",
    "    df['1st_buy_date_diff'] = (history['t_dat'].max() - df['1st_buy_date_diff']).dt.days\n",
    "    df['latest_buy_date_diff'] = (history['t_dat'].max() - df['latest_buy_date_diff']).dt.days\n",
    "    return df\n",
    "\n",
    "@noglobal\n",
    "def add_same_article_type_rate(target, history, col):\n",
    "    add_data = history[['customer_id', col]].copy()\n",
    "    add_data['total'] = add_data.groupby('customer_id').transform('count')\n",
    "    add_data = add_data.groupby(['customer_id', col])['total'].agg(['max', 'count']).reset_index()\n",
    "    add_data[f'{col}_customer_buy_rate'] = add_data['count'] / add_data['max']\n",
    "    target = target.merge(add_data[['customer_id', col, f'{col}_customer_buy_rate']], on=['customer_id', col], how='left')\n",
    "    return target\n",
    "\n",
    "    \n",
    "\n",
    "@noglobal\n",
    "def add_features(df, history, articles, customers):\n",
    "    df = df.merge(make_article_features(articles), on=['article_id'], how='left')\n",
    "    df = df.merge(make_article_tran_features(history), on=['article_id'], how='left')\n",
    "    df = df.merge(make_customer_features(customers), on=['customer_id'], how='left')\n",
    "    df = df.merge(make_customer_tran_features(history), on=['customer_id'], how='left')\n",
    "    df = df.merge(make_customer_article_features(df[['customer_id', 'article_id']], history), on=['article_id', 'customer_id'], how='left')\n",
    "\n",
    "    cols = ['product_type_name', 'product_group_name', 'graphical_appearance_name',\n",
    "            'colour_group_name', 'perceived_colour_value_name', 'perceived_colour_master_name', 'department_name',\n",
    "            'index_name', 'index_group_name', 'section_name', 'garment_group_name']\n",
    "\n",
    "    for c in cols:\n",
    "        df = add_same_article_type_rate(df, history, c)\n",
    "\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# レコメンド商品を購入するかどうかの2値分類モデル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apk(y_true, y_pred, K=12):\n",
    "    assert(len(y_true) == len(y_pred))\n",
    "    apks = []\n",
    "    for idx in range(len(y_true)):\n",
    "        y_i_true = y_true[idx]\n",
    "        y_i_pred = y_pred[idx]\n",
    "\n",
    "        # 予測値の数と重複の確認\n",
    "        assert(len(y_i_pred) <= K)\n",
    "        assert(len(np.unique(y_i_pred)) == len(y_i_pred))\n",
    "\n",
    "        sum_precision = 0.0\n",
    "        num_hits = 0.0\n",
    "\n",
    "        for i, p in enumerate(y_i_pred):\n",
    "            if p in y_i_true:\n",
    "                num_hits += 1\n",
    "                precision = num_hits / (i+1)\n",
    "                sum_precision += precision\n",
    "        apk = sum_precision / min(len(y_i_true), K)\n",
    "        apks.append(apk)\n",
    "    return apks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "@noglobal\n",
    "def run_train(transactions, articles, customers, Ns):\n",
    "    # 1週ずつローリングして学習データを生成し検証\n",
    "    train_start = datetime.datetime(2020,9,9)\n",
    "    valid_start = datetime.datetime(2020,9,16)\n",
    "    valid_end = datetime.datetime(2020,9,22)\n",
    "\n",
    "    # 学習データの作成\n",
    "    history_tran = transactions[transactions['t_dat'] < train_start].copy()\n",
    "    target_tran = transactions[(transactions['t_dat'] >= train_start) & (transactions['t_dat'] < valid_start)].copy()\n",
    "    target_id = target_tran['customer_id'].unique().tolist()\n",
    "    recom = get_reccomend(target_id, history_tran, Ns)\n",
    "    ml_train = add_labels(recom, target_tran)\n",
    "    ml_train = add_features(ml_train, history_tran, articles, customers)\n",
    "\n",
    "    # 評価データの作成\n",
    "    history_tran = transactions[transactions['t_dat'] < valid_start].copy()\n",
    "    target_tran = transactions[(transactions['t_dat'] >= valid_start) & (transactions['t_dat'] <= valid_end)].copy()\n",
    "    target_id = target_tran['customer_id'].unique().tolist()\n",
    "    recom = get_reccomend(target_id, history_tran, Ns)\n",
    "    ml_valid = add_labels(recom, target_tran)\n",
    "    ml_valid = add_features(ml_valid, history_tran, articles, customers)\n",
    "\n",
    "    target = 'buy'\n",
    "    not_use_cols = ['customer_id', 'article_id', target]\n",
    "    features = [c for c in ml_train.columns if c not in not_use_cols]\n",
    "\n",
    "    params = {\n",
    "    \"objective\": \"binary\",\n",
    "    \"boosting\" : \"gbdt\",\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"metric\": \"binary_logloss\",\n",
    "    \"seed\": 42\n",
    "}\n",
    "\n",
    "    # 学習\n",
    "    tr_x, tr_y = ml_train[features], ml_train[target]\n",
    "    vl_x, vl_y = ml_valid[features], ml_valid[target]\n",
    "    tr_data = lgb.Dataset(tr_x, label=tr_y)\n",
    "    vl_data = lgb.Dataset(vl_x, label=vl_y)\n",
    "    model = lgb.train(params, tr_data, valid_sets=[tr_data, vl_data],\n",
    "                    num_boost_round=20000, early_stopping_rounds=100,verbose_eval=1000)\n",
    "\n",
    "    # cv\n",
    "    vl_pred = model.predict(vl_x, num_iteration=model.best_iteration)\n",
    "    # 正解データ作成\n",
    "    valid = transactions[(transactions['t_dat'] >= valid_start) & (transactions['t_dat'] <= valid_end)].copy()\n",
    "    valid = valid[['customer_id', 'article_id']].drop_duplicates()\n",
    "    valid = valid.groupby('customer_id')['article_id'].apply(list).reset_index()\n",
    "    valid = valid.sort_values('customer_id').reset_index(drop=True)\n",
    "    # 2値分類の出力を元に12個選定\n",
    "    valid_pred = ml_valid[['customer_id', 'article_id']].copy()\n",
    "    valid_pred['prob'] = vl_pred\n",
    "    valid_pred = valid_pred.sort_values(['customer_id', 'prob'], ascending=False)\n",
    "    valid_pred = valid_pred.groupby('customer_id').head(12)\n",
    "    valid_pred = valid_pred.groupby('customer_id')['article_id'].apply(list).reset_index()\n",
    "    valid_pred = valid_pred.sort_values('customer_id').reset_index(drop=True)\n",
    "    assert(valid['customer_id'].tolist() == valid_pred['customer_id'].tolist())\n",
    "    # MAP@12\n",
    "    score = np.mean(apk(valid['article_id'].tolist(), valid_pred['article_id'].tolist()))\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    cf_a = trial.suggest_int('cf_a', 0, 24)\n",
    "    ctf_a = trial.suggest_int('ctf_a', 0, 24)\n",
    "    atfd_a = trial.suggest_int('atfd_a', 0, 24)\n",
    "    atfp_a = trial.suggest_int('atfp_a', 0, 24)\n",
    "    pa_a = trial.suggest_int('pa_a', 0, 24)\n",
    "\n",
    "    cf_w = trial.suggest_int('cf_w', 0, 24)\n",
    "    ctf_w = trial.suggest_int('ctf_w', 0, 24)\n",
    "    atfd_w = trial.suggest_int('atfd_w', 0, 24)\n",
    "    atfp_w = trial.suggest_int('atfp_w', 0, 24)\n",
    "    pa_w = trial.suggest_int('pa_w', 0, 24)\n",
    "\n",
    "    cf_m = trial.suggest_int('cf_m', 0, 24)\n",
    "    ctf_m = trial.suggest_int('ctf_m', 0, 24)\n",
    "    atfd_m = trial.suggest_int('atfd_m', 0, 24)\n",
    "    atfp_m = trial.suggest_int('atfp_m', 0, 24)\n",
    "    pa_m = trial.suggest_int('pa_m', 0, 24)\n",
    "\n",
    "    cf_y = trial.suggest_int('cf_y', 0, 24)\n",
    "    ctf_y = trial.suggest_int('ctf_y', 0, 24)\n",
    "    atfd_y = trial.suggest_int('atfd_y', 0, 24)\n",
    "    atfp_y = trial.suggest_int('atfp_y', 0, 24)\n",
    "    pa_y = trial.suggest_int('pa_y', 0, 24)\n",
    "\n",
    "    Ns['cf_a'] = cf_a\n",
    "    Ns['ctf_a'] = ctf_a\n",
    "    Ns['atfd_a'] = atfd_a\n",
    "    Ns['atfp_a'] = atfp_a\n",
    "    Ns['pa_a'] = pa_a\n",
    "\n",
    "    Ns['cf_w'] = cf_w\n",
    "    Ns['ctf_w'] = ctf_w\n",
    "    Ns['atfd_w'] = atfd_w\n",
    "    Ns['atfp_w'] = atfp_w\n",
    "    Ns['pa_w'] = pa_w\n",
    "\n",
    "    Ns['cf_m'] = cf_m\n",
    "    Ns['ctf_m'] = ctf_m\n",
    "    Ns['atfd_m'] = atfd_m\n",
    "    Ns['atfp_m'] = atfp_m\n",
    "    Ns['pa_m'] = pa_m\n",
    "\n",
    "    Ns['cf_y'] = cf_y\n",
    "    Ns['ctf_y'] = ctf_y\n",
    "    Ns['atfd_y'] = atfd_y\n",
    "    Ns['atfp_y'] = atfp_y\n",
    "    Ns['pa_y'] = pa_y\n",
    "\n",
    "    total_n = ctf_a + pa_a + \\\n",
    "              ctf_w + pa_w + \\\n",
    "              ctf_m + pa_m + \\\n",
    "              ctf_y + pa_y\n",
    "\n",
    "    if total_n > 12:\n",
    "        score = run_train(transactions, articles, customers, Ns)\n",
    "    else:\n",
    "        score = 0.0\n",
    "    message = f'{Ns}\\n{score}'\n",
    "    line_notify.send(message)\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-05 23:35:34,571]\u001b[0m A new study created in memory with name: no-name-5711e405-32d4-4709-ad61-3f5670a29693\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 18494, number of negative: 6454551\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.746013 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7678\n",
      "[LightGBM] [Info] Number of data points in the train set: 6473045, number of used features: 49\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002857 -> initscore=-5.855094\n",
      "[LightGBM] [Info] Start training from score -5.855094\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[789]\ttraining's binary_logloss: 0.0156292\tvalid_1's binary_logloss: 0.0175252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-05 23:51:40,855]\u001b[0m Trial 0 finished with value: 0.030452073847616577 and parameters: {'cf_a': 12, 'ctf_a': 20, 'atfd_a': 6, 'atfp_a': 18, 'pa_a': 10, 'cf_w': 2, 'ctf_w': 14, 'atfd_w': 11, 'atfp_w': 6, 'pa_w': 15, 'cf_m': 14, 'ctf_m': 3, 'atfd_m': 17, 'atfp_m': 6, 'pa_m': 12, 'cf_y': 23, 'ctf_y': 8, 'atfd_y': 14, 'atfp_y': 9, 'pa_y': 21}. Best is trial 0 with value: 0.030452073847616577.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 17827, number of negative: 5737420\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.532854 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7649\n",
      "[LightGBM] [Info] Number of data points in the train set: 5755247, number of used features: 49\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.003098 -> initscore=-5.774051\n",
      "[LightGBM] [Info] Start training from score -5.774051\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.0164761\tvalid_1's binary_logloss: 0.0189033\n",
      "[2000]\ttraining's binary_logloss: 0.015446\tvalid_1's binary_logloss: 0.0188845\n",
      "Early stopping, best iteration is:\n",
      "[2069]\ttraining's binary_logloss: 0.0153834\tvalid_1's binary_logloss: 0.0188838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-06 00:06:22,870]\u001b[0m Trial 1 finished with value: 0.03088291661301478 and parameters: {'cf_a': 5, 'ctf_a': 3, 'atfd_a': 17, 'atfp_a': 6, 'pa_a': 11, 'cf_w': 15, 'ctf_w': 8, 'atfd_w': 14, 'atfp_w': 23, 'pa_w': 17, 'cf_m': 5, 'ctf_m': 1, 'atfd_m': 2, 'atfp_m': 4, 'pa_m': 14, 'cf_y': 23, 'ctf_y': 21, 'atfd_y': 8, 'atfp_y': 5, 'pa_y': 2}. Best is trial 1 with value: 0.03088291661301478.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 18525, number of negative: 6104509\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.753321 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7647\n",
      "[LightGBM] [Info] Number of data points in the train set: 6123034, number of used features: 49\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.003025 -> initscore=-5.797662\n",
      "[LightGBM] [Info] Start training from score -5.797662\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.0163202\tvalid_1's binary_logloss: 0.0186329\n",
      "[2000]\ttraining's binary_logloss: 0.0153456\tvalid_1's binary_logloss: 0.0186038\n",
      "Early stopping, best iteration is:\n",
      "[2552]\ttraining's binary_logloss: 0.0149001\tvalid_1's binary_logloss: 0.0185936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-06 00:24:13,099]\u001b[0m Trial 2 finished with value: 0.030664596025918128 and parameters: {'cf_a': 6, 'ctf_a': 21, 'atfd_a': 6, 'atfp_a': 13, 'pa_a': 5, 'cf_w': 15, 'ctf_w': 11, 'atfd_w': 5, 'atfp_w': 13, 'pa_w': 10, 'cf_m': 6, 'ctf_m': 20, 'atfd_m': 15, 'atfp_m': 18, 'pa_m': 19, 'cf_y': 23, 'ctf_y': 1, 'atfd_y': 3, 'atfp_y': 4, 'pa_y': 24}. Best is trial 1 with value: 0.03088291661301478.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 19015, number of negative: 6412356\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.483901 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7651\n",
      "[LightGBM] [Info] Number of data points in the train set: 6431371, number of used features: 49\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002957 -> initscore=-5.820754\n",
      "[LightGBM] [Info] Start training from score -5.820754\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.0159736\tvalid_1's binary_logloss: 0.0182275\n",
      "Early stopping, best iteration is:\n",
      "[1496]\ttraining's binary_logloss: 0.0154822\tvalid_1's binary_logloss: 0.0182149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-06 00:39:00,002]\u001b[0m Trial 3 finished with value: 0.030918865428753658 and parameters: {'cf_a': 5, 'ctf_a': 10, 'atfd_a': 11, 'atfp_a': 17, 'pa_a': 9, 'cf_w': 13, 'ctf_w': 7, 'atfd_w': 21, 'atfp_w': 2, 'pa_w': 17, 'cf_m': 10, 'ctf_m': 18, 'atfd_m': 6, 'atfp_m': 7, 'pa_m': 19, 'cf_y': 18, 'ctf_y': 2, 'atfd_y': 19, 'atfp_y': 0, 'pa_y': 9}. Best is trial 3 with value: 0.030918865428753658.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 19162, number of negative: 7092925\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.672711 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7646\n",
      "[LightGBM] [Info] Number of data points in the train set: 7112087, number of used features: 49\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002694 -> initscore=-5.913924\n",
      "[LightGBM] [Info] Start training from score -5.913924\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.0147255\tvalid_1's binary_logloss: 0.016405\n",
      "Early stopping, best iteration is:\n",
      "[1460]\ttraining's binary_logloss: 0.0143025\tvalid_1's binary_logloss: 0.016388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-06 00:55:48,419]\u001b[0m Trial 4 finished with value: 0.030731669139141115 and parameters: {'cf_a': 13, 'ctf_a': 24, 'atfd_a': 4, 'atfp_a': 8, 'pa_a': 14, 'cf_w': 9, 'ctf_w': 20, 'atfd_w': 21, 'atfp_w': 22, 'pa_w': 3, 'cf_m': 5, 'ctf_m': 1, 'atfd_m': 16, 'atfp_m': 12, 'pa_m': 20, 'cf_y': 11, 'ctf_y': 14, 'atfd_y': 23, 'atfp_y': 22, 'pa_y': 4}. Best is trial 3 with value: 0.030918865428753658.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 15720, number of negative: 5851020\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.462374 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7690\n",
      "[LightGBM] [Info] Number of data points in the train set: 5866740, number of used features: 49\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002680 -> initscore=-5.919437\n",
      "[LightGBM] [Info] Start training from score -5.919437\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[621]\ttraining's binary_logloss: 0.0143103\tvalid_1's binary_logloss: 0.016134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-06 01:08:43,893]\u001b[0m Trial 5 finished with value: 0.03044174796231609 and parameters: {'cf_a': 24, 'ctf_a': 16, 'atfd_a': 20, 'atfp_a': 12, 'pa_a': 10, 'cf_w': 14, 'ctf_w': 19, 'atfd_w': 0, 'atfp_w': 6, 'pa_w': 4, 'cf_m': 1, 'ctf_m': 22, 'atfd_m': 10, 'atfp_m': 1, 'pa_m': 9, 'cf_y': 12, 'ctf_y': 13, 'atfd_y': 13, 'atfp_y': 5, 'pa_y': 5}. Best is trial 3 with value: 0.030918865428753658.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 21156, number of negative: 7065685\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.487671 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7684\n",
      "[LightGBM] [Info] Number of data points in the train set: 7086841, number of used features: 49\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002985 -> initscore=-5.811082\n",
      "[LightGBM] [Info] Start training from score -5.811082\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.016509\tvalid_1's binary_logloss: 0.0186416\n",
      "[2000]\ttraining's binary_logloss: 0.0156195\tvalid_1's binary_logloss: 0.018622\n",
      "Early stopping, best iteration is:\n",
      "[2525]\ttraining's binary_logloss: 0.015228\tvalid_1's binary_logloss: 0.0186163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-06 01:26:42,892]\u001b[0m Trial 6 finished with value: 0.03092889964023639 and parameters: {'cf_a': 14, 'ctf_a': 17, 'atfd_a': 3, 'atfp_a': 19, 'pa_a': 18, 'cf_w': 16, 'ctf_w': 8, 'atfd_w': 19, 'atfp_w': 6, 'pa_w': 19, 'cf_m': 17, 'ctf_m': 19, 'atfd_m': 22, 'atfp_m': 19, 'pa_m': 21, 'cf_y': 24, 'ctf_y': 3, 'atfd_y': 5, 'atfp_y': 5, 'pa_y': 19}. Best is trial 6 with value: 0.03092889964023639.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 18852, number of negative: 6626692\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.650322 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7598\n",
      "[LightGBM] [Info] Number of data points in the train set: 6645544, number of used features: 49\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002837 -> initscore=-5.862242\n",
      "[LightGBM] [Info] Start training from score -5.862242\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.015434\tvalid_1's binary_logloss: 0.0177632\n",
      "Early stopping, best iteration is:\n",
      "[1226]\ttraining's binary_logloss: 0.0152112\tvalid_1's binary_logloss: 0.017758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-06 01:42:19,782]\u001b[0m Trial 7 finished with value: 0.030352707062643654 and parameters: {'cf_a': 8, 'ctf_a': 19, 'atfd_a': 11, 'atfp_a': 21, 'pa_a': 10, 'cf_w': 3, 'ctf_w': 7, 'atfd_w': 10, 'atfp_w': 9, 'pa_w': 17, 'cf_m': 13, 'ctf_m': 17, 'atfd_m': 4, 'atfp_m': 7, 'pa_m': 23, 'cf_y': 1, 'ctf_y': 23, 'atfd_y': 15, 'atfp_y': 20, 'pa_y': 2}. Best is trial 6 with value: 0.03092889964023639.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 16454, number of negative: 6716099\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.609625 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7676\n",
      "[LightGBM] [Info] Number of data points in the train set: 6732553, number of used features: 49\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002444 -> initscore=-6.011694\n",
      "[LightGBM] [Info] Start training from score -6.011694\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.0128511\tvalid_1's binary_logloss: 0.0145799\n",
      "[2000]\ttraining's binary_logloss: 0.0119388\tvalid_1's binary_logloss: 0.0145576\n",
      "Early stopping, best iteration is:\n",
      "[2893]\ttraining's binary_logloss: 0.0112869\tvalid_1's binary_logloss: 0.0145507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-06 02:03:12,352]\u001b[0m Trial 8 finished with value: 0.030688852165571018 and parameters: {'cf_a': 18, 'ctf_a': 19, 'atfd_a': 24, 'atfp_a': 7, 'pa_a': 13, 'cf_w': 14, 'ctf_w': 2, 'atfd_w': 7, 'atfp_w': 14, 'pa_w': 6, 'cf_m': 3, 'ctf_m': 11, 'atfd_m': 7, 'atfp_m': 1, 'pa_m': 4, 'cf_y': 22, 'ctf_y': 13, 'atfd_y': 18, 'atfp_y': 11, 'pa_y': 21}. Best is trial 6 with value: 0.03092889964023639.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 18805, number of negative: 7192411\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.674022 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7685\n",
      "[LightGBM] [Info] Number of data points in the train set: 7211216, number of used features: 49\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002608 -> initscore=-5.946659\n",
      "[LightGBM] [Info] Start training from score -5.946659\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[495]\ttraining's binary_logloss: 0.0146355\tvalid_1's binary_logloss: 0.0153137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-06 02:17:33,138]\u001b[0m Trial 9 finished with value: 0.030684287396694442 and parameters: {'cf_a': 19, 'ctf_a': 21, 'atfd_a': 13, 'atfp_a': 21, 'pa_a': 8, 'cf_w': 15, 'ctf_w': 15, 'atfd_w': 4, 'atfp_w': 6, 'pa_w': 2, 'cf_m': 14, 'ctf_m': 23, 'atfd_m': 13, 'atfp_m': 4, 'pa_m': 16, 'cf_y': 22, 'ctf_y': 16, 'atfd_y': 20, 'atfp_y': 16, 'pa_y': 4}. Best is trial 6 with value: 0.03092889964023639.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 20657, number of negative: 6490414\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.729122 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7663\n",
      "[LightGBM] [Info] Number of data points in the train set: 6511071, number of used features: 49\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.003173 -> initscore=-5.750027\n",
      "[LightGBM] [Info] Start training from score -5.750027\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.0174866\tvalid_1's binary_logloss: 0.0200918\n",
      "[2000]\ttraining's binary_logloss: 0.0165759\tvalid_1's binary_logloss: 0.0200824\n",
      "Early stopping, best iteration is:\n",
      "[1901]\ttraining's binary_logloss: 0.016655\tvalid_1's binary_logloss: 0.0200821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-06 02:34:31,488]\u001b[0m Trial 10 finished with value: 0.030855775996823393 and parameters: {'cf_a': 14, 'ctf_a': 11, 'atfd_a': 0, 'atfp_a': 1, 'pa_a': 22, 'cf_w': 23, 'ctf_w': 0, 'atfd_w': 16, 'atfp_w': 0, 'pa_w': 23, 'cf_m': 22, 'ctf_m': 12, 'atfd_m': 24, 'atfp_m': 24, 'pa_m': 24, 'cf_y': 6, 'ctf_y': 7, 'atfd_y': 0, 'atfp_y': 15, 'pa_y': 15}. Best is trial 6 with value: 0.03092889964023639.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 20704, number of negative: 6562399\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.501755 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7623\n",
      "[LightGBM] [Info] Number of data points in the train set: 6583103, number of used features: 49\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.003145 -> initscore=-5.758785\n",
      "[LightGBM] [Info] Start training from score -5.758785\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.0172884\tvalid_1's binary_logloss: 0.0197155\n",
      "Early stopping, best iteration is:\n",
      "[1020]\ttraining's binary_logloss: 0.0172675\tvalid_1's binary_logloss: 0.0197151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-06 02:47:59,952]\u001b[0m Trial 11 finished with value: 0.03055388858650307 and parameters: {'cf_a': 0, 'ctf_a': 10, 'atfd_a': 11, 'atfp_a': 16, 'pa_a': 19, 'cf_w': 21, 'ctf_w': 6, 'atfd_w': 24, 'atfp_w': 0, 'pa_w': 23, 'cf_m': 20, 'ctf_m': 16, 'atfd_m': 24, 'atfp_m': 13, 'pa_m': 19, 'cf_y': 17, 'ctf_y': 0, 'atfd_y': 8, 'atfp_y': 1, 'pa_y': 11}. Best is trial 6 with value: 0.03092889964023639.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 19326, number of negative: 6167678\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.743006 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7640\n",
      "[LightGBM] [Info] Number of data points in the train set: 6187004, number of used features: 49\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.003124 -> initscore=-5.765626\n",
      "[LightGBM] [Info] Start training from score -5.765626\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.0169345\tvalid_1's binary_logloss: 0.0194162\n",
      "Early stopping, best iteration is:\n",
      "[1682]\ttraining's binary_logloss: 0.0162545\tvalid_1's binary_logloss: 0.0194008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-06 03:08:17,821]\u001b[0m Trial 12 finished with value: 0.03086517507102227 and parameters: {'cf_a': 2, 'ctf_a': 7, 'atfd_a': 1, 'atfp_a': 24, 'pa_a': 17, 'cf_w': 9, 'ctf_w': 4, 'atfd_w': 19, 'atfp_w': 3, 'pa_w': 19, 'cf_m': 18, 'ctf_m': 17, 'atfd_m': 19, 'atfp_m': 20, 'pa_m': 0, 'cf_y': 17, 'ctf_y': 5, 'atfd_y': 8, 'atfp_y': 0, 'pa_y': 11}. Best is trial 6 with value: 0.03092889964023639.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 17300, number of negative: 5201827\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.475681 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7667\n",
      "[LightGBM] [Info] Number of data points in the train set: 5219127, number of used features: 49\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.003315 -> initscore=-5.706059\n",
      "[LightGBM] [Info] Start training from score -5.706059\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.0174127\tvalid_1's binary_logloss: 0.0203179\n",
      "[2000]\ttraining's binary_logloss: 0.0163491\tvalid_1's binary_logloss: 0.0202928\n",
      "Early stopping, best iteration is:\n",
      "[2108]\ttraining's binary_logloss: 0.016245\tvalid_1's binary_logloss: 0.0202912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-06 03:28:01,979]\u001b[0m Trial 13 finished with value: 0.03105930675658314 and parameters: {'cf_a': 9, 'ctf_a': 14, 'atfd_a': 8, 'atfp_a': 16, 'pa_a': 0, 'cf_w': 19, 'ctf_w': 9, 'atfd_w': 18, 'atfp_w': 10, 'pa_w': 13, 'cf_m': 9, 'ctf_m': 8, 'atfd_m': 8, 'atfp_m': 11, 'pa_m': 17, 'cf_y': 16, 'ctf_y': 4, 'atfd_y': 3, 'atfp_y': 8, 'pa_y': 15}. Best is trial 13 with value: 0.03105930675658314.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 16615, number of negative: 4918403\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.434675 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7661\n",
      "[LightGBM] [Info] Number of data points in the train set: 4935018, number of used features: 49\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.003367 -> initscore=-5.690433\n",
      "[LightGBM] [Info] Start training from score -5.690433\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.0175061\tvalid_1's binary_logloss: 0.0201136\n",
      "Early stopping, best iteration is:\n",
      "[1636]\ttraining's binary_logloss: 0.0167458\tvalid_1's binary_logloss: 0.0200923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-06 03:46:24,826]\u001b[0m Trial 14 finished with value: 0.030871956380870303 and parameters: {'cf_a': 10, 'ctf_a': 13, 'atfd_a': 7, 'atfp_a': 12, 'pa_a': 0, 'cf_w': 19, 'ctf_w': 11, 'atfd_w': 17, 'atfp_w': 17, 'pa_w': 10, 'cf_m': 9, 'ctf_m': 7, 'atfd_m': 9, 'atfp_m': 14, 'pa_m': 8, 'cf_y': 15, 'ctf_y': 9, 'atfd_y': 4, 'atfp_y': 9, 'pa_y': 16}. Best is trial 13 with value: 0.03105930675658314.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 18257, number of negative: 5748609\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.549849 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7679\n",
      "[LightGBM] [Info] Number of data points in the train set: 5766866, number of used features: 49\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.003166 -> initscore=-5.752165\n",
      "[LightGBM] [Info] Start training from score -5.752165\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.0169126\tvalid_1's binary_logloss: 0.0196224\n",
      "Early stopping, best iteration is:\n",
      "[1024]\ttraining's binary_logloss: 0.0168844\tvalid_1's binary_logloss: 0.0196212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-06 04:00:29,250]\u001b[0m Trial 15 finished with value: 0.030947477501238257 and parameters: {'cf_a': 17, 'ctf_a': 14, 'atfd_a': 3, 'atfp_a': 20, 'pa_a': 2, 'cf_w': 19, 'ctf_w': 16, 'atfd_w': 14, 'atfp_w': 9, 'pa_w': 13, 'cf_m': 17, 'ctf_m': 8, 'atfd_m': 21, 'atfp_m': 17, 'pa_m': 16, 'cf_y': 8, 'ctf_y': 4, 'atfd_y': 5, 'atfp_y': 7, 'pa_y': 16}. Best is trial 13 with value: 0.03105930675658314.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 16851, number of negative: 5448260\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.621593 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7686\n",
      "[LightGBM] [Info] Number of data points in the train set: 5465111, number of used features: 49\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.003083 -> initscore=-5.778642\n",
      "[LightGBM] [Info] Start training from score -5.778642\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[860]\ttraining's binary_logloss: 0.0162626\tvalid_1's binary_logloss: 0.0189722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-06 04:21:03,822]\u001b[0m Trial 16 finished with value: 0.030790251266374677 and parameters: {'cf_a': 19, 'ctf_a': 15, 'atfd_a': 8, 'atfp_a': 24, 'pa_a': 0, 'cf_w': 24, 'ctf_w': 24, 'atfd_w': 13, 'atfp_w': 11, 'pa_w': 12, 'cf_m': 24, 'ctf_m': 7, 'atfd_m': 0, 'atfp_m': 10, 'pa_m': 16, 'cf_y': 7, 'ctf_y': 5, 'atfd_y': 0, 'atfp_y': 8, 'pa_y': 15}. Best is trial 13 with value: 0.03105930675658314.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 17591, number of negative: 6088724\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.585606 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7687\n",
      "[LightGBM] [Info] Number of data points in the train set: 6106315, number of used features: 49\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002881 -> initscore=-5.846806\n",
      "[LightGBM] [Info] Start training from score -5.846806\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.0152766\tvalid_1's binary_logloss: 0.0177272\n",
      "Early stopping, best iteration is:\n",
      "[1791]\ttraining's binary_logloss: 0.0144702\tvalid_1's binary_logloss: 0.017709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-06 04:37:37,355]\u001b[0m Trial 17 finished with value: 0.031030497303215533 and parameters: {'cf_a': 23, 'ctf_a': 2, 'atfd_a': 14, 'atfp_a': 14, 'pa_a': 4, 'cf_w': 19, 'ctf_w': 18, 'atfd_w': 15, 'atfp_w': 17, 'pa_w': 8, 'cf_m': 17, 'ctf_m': 8, 'atfd_m': 12, 'atfp_m': 17, 'pa_m': 11, 'cf_y': 9, 'ctf_y': 9, 'atfd_y': 11, 'atfp_y': 14, 'pa_y': 8}. Best is trial 13 with value: 0.03105930675658314.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 17575, number of negative: 6235909\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.444508 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7676\n",
      "[LightGBM] [Info] Number of data points in the train set: 6253484, number of used features: 49\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002810 -> initscore=-5.871602\n",
      "[LightGBM] [Info] Start training from score -5.871602\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.014954\tvalid_1's binary_logloss: 0.01731\n",
      "[2000]\ttraining's binary_logloss: 0.0140048\tvalid_1's binary_logloss: 0.0172827\n",
      "Early stopping, best iteration is:\n",
      "[2277]\ttraining's binary_logloss: 0.0137784\tvalid_1's binary_logloss: 0.0172809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-06 04:53:50,514]\u001b[0m Trial 18 finished with value: 0.031072679108807847 and parameters: {'cf_a': 23, 'ctf_a': 1, 'atfd_a': 15, 'atfp_a': 14, 'pa_a': 5, 'cf_w': 10, 'ctf_w': 19, 'atfd_w': 23, 'atfp_w': 19, 'pa_w': 7, 'cf_m': 9, 'ctf_m': 9, 'atfd_m': 12, 'atfp_m': 23, 'pa_m': 10, 'cf_y': 1, 'ctf_y': 10, 'atfd_y': 10, 'atfp_y': 14, 'pa_y': 8}. Best is trial 18 with value: 0.031072679108807847.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 17272, number of negative: 5913319\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.730513 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7644\n",
      "[LightGBM] [Info] Number of data points in the train set: 5930591, number of used features: 49\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002912 -> initscore=-5.835876\n",
      "[LightGBM] [Info] Start training from score -5.835876\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.0155321\tvalid_1's binary_logloss: 0.0180296\n",
      "[2000]\ttraining's binary_logloss: 0.0145418\tvalid_1's binary_logloss: 0.0180073\n",
      "Early stopping, best iteration is:\n",
      "[2074]\ttraining's binary_logloss: 0.0144739\tvalid_1's binary_logloss: 0.0180067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-06 05:10:45,237]\u001b[0m Trial 19 finished with value: 0.030781340199113154 and parameters: {'cf_a': 9, 'ctf_a': 5, 'atfd_a': 16, 'atfp_a': 10, 'pa_a': 6, 'cf_w': 9, 'ctf_w': 23, 'atfd_w': 24, 'atfp_w': 19, 'pa_w': 7, 'cf_m': 9, 'ctf_m': 14, 'atfd_m': 10, 'atfp_m': 24, 'pa_m': 6, 'cf_y': 2, 'ctf_y': 18, 'atfd_y': 10, 'atfp_y': 18, 'pa_y': 7}. Best is trial 18 with value: 0.031072679108807847.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 16931, number of negative: 6199667\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.510926 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7669\n",
      "[LightGBM] [Info] Number of data points in the train set: 6216598, number of used features: 49\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002724 -> initscore=-5.903105\n",
      "[LightGBM] [Info] Start training from score -5.903105\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[759]\ttraining's binary_logloss: 0.0146615\tvalid_1's binary_logloss: 0.0163656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-06 05:23:30,526]\u001b[0m Trial 20 finished with value: 0.030684366536082638 and parameters: {'cf_a': 22, 'ctf_a': 8, 'atfd_a': 19, 'atfp_a': 15, 'pa_a': 2, 'cf_w': 5, 'ctf_w': 13, 'atfd_w': 21, 'atfp_w': 16, 'pa_w': 10, 'cf_m': 11, 'ctf_m': 4, 'atfd_m': 7, 'atfp_m': 10, 'pa_m': 3, 'cf_y': 5, 'ctf_y': 11, 'atfd_y': 16, 'atfp_y': 12, 'pa_y': 13}. Best is trial 18 with value: 0.031072679108807847.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 17631, number of negative: 6302981\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.643405 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7671\n",
      "[LightGBM] [Info] Number of data points in the train set: 6320612, number of used features: 49\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002789 -> initscore=-5.879119\n",
      "[LightGBM] [Info] Start training from score -5.879119\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.0148562\tvalid_1's binary_logloss: 0.0172237\n",
      "Early stopping, best iteration is:\n",
      "[1633]\ttraining's binary_logloss: 0.0142274\tvalid_1's binary_logloss: 0.0172159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-06 05:39:52,927]\u001b[0m Trial 21 finished with value: 0.030953151558952875 and parameters: {'cf_a': 24, 'ctf_a': 1, 'atfd_a': 14, 'atfp_a': 14, 'pa_a': 4, 'cf_w': 19, 'ctf_w': 20, 'atfd_w': 18, 'atfp_w': 20, 'pa_w': 7, 'cf_m': 7, 'ctf_m': 10, 'atfd_m': 13, 'atfp_m': 21, 'pa_m': 11, 'cf_y': 11, 'ctf_y': 10, 'atfd_y': 11, 'atfp_y': 13, 'pa_y': 8}. Best is trial 18 with value: 0.031072679108807847.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 16104, number of negative: 5200727\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.495625 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7704\n",
      "[LightGBM] [Info] Number of data points in the train set: 5216831, number of used features: 49\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.003087 -> initscore=-5.777486\n",
      "[LightGBM] [Info] Start training from score -5.777486\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.0159369\tvalid_1's binary_logloss: 0.018775\n",
      "[2000]\ttraining's binary_logloss: 0.0148583\tvalid_1's binary_logloss: 0.0187623\n",
      "Early stopping, best iteration is:\n",
      "[2059]\ttraining's binary_logloss: 0.014799\tvalid_1's binary_logloss: 0.0187614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-06 05:58:48,806]\u001b[0m Trial 22 finished with value: 0.030962863262539702 and parameters: {'cf_a': 21, 'ctf_a': 0, 'atfd_a': 9, 'atfp_a': 10, 'pa_a': 3, 'cf_w': 11, 'ctf_w': 17, 'atfd_w': 16, 'atfp_w': 17, 'pa_w': 5, 'cf_m': 15, 'ctf_m': 9, 'atfd_m': 11, 'atfp_m': 15, 'pa_m': 10, 'cf_y': 3, 'ctf_y': 7, 'atfd_y': 10, 'atfp_y': 14, 'pa_y': 0}. Best is trial 18 with value: 0.031072679108807847.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 17869, number of negative: 6171783\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.660932 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7673\n",
      "[LightGBM] [Info] Number of data points in the train set: 6189652, number of used features: 49\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002887 -> initscore=-5.844676\n",
      "[LightGBM] [Info] Start training from score -5.844676\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.0154379\tvalid_1's binary_logloss: 0.016764\n",
      "[2000]\ttraining's binary_logloss: 0.0144743\tvalid_1's binary_logloss: 0.0167407\n",
      "Early stopping, best iteration is:\n",
      "[2592]\ttraining's binary_logloss: 0.0140062\tvalid_1's binary_logloss: 0.0167337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-06 06:23:01,446]\u001b[0m Trial 23 finished with value: 0.030505435489408064 and parameters: {'cf_a': 21, 'ctf_a': 3, 'atfd_a': 15, 'atfp_a': 16, 'pa_a': 6, 'cf_w': 6, 'ctf_w': 17, 'atfd_w': 22, 'atfp_w': 20, 'pa_w': 0, 'cf_m': 12, 'ctf_m': 5, 'atfd_m': 13, 'atfp_m': 22, 'pa_m': 14, 'cf_y': 0, 'ctf_y': 6, 'atfd_y': 7, 'atfp_y': 17, 'pa_y': 9}. Best is trial 18 with value: 0.031072679108807847.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 16965, number of negative: 5638894\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.254529 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7681\n",
      "[LightGBM] [Info] Number of data points in the train set: 5655859, number of used features: 49\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.003000 -> initscore=-5.806291\n",
      "[LightGBM] [Info] Start training from score -5.806291\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.0157205\tvalid_1's binary_logloss: 0.0181586\n",
      "[2000]\ttraining's binary_logloss: 0.0146577\tvalid_1's binary_logloss: 0.0181317\n",
      "Early stopping, best iteration is:\n",
      "[2209]\ttraining's binary_logloss: 0.0144714\tvalid_1's binary_logloss: 0.0181302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-06 06:38:10,264]\u001b[0m Trial 24 finished with value: 0.0309984125711945 and parameters: {'cf_a': 16, 'ctf_a': 4, 'atfd_a': 18, 'atfp_a': 3, 'pa_a': 7, 'cf_w': 17, 'ctf_w': 21, 'atfd_w': 19, 'atfp_w': 15, 'pa_w': 8, 'cf_m': 8, 'ctf_m': 14, 'atfd_m': 8, 'atfp_m': 16, 'pa_m': 7, 'cf_y': 14, 'ctf_y': 11, 'atfd_y': 12, 'atfp_y': 10, 'pa_y': 13}. Best is trial 18 with value: 0.031072679108807847.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 15882, number of negative: 5085215\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.424810 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7686\n",
      "[LightGBM] [Info] Number of data points in the train set: 5101097, number of used features: 49\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.003113 -> initscore=-5.768906\n",
      "[LightGBM] [Info] Start training from score -5.768906\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.0160505\tvalid_1's binary_logloss: 0.0186982\n",
      "[2000]\ttraining's binary_logloss: 0.0149715\tvalid_1's binary_logloss: 0.0186757\n",
      "Early stopping, best iteration is:\n",
      "[1961]\ttraining's binary_logloss: 0.0150098\tvalid_1's binary_logloss: 0.0186752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-06 06:57:32,623]\u001b[0m Trial 25 finished with value: 0.0310817736793081 and parameters: {'cf_a': 22, 'ctf_a': 7, 'atfd_a': 9, 'atfp_a': 10, 'pa_a': 0, 'cf_w': 11, 'ctf_w': 10, 'atfd_w': 9, 'atfp_w': 12, 'pa_w': 9, 'cf_m': 11, 'ctf_m': 6, 'atfd_m': 5, 'atfp_m': 11, 'pa_m': 12, 'cf_y': 9, 'ctf_y': 16, 'atfd_y': 2, 'atfp_y': 19, 'pa_y': 6}. Best is trial 25 with value: 0.0310817736793081.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 16415, number of negative: 5252382\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.542386 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7670\n",
      "[LightGBM] [Info] Number of data points in the train set: 5268797, number of used features: 49\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.003116 -> initscore=-5.768241\n",
      "[LightGBM] [Info] Start training from score -5.768241\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.0163489\tvalid_1's binary_logloss: 0.0191343\n",
      "Early stopping, best iteration is:\n",
      "[1670]\ttraining's binary_logloss: 0.0155899\tvalid_1's binary_logloss: 0.0191198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-06 07:17:41,315]\u001b[0m Trial 26 finished with value: 0.0309485941465493 and parameters: {'cf_a': 20, 'ctf_a': 6, 'atfd_a': 9, 'atfp_a': 4, 'pa_a': 0, 'cf_w': 11, 'ctf_w': 11, 'atfd_w': 8, 'atfp_w': 10, 'pa_w': 14, 'cf_m': 3, 'ctf_m': 5, 'atfd_m': 4, 'atfp_m': 10, 'pa_m': 14, 'cf_y': 4, 'ctf_y': 18, 'atfd_y': 2, 'atfp_y': 23, 'pa_y': 6}. Best is trial 25 with value: 0.0310817736793081.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 17402, number of negative: 6157703\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.560774 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7668\n",
      "[LightGBM] [Info] Number of data points in the train set: 6175105, number of used features: 49\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002818 -> initscore=-5.868874\n",
      "[LightGBM] [Info] Start training from score -5.868874\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[678]\ttraining's binary_logloss: 0.0153075\tvalid_1's binary_logloss: 0.0174608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-06 07:31:13,545]\u001b[0m Trial 27 finished with value: 0.030784283501174993 and parameters: {'cf_a': 11, 'ctf_a': 8, 'atfd_a': 22, 'atfp_a': 10, 'pa_a': 2, 'cf_w': 7, 'ctf_w': 9, 'atfd_w': 9, 'atfp_w': 12, 'pa_w': 11, 'cf_m': 12, 'ctf_m': 13, 'atfd_m': 4, 'atfp_m': 9, 'pa_m': 17, 'cf_y': 20, 'ctf_y': 16, 'atfd_y': 2, 'atfp_y': 19, 'pa_y': 11}. Best is trial 25 with value: 0.0310817736793081.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 18186, number of negative: 6227461\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.497673 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7657\n",
      "[LightGBM] [Info] Number of data points in the train set: 6245647, number of used features: 49\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002912 -> initscore=-5.836072\n",
      "[LightGBM] [Info] Start training from score -5.836072\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.0156303\tvalid_1's binary_logloss: 0.0180415\n",
      "Early stopping, best iteration is:\n",
      "[981]\ttraining's binary_logloss: 0.0156408\tvalid_1's binary_logloss: 0.0180072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-06 07:44:23,493]\u001b[0m Trial 28 finished with value: 0.0309925886790288 and parameters: {'cf_a': 15, 'ctf_a': 12, 'atfd_a': 12, 'atfp_a': 10, 'pa_a': 1, 'cf_w': 12, 'ctf_w': 4, 'atfd_w': 12, 'atfp_w': 24, 'pa_w': 15, 'cf_m': 10, 'ctf_m': 6, 'atfd_m': 5, 'atfp_m': 13, 'pa_m': 13, 'cf_y': 14, 'ctf_y': 19, 'atfd_y': 6, 'atfp_y': 22, 'pa_y': 19}. Best is trial 25 with value: 0.0310817736793081.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 14868, number of negative: 4665401\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.453834 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7653\n",
      "[LightGBM] [Info] Number of data points in the train set: 4680269, number of used features: 49\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.003177 -> initscore=-5.748718\n",
      "[LightGBM] [Info] Start training from score -5.748718\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.0165388\tvalid_1's binary_logloss: 0.0191214\n",
      "Early stopping, best iteration is:\n",
      "[1655]\ttraining's binary_logloss: 0.0157701\tvalid_1's binary_logloss: 0.0191069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-06 07:57:25,414]\u001b[0m Trial 29 finished with value: 0.03002079221659077 and parameters: {'cf_a': 8, 'ctf_a': 0, 'atfd_a': 5, 'atfp_a': 17, 'pa_a': 4, 'cf_w': 1, 'ctf_w': 13, 'atfd_w': 11, 'atfp_w': 9, 'pa_w': 9, 'cf_m': 7, 'ctf_m': 3, 'atfd_m': 2, 'atfp_m': 8, 'pa_m': 12, 'cf_y': 9, 'ctf_y': 15, 'atfd_y': 1, 'atfp_y': 20, 'pa_y': 18}. Best is trial 25 with value: 0.0310817736793081.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 17710, number of negative: 5619610\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.492065 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7678\n",
      "[LightGBM] [Info] Number of data points in the train set: 5637320, number of used features: 49\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.003142 -> initscore=-5.759888\n",
      "[LightGBM] [Info] Start training from score -5.759888\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.0166408\tvalid_1's binary_logloss: 0.0189154\n",
      "Early stopping, best iteration is:\n",
      "[1894]\ttraining's binary_logloss: 0.0157088\tvalid_1's binary_logloss: 0.0189009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-06 08:11:55,905]\u001b[0m Trial 30 finished with value: 0.031112422090567846 and parameters: {'cf_a': 12, 'ctf_a': 9, 'atfd_a': 8, 'atfp_a': 12, 'pa_a': 2, 'cf_w': 8, 'ctf_w': 15, 'atfd_w': 23, 'atfp_w': 13, 'pa_w': 14, 'cf_m': 15, 'ctf_m': 10, 'atfd_m': 15, 'atfp_m': 4, 'pa_m': 5, 'cf_y': 20, 'ctf_y': 21, 'atfd_y': 4, 'atfp_y': 12, 'pa_y': 13}. Best is trial 30 with value: 0.031112422090567846.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 17565, number of negative: 5573959\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.769120 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7671\n",
      "[LightGBM] [Info] Number of data points in the train set: 5591524, number of used features: 49\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.003141 -> initscore=-5.759953\n",
      "[LightGBM] [Info] Start training from score -5.759953\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.0166276\tvalid_1's binary_logloss: 0.0189513\n",
      "[2000]\ttraining's binary_logloss: 0.0156231\tvalid_1's binary_logloss: 0.0189265\n",
      "[3000]\ttraining's binary_logloss: 0.0147952\tvalid_1's binary_logloss: 0.0188966\n",
      "Early stopping, best iteration is:\n",
      "[3114]\ttraining's binary_logloss: 0.0147039\tvalid_1's binary_logloss: 0.018896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-06 08:30:58,784]\u001b[0m Trial 31 finished with value: 0.03143208627505985 and parameters: {'cf_a': 12, 'ctf_a': 9, 'atfd_a': 8, 'atfp_a': 12, 'pa_a': 2, 'cf_w': 8, 'ctf_w': 14, 'atfd_w': 23, 'atfp_w': 12, 'pa_w': 12, 'cf_m': 15, 'ctf_m': 10, 'atfd_m': 15, 'atfp_m': 11, 'pa_m': 5, 'cf_y': 19, 'ctf_y': 22, 'atfd_y': 3, 'atfp_y': 11, 'pa_y': 13}. Best is trial 31 with value: 0.03143208627505985.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 18123, number of negative: 5888080\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.650747 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7671\n",
      "[LightGBM] [Info] Number of data points in the train set: 5906203, number of used features: 49\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.003068 -> initscore=-5.783503\n",
      "[LightGBM] [Info] Start training from score -5.783503\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.0163766\tvalid_1's binary_logloss: 0.0185467\n",
      "[2000]\ttraining's binary_logloss: 0.0154\tvalid_1's binary_logloss: 0.0185154\n",
      "Early stopping, best iteration is:\n",
      "[2363]\ttraining's binary_logloss: 0.0150847\tvalid_1's binary_logloss: 0.0185093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-06 08:48:35,923]\u001b[0m Trial 32 finished with value: 0.03128298089039722 and parameters: {'cf_a': 12, 'ctf_a': 8, 'atfd_a': 9, 'atfp_a': 12, 'pa_a': 3, 'cf_w': 4, 'ctf_w': 14, 'atfd_w': 23, 'atfp_w': 13, 'pa_w': 15, 'cf_m': 14, 'ctf_m': 10, 'atfd_m': 18, 'atfp_m': 4, 'pa_m': 5, 'cf_y': 18, 'ctf_y': 24, 'atfd_y': 4, 'atfp_y': 12, 'pa_y': 13}. Best is trial 31 with value: 0.03143208627505985.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 18231, number of negative: 5842328\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.480859 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7680\n",
      "[LightGBM] [Info] Number of data points in the train set: 5860559, number of used features: 49\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.003111 -> initscore=-5.769761\n",
      "[LightGBM] [Info] Start training from score -5.769761\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.0166498\tvalid_1's binary_logloss: 0.0188574\n",
      "Early stopping, best iteration is:\n",
      "[1113]\ttraining's binary_logloss: 0.0165249\tvalid_1's binary_logloss: 0.0188509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-06 09:01:33,639]\u001b[0m Trial 33 finished with value: 0.030984696871091788 and parameters: {'cf_a': 12, 'ctf_a': 9, 'atfd_a': 10, 'atfp_a': 8, 'pa_a': 2, 'cf_w': 3, 'ctf_w': 14, 'atfd_w': 23, 'atfp_w': 13, 'pa_w': 15, 'cf_m': 15, 'ctf_m': 11, 'atfd_m': 17, 'atfp_m': 4, 'pa_m': 4, 'cf_y': 20, 'ctf_y': 24, 'atfd_y': 4, 'atfp_y': 11, 'pa_y': 13}. Best is trial 31 with value: 0.03143208627505985.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 18021, number of negative: 5649110\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.645235 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7673\n",
      "[LightGBM] [Info] Number of data points in the train set: 5667131, number of used features: 49\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.003180 -> initscore=-5.747716\n",
      "[LightGBM] [Info] Start training from score -5.747716\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[765]\ttraining's binary_logloss: 0.0171785\tvalid_1's binary_logloss: 0.0191914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-06 09:14:15,632]\u001b[0m Trial 34 finished with value: 0.030986481109733306 and parameters: {'cf_a': 11, 'ctf_a': 6, 'atfd_a': 7, 'atfp_a': 12, 'pa_a': 3, 'cf_w': 7, 'ctf_w': 15, 'atfd_w': 6, 'atfp_w': 12, 'pa_w': 18, 'cf_m': 15, 'ctf_m': 10, 'atfd_m': 18, 'atfp_m': 5, 'pa_m': 1, 'cf_y': 19, 'ctf_y': 21, 'atfd_y': 6, 'atfp_y': 12, 'pa_y': 10}. Best is trial 31 with value: 0.03143208627505985.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 17283, number of negative: 5201769\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.649523 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7671\n",
      "[LightGBM] [Info] Number of data points in the train set: 5219052, number of used features: 49\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.003312 -> initscore=-5.707031\n",
      "[LightGBM] [Info] Start training from score -5.707031\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[867]\ttraining's binary_logloss: 0.0175943\tvalid_1's binary_logloss: 0.0198176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-06 09:27:10,421]\u001b[0m Trial 35 finished with value: 0.031150422023169963 and parameters: {'cf_a': 6, 'ctf_a': 9, 'atfd_a': 6, 'atfp_a': 6, 'pa_a': 8, 'cf_w': 5, 'ctf_w': 12, 'atfd_w': 21, 'atfp_w': 15, 'pa_w': 12, 'cf_m': 20, 'ctf_m': 1, 'atfd_m': 15, 'atfp_m': 0, 'pa_m': 5, 'cf_y': 21, 'ctf_y': 22, 'atfd_y': 2, 'atfp_y': 16, 'pa_y': 13}. Best is trial 31 with value: 0.03143208627505985.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 18054, number of negative: 5521869\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.551453 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7672\n",
      "[LightGBM] [Info] Number of data points in the train set: 5539923, number of used features: 49\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.003259 -> initscore=-5.723104\n",
      "[LightGBM] [Info] Start training from score -5.723104\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.0173418\tvalid_1's binary_logloss: 0.0194705\n",
      "[2000]\ttraining's binary_logloss: 0.0163152\tvalid_1's binary_logloss: 0.0194478\n",
      "Early stopping, best iteration is:\n",
      "[2541]\ttraining's binary_logloss: 0.0158301\tvalid_1's binary_logloss: 0.0194354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-06 09:44:48,101]\u001b[0m Trial 36 finished with value: 0.03090104615388013 and parameters: {'cf_a': 6, 'ctf_a': 11, 'atfd_a': 6, 'atfp_a': 5, 'pa_a': 12, 'cf_w': 0, 'ctf_w': 13, 'atfd_w': 21, 'atfp_w': 15, 'pa_w': 16, 'cf_m': 20, 'ctf_m': 1, 'atfd_m': 15, 'atfp_m': 0, 'pa_m': 6, 'cf_y': 21, 'ctf_y': 21, 'atfd_y': 4, 'atfp_y': 16, 'pa_y': 13}. Best is trial 31 with value: 0.03143208627505985.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 19005, number of negative: 5717193\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.452350 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7656\n",
      "[LightGBM] [Info] Number of data points in the train set: 5736198, number of used features: 49\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.003313 -> initscore=-5.706531\n",
      "[LightGBM] [Info] Start training from score -5.706531\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.0178055\tvalid_1's binary_logloss: 0.0201768\n",
      "Early stopping, best iteration is:\n",
      "[1340]\ttraining's binary_logloss: 0.017452\tvalid_1's binary_logloss: 0.0201614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-06 09:58:06,370]\u001b[0m Trial 37 finished with value: 0.031094676302717787 and parameters: {'cf_a': 3, 'ctf_a': 9, 'atfd_a': 5, 'atfp_a': 7, 'pa_a': 8, 'cf_w': 4, 'ctf_w': 12, 'atfd_w': 22, 'atfp_w': 15, 'pa_w': 21, 'cf_m': 21, 'ctf_m': 0, 'atfd_m': 15, 'atfp_m': 2, 'pa_m': 2, 'cf_y': 24, 'ctf_y': 22, 'atfd_y': 0, 'atfp_y': 10, 'pa_y': 24}. Best is trial 31 with value: 0.03143208627505985.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 17812, number of negative: 5516205\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.629703 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7700\n",
      "[LightGBM] [Info] Number of data points in the train set: 5534017, number of used features: 49\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.003219 -> initscore=-5.735573\n",
      "[LightGBM] [Info] Start training from score -5.735573\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.0170565\tvalid_1's binary_logloss: 0.0193847\n",
      "Early stopping, best iteration is:\n",
      "[1493]\ttraining's binary_logloss: 0.0165272\tvalid_1's binary_logloss: 0.0193672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-06 10:12:38,298]\u001b[0m Trial 38 finished with value: 0.03142532631206851 and parameters: {'cf_a': 13, 'ctf_a': 12, 'atfd_a': 3, 'atfp_a': 2, 'pa_a': 6, 'cf_w': 7, 'ctf_w': 15, 'atfd_w': 20, 'atfp_w': 8, 'pa_w': 12, 'cf_m': 19, 'ctf_m': 15, 'atfd_m': 20, 'atfp_m': 2, 'pa_m': 5, 'cf_y': 19, 'ctf_y': 24, 'atfd_y': 8, 'atfp_y': 7, 'pa_y': 17}. Best is trial 31 with value: 0.03143208627505985.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 17574, number of negative: 5234755\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.596675 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7660\n",
      "[LightGBM] [Info] Number of data points in the train set: 5252329, number of used features: 49\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.003346 -> initscore=-5.696655\n",
      "[LightGBM] [Info] Start training from score -5.696655\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.017709\tvalid_1's binary_logloss: 0.020066\n",
      "Early stopping, best iteration is:\n",
      "[1754]\ttraining's binary_logloss: 0.0168636\tvalid_1's binary_logloss: 0.0200395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-06 10:27:21,145]\u001b[0m Trial 39 finished with value: 0.031022195380691106 and parameters: {'cf_a': 7, 'ctf_a': 12, 'atfd_a': 4, 'atfp_a': 1, 'pa_a': 8, 'cf_w': 5, 'ctf_w': 12, 'atfd_w': 19, 'atfp_w': 7, 'pa_w': 11, 'cf_m': 19, 'ctf_m': 21, 'atfd_m': 19, 'atfp_m': 2, 'pa_m': 7, 'cf_y': 18, 'ctf_y': 24, 'atfd_y': 7, 'atfp_y': 3, 'pa_y': 17}. Best is trial 31 with value: 0.03143208627505985.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 17822, number of negative: 5452879\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.248320 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7689\n",
      "[LightGBM] [Info] Number of data points in the train set: 5470701, number of used features: 49\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.003258 -> initscore=-5.723465\n",
      "[LightGBM] [Info] Start training from score -5.723465\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.0172353\tvalid_1's binary_logloss: 0.0194364\n",
      "[2000]\ttraining's binary_logloss: 0.0161724\tvalid_1's binary_logloss: 0.0194167\n",
      "Early stopping, best iteration is:\n",
      "[2622]\ttraining's binary_logloss: 0.0156136\tvalid_1's binary_logloss: 0.019411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-06 10:42:49,598]\u001b[0m Trial 40 finished with value: 0.031108517208634008 and parameters: {'cf_a': 14, 'ctf_a': 16, 'atfd_a': 2, 'atfp_a': 2, 'pa_a': 11, 'cf_w': 2, 'ctf_w': 14, 'atfd_w': 21, 'atfp_w': 4, 'pa_w': 12, 'cf_m': 23, 'ctf_m': 15, 'atfd_m': 21, 'atfp_m': 6, 'pa_m': 3, 'cf_y': 22, 'ctf_y': 19, 'atfd_y': 6, 'atfp_y': 6, 'pa_y': 20}. Best is trial 31 with value: 0.03143208627505985.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 18032, number of negative: 5675568\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.442107 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7678\n",
      "[LightGBM] [Info] Number of data points in the train set: 5693600, number of used features: 49\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.003167 -> initscore=-5.751778\n",
      "[LightGBM] [Info] Start training from score -5.751778\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.0168399\tvalid_1's binary_logloss: 0.0192399\n",
      "Early stopping, best iteration is:\n",
      "[1785]\ttraining's binary_logloss: 0.0160273\tvalid_1's binary_logloss: 0.0192249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-06 10:57:22,513]\u001b[0m Trial 41 finished with value: 0.031052078475755054 and parameters: {'cf_a': 12, 'ctf_a': 10, 'atfd_a': 7, 'atfp_a': 0, 'pa_a': 6, 'cf_w': 7, 'ctf_w': 16, 'atfd_w': 24, 'atfp_w': 13, 'pa_w': 14, 'cf_m': 18, 'ctf_m': 12, 'atfd_m': 16, 'atfp_m': 3, 'pa_m': 5, 'cf_y': 20, 'ctf_y': 23, 'atfd_y': 3, 'atfp_y': 10, 'pa_y': 22}. Best is trial 31 with value: 0.03143208627505985.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 18198, number of negative: 5602425\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.560616 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7691\n",
      "[LightGBM] [Info] Number of data points in the train set: 5620623, number of used features: 49\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.003238 -> initscore=-5.729643\n",
      "[LightGBM] [Info] Start training from score -5.729643\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.0172468\tvalid_1's binary_logloss: 0.0194979\n",
      "Early stopping, best iteration is:\n",
      "[1058]\ttraining's binary_logloss: 0.0171829\tvalid_1's binary_logloss: 0.0194961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-06 11:11:25,576]\u001b[0m Trial 42 finished with value: 0.031014275080320317 and parameters: {'cf_a': 13, 'ctf_a': 9, 'atfd_a': 5, 'atfp_a': 8, 'pa_a': 5, 'cf_w': 8, 'ctf_w': 15, 'atfd_w': 20, 'atfp_w': 7, 'pa_w': 16, 'cf_m': 16, 'ctf_m': 18, 'atfd_m': 17, 'atfp_m': 0, 'pa_m': 5, 'cf_y': 18, 'ctf_y': 22, 'atfd_y': 5, 'atfp_y': 12, 'pa_y': 14}. Best is trial 31 with value: 0.03143208627505985.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 18189, number of negative: 6129221\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.430612 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7649\n",
      "[LightGBM] [Info] Number of data points in the train set: 6147410, number of used features: 49\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002959 -> initscore=-5.820006\n",
      "[LightGBM] [Info] Start training from score -5.820006\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.015849\tvalid_1's binary_logloss: 0.0181282\n",
      "[2000]\ttraining's binary_logloss: 0.0148679\tvalid_1's binary_logloss: 0.0180996\n",
      "Early stopping, best iteration is:\n",
      "[2351]\ttraining's binary_logloss: 0.0145838\tvalid_1's binary_logloss: 0.0180963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-06 11:26:58,229]\u001b[0m Trial 43 finished with value: 0.03080334973536638 and parameters: {'cf_a': 4, 'ctf_a': 11, 'atfd_a': 3, 'atfp_a': 5, 'pa_a': 7, 'cf_w': 5, 'ctf_w': 16, 'atfd_w': 22, 'atfp_w': 14, 'pa_w': 12, 'cf_m': 14, 'ctf_m': 13, 'atfd_m': 19, 'atfp_m': 6, 'pa_m': 8, 'cf_y': 19, 'ctf_y': 22, 'atfd_y': 24, 'atfp_y': 4, 'pa_y': 12}. Best is trial 31 with value: 0.03143208627505985.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 17945, number of negative: 5955185\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.471198 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7676\n",
      "[LightGBM] [Info] Number of data points in the train set: 5973130, number of used features: 49\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.003004 -> initscore=-5.804706\n",
      "[LightGBM] [Info] Start training from score -5.804706\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.016038\tvalid_1's binary_logloss: 0.0181074\n",
      "[2000]\ttraining's binary_logloss: 0.0150581\tvalid_1's binary_logloss: 0.0180929\n",
      "Early stopping, best iteration is:\n",
      "[1980]\ttraining's binary_logloss: 0.0150751\tvalid_1's binary_logloss: 0.0180893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-06 11:41:59,239]\u001b[0m Trial 44 finished with value: 0.0309393399301375 and parameters: {'cf_a': 16, 'ctf_a': 7, 'atfd_a': 10, 'atfp_a': 12, 'pa_a': 9, 'cf_w': 3, 'ctf_w': 11, 'atfd_w': 23, 'atfp_w': 11, 'pa_w': 14, 'cf_m': 13, 'ctf_m': 16, 'atfd_m': 14, 'atfp_m': 3, 'pa_m': 3, 'cf_y': 21, 'ctf_y': 20, 'atfd_y': 1, 'atfp_y': 15, 'pa_y': 17}. Best is trial 31 with value: 0.03143208627505985.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, timeout=12*60*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cf_a': 12, 'ctf_a': 9, 'atfd_a': 8, 'atfp_a': 12, 'pa_a': 2, 'cf_w': 8, 'ctf_w': 14, 'atfd_w': 23, 'atfp_w': 12, 'pa_w': 12, 'cf_m': 15, 'ctf_m': 10, 'atfd_m': 15, 'atfp_m': 11, 'pa_m': 5, 'cf_y': 19, 'ctf_y': 22, 'atfd_y': 3, 'atfp_y': 11, 'pa_y': 13}\n"
     ]
    }
   ],
   "source": [
    "print(study.best_params)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
