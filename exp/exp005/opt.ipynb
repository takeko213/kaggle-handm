{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# exp005_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import itertools\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "sys.path.append(os.getenv('UTILS_PATH'))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from optuna.integration import lightgbm as optuna_lgb\n",
    "import line_notify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import builtins\n",
    "import types\n",
    "\n",
    "def imports():\n",
    "    for name, val in globals().items():\n",
    "        # module imports\n",
    "        if isinstance(val, types.ModuleType):\n",
    "            yield name, val\n",
    "\n",
    "            # functions / callables\n",
    "        if hasattr(val, '__call__'):\n",
    "            yield name, val\n",
    "\n",
    "\n",
    "def noglobal(f):\n",
    "    '''\n",
    "    ref: https://gist.github.com/raven38/4e4c3c7a179283c441f575d6e375510c\n",
    "    '''\n",
    "    return types.FunctionType(f.__code__,\n",
    "                              dict(imports()),\n",
    "                              f.__name__,\n",
    "                              f.__defaults__,\n",
    "                              f.__closure__\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ディレクトリ設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIR = os.getenv('INPUT_DIR')\n",
    "OUTPUT_DIR = os.getenv('OUTPUT_DIR')\n",
    "#exp_name = os.path.dirname(__file__).split('/')[-1]\n",
    "exp_name = 'exp005'\n",
    "os.makedirs(OUTPUT_DIR + exp_name, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データ読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = pd.read_csv(INPUT_DIR + 'articles.csv', dtype='object')\n",
    "customers = pd.read_csv(INPUT_DIR + 'customers.csv')\n",
    "transactions = pd.read_csv(INPUT_DIR + 'transactions_train.csv', dtype={'article_id':'str'}, parse_dates=['t_dat'])\n",
    "sample = pd.read_csv(INPUT_DIR + 'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データセット作成（レコメンド→対象データセット作成→特徴量エンジニアリング）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@noglobal\n",
    "def get_customer_frequent(history, n=12, timedelta=None):\n",
    "    \"\"\"顧客ごと商品の購入数をカウントし上位の商品を抽出\n",
    "\n",
    "    Args:\n",
    "        history (dataframe): 集計対象の実績データ\n",
    "        n (int): レコメンド対象とする数\n",
    "        timedelta (dateutil.relativedelta): 指定された場合、実績データの終端からtimedelta分のデータを取得する\n",
    "\n",
    "    Returns:\n",
    "        dataframe: 抽出結果\n",
    "    \"\"\"\n",
    "    if timedelta is not None:\n",
    "        st_date = history['t_dat'].max() - timedelta\n",
    "        history = history[history['t_dat']>=st_date].copy()\n",
    "        \n",
    "    customer_agg = history.groupby(['customer_id', 'article_id'])['t_dat'].count().reset_index()\n",
    "    customer_agg = customer_agg.rename(columns={'t_dat':'cnt'})\n",
    "    customer_agg = customer_agg.sort_values(['customer_id', 'cnt'], ascending=False)\n",
    "    result = customer_agg.groupby('customer_id').head(n)\n",
    "    return result[['customer_id', 'article_id']]\n",
    "\n",
    "@noglobal\n",
    "def get_popular_article(history, n=12, timedelta=None):\n",
    "    \"\"\"全体の購入数をカウントし上位の商品を抽出\n",
    "\n",
    "    Args:\n",
    "        history (dataframe): 集計対象の実績データ\n",
    "        n (int): レコメンド対象とする数\n",
    "        timedelta (dateutil.relativedelta): 指定された場合、実績データの終端からtimedelta分のデータを取得する\n",
    "\n",
    "    Returns:\n",
    "        list: 抽出結果\n",
    "    \"\"\"\n",
    "    # 全体の購入数量\n",
    "    if timedelta is not None:\n",
    "        st_date = history['t_dat'].max() - timedelta\n",
    "        history = history[history['t_dat']>=st_date].copy()\n",
    "\n",
    "    total_agg = history.groupby('article_id')['t_dat'].count().reset_index()\n",
    "    total_agg = total_agg.rename(columns={'t_dat':'cnt'})\n",
    "    total_agg = total_agg.sort_values(['cnt'], ascending=False)\n",
    "    total_agg = total_agg.head(n)\n",
    "    result = list(total_agg['article_id'].values)\n",
    "    return result\n",
    "\n",
    "@noglobal\n",
    "def get_reccomend(target_customer_id, history):\n",
    "    \"\"\"対象のcustomer_idに対するレコメンド結果を返す\n",
    "\n",
    "    Args:\n",
    "        target_customer_id (list): 対象のcustomer_id\n",
    "        history (dataframe): レコメンドに用いる実績データ\n",
    "\n",
    "    Returns:\n",
    "        dataframe: レコメンド結果\n",
    "    \"\"\"\n",
    "    n = 12\n",
    "    result = pd.DataFrame()\n",
    "    \n",
    "    for td in [None, relativedelta(weeks=1), relativedelta(months=1), relativedelta(years=1)]:\n",
    "\n",
    "        customer_freq = get_customer_frequent(history, n, td)\n",
    "        popular_article = get_popular_article(history, n, td)\n",
    "        # customerとpopular articleの全組み合わせでdataframe作成\n",
    "        popular_article = pd.DataFrame(itertools.product(target_customer_id, popular_article), columns=['customer_id', 'article_id'])\n",
    "        tmp = pd.concat([customer_freq, popular_article])\n",
    "        result = result.append(tmp)\n",
    "    result = result.drop_duplicates()\n",
    "    result = result[result['customer_id'].isin(target_customer_id)].copy()\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@noglobal\n",
    "def add_labels(recom_result, history):\n",
    "    \"\"\"レコメンドしたデータが学習期間で購入されたかどうかのフラグを付与する\n",
    "\n",
    "    Args:\n",
    "        recom_result (_type_): レコメンド結果\n",
    "        train_tran (_type_): 学習期間のトランザクションデータ\n",
    "\n",
    "    Returns:\n",
    "        _type_: 学習期間での購入フラグを付与したレコメンド結果\n",
    "    \"\"\"\n",
    "    history = history[['customer_id', 'article_id']].drop_duplicates()\n",
    "    history['buy'] = 1\n",
    "    recom_result = recom_result.merge(history, on=['customer_id', 'article_id'], how='left')\n",
    "    recom_result['buy'] = recom_result['buy'].fillna(0)\n",
    "    return recom_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@noglobal\n",
    "def make_article_features(articles):\n",
    "    le_cols = ['product_type_name', 'product_group_name', 'graphical_appearance_name',\n",
    "               'colour_group_name', 'perceived_colour_value_name', 'department_name',\n",
    "               'index_name', 'index_group_name', 'section_name', 'garment_group_name']\n",
    "    for c in le_cols:\n",
    "        le = LabelEncoder()\n",
    "        articles[c] = le.fit_transform(articles[c].fillna(''))\n",
    "    return articles[['article_id']+le_cols]\n",
    "\n",
    "@noglobal\n",
    "def make_customer_features(customers):\n",
    "    le_cols = ['club_member_status', 'fashion_news_frequency', 'postal_code']\n",
    "    for c in le_cols:\n",
    "        le = LabelEncoder()\n",
    "        customers[c] = le.fit_transform(customers[c].fillna(''))\n",
    "    return customers\n",
    "\n",
    "@noglobal\n",
    "def make_customer_article_features(target, history):\n",
    "    df = target.merge(history, on=['customer_id', 'article_id'], how='inner')\n",
    "    df = df.groupby(['customer_id', 'article_id']).agg({'t_dat':['count', 'min', 'max']}).reset_index()\n",
    "    df.columns = ['customer_id', 'article_id', 'count', '1st_buy_date_diff', 'latest_buy_date_diff']\n",
    "    df['1st_buy_date_diff'] = (history['t_dat'].max() - df['1st_buy_date_diff']).dt.days\n",
    "    df['latest_buy_date_diff'] = (history['t_dat'].max() - df['latest_buy_date_diff']).dt.days\n",
    "    return df\n",
    "\n",
    "@noglobal\n",
    "def add_features(df, history, articles, customers):\n",
    "    article_features = make_article_features(articles)\n",
    "    customer_features = make_customer_features(customers)\n",
    "    customer_article_features = make_customer_article_features(df[['customer_id', 'article_id']], history)\n",
    "\n",
    "    df = df.merge(article_features, on=['article_id'], how='left')\n",
    "    df = df.merge(customer_features, on=['customer_id'], how='left')\n",
    "    df = df.merge(customer_article_features, on=['article_id', 'customer_id'], how='left')\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_start = '2020-09-09'\n",
    "valid_start = '2020-09-16'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習データの作成\n",
    "history_tran = transactions[transactions['t_dat'] < train_start].copy()\n",
    "target_tran = transactions[(transactions['t_dat'] >= train_start) & (transactions['t_dat'] < valid_start)].copy()\n",
    "\n",
    "target_id = target_tran['customer_id'].unique().tolist()\n",
    "recom = get_reccomend(target_id, history_tran)\n",
    "ml_train = add_labels(recom, target_tran)\n",
    "ml_train = add_features(ml_train, history_tran, articles, customers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 評価データの作成\n",
    "history_tran = transactions[transactions['t_dat'] < valid_start].copy()\n",
    "target_tran = transactions[transactions['t_dat'] >= valid_start].copy()\n",
    "\n",
    "target_id = target_tran['customer_id'].unique().tolist()\n",
    "recom = get_reccomend(target_id, history_tran)\n",
    "ml_valid = add_labels(recom, target_tran)\n",
    "ml_valid = add_features(ml_valid, history_tran, articles, customers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# テストデータの作成\n",
    "target_id = sample['customer_id'].tolist()\n",
    "recom = get_reccomend(target_id, transactions)\n",
    "ml_test = add_features(recom, transactions, articles, customers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    2977593\n",
       "1.0      12998\n",
       "Name: buy, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_train['buy'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    3254466\n",
       "1.0      14544\n",
       "Name: buy, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_valid['buy'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# レコメンド商品を購入するかどうかの2値分類モデル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'buy'\n",
    "not_use_cols = ['customer_id', 'article_id', target]\n",
    "features = [c for c in ml_train.columns if c not in not_use_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"objective\": \"binary\",\n",
    "    \"boosting\" : \"gbdt\",\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"metric\": \"binary_logloss\",\n",
    "    \"seed\": SEED\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-16 15:37:42,732]\u001b[0m A new study created in memory with name: no-name-0fd4a6cf-a123-43bf-ac87-85eeee4062fb\u001b[0m\n",
      "feature_fraction, val_score: inf:   0%|          | 0/7 [00:00<?, ?it/s]/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.097426 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1376\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.025479:  14%|#4        | 1/7 [00:14<01:24, 14.08s/it]\u001b[32m[I 2022-02-16 15:37:56,818]\u001b[0m Trial 0 finished with value: 0.02547942809458793 and parameters: {'feature_fraction': 0.8}. Best is trial 0 with value: 0.02547942809458793.\u001b[0m\n",
      "feature_fraction, val_score: 0.025479:  14%|#4        | 1/7 [00:14<01:24, 14.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[26]\tvalid_0's binary_logloss: 0.0238092\tvalid_1's binary_logloss: 0.0254794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.236944 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1376\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.025438:  29%|##8       | 2/7 [00:25<01:02, 12.54s/it]\u001b[32m[I 2022-02-16 15:38:08,287]\u001b[0m Trial 1 finished with value: 0.025438456349751157 and parameters: {'feature_fraction': 0.6}. Best is trial 1 with value: 0.025438456349751157.\u001b[0m\n",
      "feature_fraction, val_score: 0.025438:  29%|##8       | 2/7 [00:25<01:02, 12.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[44]\tvalid_0's binary_logloss: 0.0236261\tvalid_1's binary_logloss: 0.0254385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.242048 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1376\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.025381:  43%|####2     | 3/7 [00:41<00:55, 13.99s/it]\u001b[32m[I 2022-02-16 15:38:23,993]\u001b[0m Trial 2 finished with value: 0.025381099628384373 and parameters: {'feature_fraction': 0.7}. Best is trial 2 with value: 0.025381099628384373.\u001b[0m\n",
      "feature_fraction, val_score: 0.025381:  43%|####2     | 3/7 [00:41<00:55, 13.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[31]\tvalid_0's binary_logloss: 0.0237426\tvalid_1's binary_logloss: 0.0253811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.246601 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1376\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.025321:  57%|#####7    | 4/7 [00:51<00:37, 12.49s/it]\u001b[32m[I 2022-02-16 15:38:34,198]\u001b[0m Trial 3 finished with value: 0.025320522763760307 and parameters: {'feature_fraction': 0.4}. Best is trial 3 with value: 0.025320522763760307.\u001b[0m\n",
      "feature_fraction, val_score: 0.025321:  57%|#####7    | 4/7 [00:51<00:37, 12.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[39]\tvalid_0's binary_logloss: 0.0237395\tvalid_1's binary_logloss: 0.0253205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.041317 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1376\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.025321:  71%|#######1  | 5/7 [01:02<00:24, 12.02s/it]\u001b[32m[I 2022-02-16 15:38:45,374]\u001b[0m Trial 4 finished with value: 0.02542474110935013 and parameters: {'feature_fraction': 0.5}. Best is trial 3 with value: 0.025320522763760307.\u001b[0m\n",
      "feature_fraction, val_score: 0.025321:  71%|#######1  | 5/7 [01:02<00:24, 12.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[52]\tvalid_0's binary_logloss: 0.0235414\tvalid_1's binary_logloss: 0.0254247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.245369 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1376\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.025321:  86%|########5 | 6/7 [01:13<00:11, 11.77s/it]\u001b[32m[I 2022-02-16 15:38:56,664]\u001b[0m Trial 5 finished with value: 0.025533092980443463 and parameters: {'feature_fraction': 1.0}. Best is trial 3 with value: 0.025320522763760307.\u001b[0m\n",
      "feature_fraction, val_score: 0.025321:  86%|########5 | 6/7 [01:13<00:11, 11.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's binary_logloss: 0.0238057\tvalid_1's binary_logloss: 0.0255331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.269148 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1376\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.025321: 100%|##########| 7/7 [01:24<00:00, 11.30s/it]\u001b[32m[I 2022-02-16 15:39:06,990]\u001b[0m Trial 6 finished with value: 0.02556500695608382 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 3 with value: 0.025320522763760307.\u001b[0m\n",
      "feature_fraction, val_score: 0.025321: 100%|##########| 7/7 [01:24<00:00, 12.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[25]\tvalid_0's binary_logloss: 0.0238523\tvalid_1's binary_logloss: 0.025565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.025321:   0%|          | 0/20 [00:00<?, ?it/s]/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.236265 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1376\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.025304:   5%|5         | 1/20 [00:13<04:16, 13.50s/it]\u001b[32m[I 2022-02-16 15:39:20,496]\u001b[0m Trial 7 finished with value: 0.025304439490679086 and parameters: {'num_leaves': 35}. Best is trial 7 with value: 0.025304439490679086.\u001b[0m\n",
      "num_leaves, val_score: 0.025304:   5%|5         | 1/20 [00:13<04:16, 13.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[65]\tvalid_0's binary_logloss: 0.0233524\tvalid_1's binary_logloss: 0.0253044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.253070 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1376\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.025304:  10%|#         | 2/20 [00:35<05:29, 18.32s/it]\u001b[32m[I 2022-02-16 15:39:42,186]\u001b[0m Trial 8 finished with value: 0.02583018972468068 and parameters: {'num_leaves': 139}. Best is trial 7 with value: 0.025304439490679086.\u001b[0m\n",
      "num_leaves, val_score: 0.025304:  10%|#         | 2/20 [00:35<05:29, 18.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[37]\tvalid_0's binary_logloss: 0.0226167\tvalid_1's binary_logloss: 0.0258302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.036469 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1376\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.025304:  15%|#5        | 3/20 [00:45<04:11, 14.82s/it]\u001b[32m[I 2022-02-16 15:39:52,844]\u001b[0m Trial 9 finished with value: 0.025306153622308217 and parameters: {'num_leaves': 33}. Best is trial 7 with value: 0.025304439490679086.\u001b[0m\n",
      "num_leaves, val_score: 0.025304:  15%|#5        | 3/20 [00:45<04:11, 14.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[40]\tvalid_0's binary_logloss: 0.0236741\tvalid_1's binary_logloss: 0.0253062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.040743 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1376\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.025304:  20%|##        | 4/20 [01:00<03:54, 14.68s/it]\u001b[32m[I 2022-02-16 15:40:07,303]\u001b[0m Trial 10 finished with value: 0.026226302375100617 and parameters: {'num_leaves': 246}. Best is trial 7 with value: 0.025304439490679086.\u001b[0m\n",
      "num_leaves, val_score: 0.025304:  20%|##        | 4/20 [01:00<03:54, 14.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[36]\tvalid_0's binary_logloss: 0.0217636\tvalid_1's binary_logloss: 0.0262263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.237172 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1376\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.025304:  25%|##5       | 5/20 [01:16<03:46, 15.11s/it]\u001b[32m[I 2022-02-16 15:40:23,170]\u001b[0m Trial 11 finished with value: 0.026070178029954528 and parameters: {'num_leaves': 186}. Best is trial 7 with value: 0.025304439490679086.\u001b[0m\n",
      "num_leaves, val_score: 0.025304:  25%|##5       | 5/20 [01:16<03:46, 15.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[36]\tvalid_0's binary_logloss: 0.0222673\tvalid_1's binary_logloss: 0.0260702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.086687 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1376\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.025304:  30%|###       | 6/20 [01:33<03:41, 15.82s/it]\u001b[32m[I 2022-02-16 15:40:40,382]\u001b[0m Trial 12 finished with value: 0.026215930983067043 and parameters: {'num_leaves': 229}. Best is trial 7 with value: 0.025304439490679086.\u001b[0m\n",
      "num_leaves, val_score: 0.025304:  30%|###       | 6/20 [01:33<03:41, 15.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[43]\tvalid_0's binary_logloss: 0.0215207\tvalid_1's binary_logloss: 0.0262159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.035424 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1376\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.025304:  35%|###5      | 7/20 [01:50<03:31, 16.28s/it]\u001b[32m[I 2022-02-16 15:40:57,602]\u001b[0m Trial 13 finished with value: 0.025906372854005384 and parameters: {'num_leaves': 167}. Best is trial 7 with value: 0.025304439490679086.\u001b[0m\n",
      "num_leaves, val_score: 0.025304:  35%|###5      | 7/20 [01:50<03:31, 16.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[53]\tvalid_0's binary_logloss: 0.0217231\tvalid_1's binary_logloss: 0.0259064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042048 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1376\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.025304:  40%|####      | 8/20 [02:05<03:10, 15.87s/it]\u001b[32m[I 2022-02-16 15:41:12,583]\u001b[0m Trial 14 finished with value: 0.025604331416217423 and parameters: {'num_leaves': 92}. Best is trial 7 with value: 0.025304439490679086.\u001b[0m\n",
      "num_leaves, val_score: 0.025304:  40%|####      | 8/20 [02:05<03:10, 15.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[36]\tvalid_0's binary_logloss: 0.0230385\tvalid_1's binary_logloss: 0.0256043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.038055 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1376\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.025304:  45%|####5     | 9/20 [02:20<02:50, 15.51s/it]\u001b[32m[I 2022-02-16 15:41:27,317]\u001b[0m Trial 15 finished with value: 0.02625608703648884 and parameters: {'num_leaves': 230}. Best is trial 7 with value: 0.025304439490679086.\u001b[0m\n",
      "num_leaves, val_score: 0.025304:  45%|####5     | 9/20 [02:20<02:50, 15.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[35]\tvalid_0's binary_logloss: 0.0219396\tvalid_1's binary_logloss: 0.0262561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.037837 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1376\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.025304:  50%|#####     | 10/20 [02:33<02:28, 14.85s/it]\u001b[32m[I 2022-02-16 15:41:40,692]\u001b[0m Trial 16 finished with value: 0.026005172863175906 and parameters: {'num_leaves': 183}. Best is trial 7 with value: 0.025304439490679086.\u001b[0m\n",
      "num_leaves, val_score: 0.025304:  50%|#####     | 10/20 [02:33<02:28, 14.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[43]\tvalid_0's binary_logloss: 0.021924\tvalid_1's binary_logloss: 0.0260052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.035628 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1376\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.025218:  55%|#####5    | 11/20 [02:49<02:17, 15.29s/it]\u001b[32m[I 2022-02-16 15:41:56,970]\u001b[0m Trial 17 finished with value: 0.025218367652176093 and parameters: {'num_leaves': 10}. Best is trial 17 with value: 0.025218367652176093.\u001b[0m\n",
      "num_leaves, val_score: 0.025218:  55%|#####5    | 11/20 [02:49<02:17, 15.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[147]\tvalid_0's binary_logloss: 0.0236737\tvalid_1's binary_logloss: 0.0252184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.037249 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1376\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.025218:  60%|######    | 12/20 [03:08<02:09, 16.14s/it]\u001b[32m[I 2022-02-16 15:42:15,066]\u001b[0m Trial 18 finished with value: 0.025263881592570796 and parameters: {'num_leaves': 8}. Best is trial 17 with value: 0.025218367652176093.\u001b[0m\n",
      "num_leaves, val_score: 0.025218:  60%|######    | 12/20 [03:08<02:09, 16.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[187]\tvalid_0's binary_logloss: 0.0237158\tvalid_1's binary_logloss: 0.0252639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.264486 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1376\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.025205:  65%|######5   | 13/20 [03:51<02:50, 24.41s/it]\u001b[32m[I 2022-02-16 15:42:58,508]\u001b[0m Trial 19 finished with value: 0.02520497227898798 and parameters: {'num_leaves': 4}. Best is trial 19 with value: 0.02520497227898798.\u001b[0m\n",
      "num_leaves, val_score: 0.025205:  65%|######5   | 13/20 [03:51<02:50, 24.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[562]\tvalid_0's binary_logloss: 0.0236978\tvalid_1's binary_logloss: 0.025205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.040807 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1376\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.025205:  70%|#######   | 14/20 [04:03<02:04, 20.71s/it]\u001b[32m[I 2022-02-16 15:43:10,675]\u001b[0m Trial 20 finished with value: 0.02548460959867971 and parameters: {'num_leaves': 80}. Best is trial 19 with value: 0.02520497227898798.\u001b[0m\n",
      "num_leaves, val_score: 0.025205:  70%|#######   | 14/20 [04:03<02:04, 20.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[38]\tvalid_0's binary_logloss: 0.023143\tvalid_1's binary_logloss: 0.0254846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.259961 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1376\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.025205:  75%|#######5  | 15/20 [04:19<01:36, 19.22s/it]\u001b[32m[I 2022-02-16 15:43:26,428]\u001b[0m Trial 21 finished with value: 0.02543177105163613 and parameters: {'num_leaves': 72}. Best is trial 19 with value: 0.02520497227898798.\u001b[0m\n",
      "num_leaves, val_score: 0.025205:  75%|#######5  | 15/20 [04:19<01:36, 19.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[48]\tvalid_0's binary_logloss: 0.0230147\tvalid_1's binary_logloss: 0.0254318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.266028 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1376\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.025205:  80%|########  | 16/20 [04:42<01:21, 20.40s/it]\u001b[32m[I 2022-02-16 15:43:49,567]\u001b[0m Trial 22 finished with value: 0.025207975570451107 and parameters: {'num_leaves': 7}. Best is trial 19 with value: 0.02520497227898798.\u001b[0m\n",
      "num_leaves, val_score: 0.025205:  80%|########  | 16/20 [04:42<01:21, 20.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[247]\tvalid_0's binary_logloss: 0.0236718\tvalid_1's binary_logloss: 0.025208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.252749 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1376\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.025205:  85%|########5 | 17/20 [04:55<00:54, 18.28s/it]\u001b[32m[I 2022-02-16 15:44:02,933]\u001b[0m Trial 23 finished with value: 0.02540453579214412 and parameters: {'num_leaves': 50}. Best is trial 19 with value: 0.02520497227898798.\u001b[0m\n",
      "num_leaves, val_score: 0.025205:  85%|########5 | 17/20 [04:55<00:54, 18.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[52]\tvalid_0's binary_logloss: 0.0232633\tvalid_1's binary_logloss: 0.0254045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.243074 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1376\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.025205:  90%|######### | 18/20 [05:09<00:33, 16.99s/it]\u001b[32m[I 2022-02-16 15:44:16,895]\u001b[0m Trial 24 finished with value: 0.02559740014796338 and parameters: {'num_leaves': 100}. Best is trial 19 with value: 0.02520497227898798.\u001b[0m\n",
      "num_leaves, val_score: 0.025205:  90%|######### | 18/20 [05:09<00:33, 16.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[35]\tvalid_0's binary_logloss: 0.0229892\tvalid_1's binary_logloss: 0.0255974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.035932 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1376\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.025205:  95%|#########5| 19/20 [05:23<00:15, 15.87s/it]\u001b[32m[I 2022-02-16 15:44:30,167]\u001b[0m Trial 25 finished with value: 0.025889804880661168 and parameters: {'num_leaves': 122}. Best is trial 19 with value: 0.02520497227898798.\u001b[0m\n",
      "num_leaves, val_score: 0.025205:  95%|#########5| 19/20 [05:23<00:15, 15.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[33]\tvalid_0's binary_logloss: 0.0229117\tvalid_1's binary_logloss: 0.0258898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.246609 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1376\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.025205: 100%|##########| 20/20 [05:55<00:00, 20.84s/it]\u001b[32m[I 2022-02-16 15:45:02,591]\u001b[0m Trial 26 finished with value: 0.02536832165146509 and parameters: {'num_leaves': 3}. Best is trial 19 with value: 0.02520497227898798.\u001b[0m\n",
      "num_leaves, val_score: 0.025205: 100%|##########| 20/20 [05:55<00:00, 17.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[650]\tvalid_0's binary_logloss: 0.0239259\tvalid_1's binary_logloss: 0.0253683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.025205:   0%|          | 0/10 [00:00<?, ?it/s]/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.034549 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1376\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\tvalid_0's binary_logloss: 0.0234442\tvalid_1's binary_logloss: 0.0251104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.025106:  10%|#         | 1/10 [00:50<07:30, 50.00s/it]\u001b[32m[I 2022-02-16 15:45:52,598]\u001b[0m Trial 27 finished with value: 0.0251058611564457 and parameters: {'bagging_fraction': 0.854128578061625, 'bagging_freq': 1}. Best is trial 27 with value: 0.0251058611564457.\u001b[0m\n",
      "bagging, val_score: 0.025106:  10%|#         | 1/10 [00:50<07:30, 50.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[986]\tvalid_0's binary_logloss: 0.0234505\tvalid_1's binary_logloss: 0.0251059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.258611 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1376\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.025106:  20%|##        | 2/10 [01:41<06:44, 50.61s/it]\u001b[32m[I 2022-02-16 15:46:43,638]\u001b[0m Trial 28 finished with value: 0.025223580113078126 and parameters: {'bagging_fraction': 0.8624448677763122, 'bagging_freq': 5}. Best is trial 27 with value: 0.0251058611564457.\u001b[0m\n",
      "bagging, val_score: 0.025106:  20%|##        | 2/10 [01:41<06:44, 50.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[815]\tvalid_0's binary_logloss: 0.0235285\tvalid_1's binary_logloss: 0.0252236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.239079 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1376\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.025106:  30%|###       | 3/10 [02:11<04:51, 41.60s/it]\u001b[32m[I 2022-02-16 15:47:14,515]\u001b[0m Trial 29 finished with value: 0.025187910406717213 and parameters: {'bagging_fraction': 0.9346414241018525, 'bagging_freq': 3}. Best is trial 27 with value: 0.0251058611564457.\u001b[0m\n",
      "bagging, val_score: 0.025106:  30%|###       | 3/10 [02:11<04:51, 41.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[513]\tvalid_0's binary_logloss: 0.0237126\tvalid_1's binary_logloss: 0.0251879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.062534 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1376\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.025106:  40%|####      | 4/10 [02:38<03:35, 35.87s/it]\u001b[32m[I 2022-02-16 15:47:41,594]\u001b[0m Trial 30 finished with value: 0.0251310732859363 and parameters: {'bagging_fraction': 0.4993515946136968, 'bagging_freq': 6}. Best is trial 27 with value: 0.0251058611564457.\u001b[0m\n",
      "bagging, val_score: 0.025106:  40%|####      | 4/10 [02:39<03:35, 35.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[644]\tvalid_0's binary_logloss: 0.0236399\tvalid_1's binary_logloss: 0.0251311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.242542 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1376\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\tvalid_0's binary_logloss: 0.0234323\tvalid_1's binary_logloss: 0.0251019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.025095:  50%|#####     | 5/10 [03:23<03:15, 39.09s/it]\u001b[32m[I 2022-02-16 15:48:26,384]\u001b[0m Trial 31 finished with value: 0.02509481006364362 and parameters: {'bagging_fraction': 0.7044322351272188, 'bagging_freq': 5}. Best is trial 31 with value: 0.02509481006364362.\u001b[0m\n",
      "bagging, val_score: 0.025095:  50%|#####     | 5/10 [03:23<03:15, 39.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[965]\tvalid_0's binary_logloss: 0.0234501\tvalid_1's binary_logloss: 0.0250948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.257564 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1376\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\tvalid_0's binary_logloss: 0.023435\tvalid_1's binary_logloss: 0.0250863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.025079:  60%|######    | 6/10 [04:40<03:27, 51.92s/it]\u001b[32m[I 2022-02-16 15:49:43,225]\u001b[0m Trial 32 finished with value: 0.025078675220434214 and parameters: {'bagging_fraction': 0.8154283192468761, 'bagging_freq': 1}. Best is trial 32 with value: 0.025078675220434214.\u001b[0m\n",
      "bagging, val_score: 0.025079:  60%|######    | 6/10 [04:40<03:27, 51.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1050]\tvalid_0's binary_logloss: 0.0234105\tvalid_1's binary_logloss: 0.0250787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.250228 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1376\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.025079:  70%|#######   | 7/10 [05:06<02:10, 43.48s/it]\u001b[32m[I 2022-02-16 15:50:09,310]\u001b[0m Trial 33 finished with value: 0.02521911807199676 and parameters: {'bagging_fraction': 0.4914299706012013, 'bagging_freq': 4}. Best is trial 32 with value: 0.025078675220434214.\u001b[0m\n",
      "bagging, val_score: 0.025079:  70%|#######   | 7/10 [05:06<02:10, 43.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[546]\tvalid_0's binary_logloss: 0.0236981\tvalid_1's binary_logloss: 0.0252191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.233568 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1376\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\tvalid_0's binary_logloss: 0.0234435\tvalid_1's binary_logloss: 0.0251509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.025079:  80%|########  | 8/10 [05:59<01:32, 46.32s/it]\u001b[32m[I 2022-02-16 15:51:01,707]\u001b[0m Trial 34 finished with value: 0.025133383417914944 and parameters: {'bagging_fraction': 0.7454864485153507, 'bagging_freq': 6}. Best is trial 32 with value: 0.025078675220434214.\u001b[0m\n",
      "bagging, val_score: 0.025079:  80%|########  | 8/10 [05:59<01:32, 46.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1105]\tvalid_0's binary_logloss: 0.0234009\tvalid_1's binary_logloss: 0.0251334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.257728 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1376\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.025079:  90%|######### | 9/10 [06:53<00:48, 48.69s/it]\u001b[32m[I 2022-02-16 15:51:55,623]\u001b[0m Trial 35 finished with value: 0.025192735347002355 and parameters: {'bagging_fraction': 0.8079065873255571, 'bagging_freq': 5}. Best is trial 32 with value: 0.025078675220434214.\u001b[0m\n",
      "bagging, val_score: 0.025079:  90%|######### | 9/10 [06:53<00:48, 48.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[872]\tvalid_0's binary_logloss: 0.0234976\tvalid_1's binary_logloss: 0.0251927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.250906 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1376\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.025079: 100%|##########| 10/10 [07:34<00:00, 46.52s/it]\u001b[32m[I 2022-02-16 15:52:37,285]\u001b[0m Trial 36 finished with value: 0.025169155625080344 and parameters: {'bagging_fraction': 0.8628353489209891, 'bagging_freq': 7}. Best is trial 32 with value: 0.025078675220434214.\u001b[0m\n",
      "bagging, val_score: 0.025079: 100%|##########| 10/10 [07:34<00:00, 45.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[583]\tvalid_0's binary_logloss: 0.023642\tvalid_1's binary_logloss: 0.0251692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.025079:   0%|          | 0/3 [00:00<?, ?it/s]/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.109493 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1376\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\tvalid_0's binary_logloss: 0.023435\tvalid_1's binary_logloss: 0.0250863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.025079:  33%|###3      | 1/3 [00:55<01:50, 55.48s/it]\u001b[32m[I 2022-02-16 15:53:32,769]\u001b[0m Trial 37 finished with value: 0.0250786752204342 and parameters: {'feature_fraction': 0.41600000000000004}. Best is trial 37 with value: 0.0250786752204342.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.025079:  33%|###3      | 1/3 [00:55<01:50, 55.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1050]\tvalid_0's binary_logloss: 0.0234105\tvalid_1's binary_logloss: 0.0250787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.255512 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1376\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.025079:  67%|######6   | 2/3 [01:55<00:58, 58.37s/it]\u001b[32m[I 2022-02-16 15:54:33,159]\u001b[0m Trial 38 finished with value: 0.02520129415517848 and parameters: {'feature_fraction': 0.48000000000000004}. Best is trial 37 with value: 0.0250786752204342.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.025079:  67%|######6   | 2/3 [01:55<00:58, 58.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[801]\tvalid_0's binary_logloss: 0.0235301\tvalid_1's binary_logloss: 0.0252013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.038227 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1376\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.025079: 100%|##########| 3/3 [02:39<00:00, 51.75s/it]\u001b[32m[I 2022-02-16 15:55:17,035]\u001b[0m Trial 39 finished with value: 0.02520129415517848 and parameters: {'feature_fraction': 0.44800000000000006}. Best is trial 37 with value: 0.0250786752204342.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.025079: 100%|##########| 3/3 [02:39<00:00, 53.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[801]\tvalid_0's binary_logloss: 0.0235301\tvalid_1's binary_logloss: 0.0252013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.025079:   0%|          | 0/20 [00:00<?, ?it/s]/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.245723 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1376\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.025079:   5%|5         | 1/20 [00:37<11:44, 37.09s/it]\u001b[32m[I 2022-02-16 15:55:54,128]\u001b[0m Trial 40 finished with value: 0.02522448670920114 and parameters: {'lambda_l1': 2.250420023395027, 'lambda_l2': 0.22986752867912277}. Best is trial 40 with value: 0.02522448670920114.\u001b[0m\n",
      "regularization_factors, val_score: 0.025079:   5%|5         | 1/20 [00:37<11:44, 37.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[580]\tvalid_0's binary_logloss: 0.0236766\tvalid_1's binary_logloss: 0.0252245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.036951 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1376\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\tvalid_0's binary_logloss: 0.0234368\tvalid_1's binary_logloss: 0.0251661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.025079:  10%|#         | 2/20 [01:31<14:06, 47.00s/it]\u001b[32m[I 2022-02-16 15:56:48,072]\u001b[0m Trial 41 finished with value: 0.025158673808720177 and parameters: {'lambda_l1': 0.00046534577050677957, 'lambda_l2': 0.0035618556719829975}. Best is trial 41 with value: 0.025158673808720177.\u001b[0m\n",
      "regularization_factors, val_score: 0.025079:  10%|#         | 2/20 [01:31<14:06, 47.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1051]\tvalid_0's binary_logloss: 0.023415\tvalid_1's binary_logloss: 0.0251587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.085426 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1376\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\tvalid_0's binary_logloss: 0.023435\tvalid_1's binary_logloss: 0.0250983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.025079:  15%|#5        | 3/20 [02:39<16:02, 56.62s/it]\u001b[32m[I 2022-02-16 15:57:56,127]\u001b[0m Trial 42 finished with value: 0.02509061640695042 and parameters: {'lambda_l1': 1.155994596444457e-07, 'lambda_l2': 3.648436365523494e-06}. Best is trial 42 with value: 0.02509061640695042.\u001b[0m\n",
      "regularization_factors, val_score: 0.025079:  15%|#5        | 3/20 [02:39<16:02, 56.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1050]\tvalid_0's binary_logloss: 0.0234105\tvalid_1's binary_logloss: 0.0250906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043273 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1376\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.025079:  20%|##        | 4/20 [03:09<12:19, 46.23s/it]\u001b[32m[I 2022-02-16 15:58:26,430]\u001b[0m Trial 43 finished with value: 0.02518007829513249 and parameters: {'lambda_l1': 3.455547069778294, 'lambda_l2': 0.00033235166550877243}. Best is trial 42 with value: 0.02509061640695042.\u001b[0m\n",
      "regularization_factors, val_score: 0.025079:  20%|##        | 4/20 [03:09<12:19, 46.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[580]\tvalid_0's binary_logloss: 0.0236833\tvalid_1's binary_logloss: 0.0251801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.038331 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1376\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\tvalid_0's binary_logloss: 0.0234359\tvalid_1's binary_logloss: 0.0251028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.025079:  25%|##5       | 5/20 [04:00<11:59, 47.94s/it]\u001b[32m[I 2022-02-16 15:59:17,411]\u001b[0m Trial 44 finished with value: 0.025094738167265224 and parameters: {'lambda_l1': 0.001854297742375592, 'lambda_l2': 6.831425763425825e-07}. Best is trial 42 with value: 0.02509061640695042.\u001b[0m\n",
      "regularization_factors, val_score: 0.025079:  25%|##5       | 5/20 [04:00<11:59, 47.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1050]\tvalid_0's binary_logloss: 0.0234123\tvalid_1's binary_logloss: 0.0250947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.235932 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1376\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.025079:  30%|###       | 6/20 [04:42<10:44, 46.02s/it]\u001b[32m[I 2022-02-16 15:59:59,688]\u001b[0m Trial 45 finished with value: 0.025135991747246466 and parameters: {'lambda_l1': 5.26354391798722e-05, 'lambda_l2': 5.036867839879843e-06}. Best is trial 42 with value: 0.02509061640695042.\u001b[0m\n",
      "regularization_factors, val_score: 0.025079:  30%|###       | 6/20 [04:42<10:44, 46.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[837]\tvalid_0's binary_logloss: 0.0235118\tvalid_1's binary_logloss: 0.025136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.261014 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1376\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\tvalid_0's binary_logloss: 0.0234845\tvalid_1's binary_logloss: 0.0251417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.025079:  35%|###5      | 7/20 [06:06<12:38, 58.36s/it]\u001b[32m[I 2022-02-16 16:01:23,454]\u001b[0m Trial 46 finished with value: 0.02512670204517618 and parameters: {'lambda_l1': 2.8751479360048466, 'lambda_l2': 2.3560949473769507e-07}. Best is trial 42 with value: 0.02509061640695042.\u001b[0m\n",
      "regularization_factors, val_score: 0.025079:  35%|###5      | 7/20 [06:06<12:38, 58.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1257]\tvalid_0's binary_logloss: 0.0233961\tvalid_1's binary_logloss: 0.0251267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.041000 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1376\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\tvalid_0's binary_logloss: 0.0234527\tvalid_1's binary_logloss: 0.025105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.025079:  40%|####      | 8/20 [06:55<11:03, 55.30s/it]\u001b[32m[I 2022-02-16 16:02:12,196]\u001b[0m Trial 47 finished with value: 0.025091925903426408 and parameters: {'lambda_l1': 8.267313430415213e-06, 'lambda_l2': 0.13940057185279842}. Best is trial 42 with value: 0.02509061640695042.\u001b[0m\n",
      "regularization_factors, val_score: 0.025079:  40%|####      | 8/20 [06:55<11:03, 55.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1051]\tvalid_0's binary_logloss: 0.0234321\tvalid_1's binary_logloss: 0.0250919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.238965 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1376\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.025079:  45%|####5     | 9/20 [07:29<08:56, 48.78s/it]\u001b[32m[I 2022-02-16 16:02:46,638]\u001b[0m Trial 48 finished with value: 0.02512196867734532 and parameters: {'lambda_l1': 1.1364813178769731e-08, 'lambda_l2': 1.178345042490544}. Best is trial 42 with value: 0.02509061640695042.\u001b[0m\n",
      "regularization_factors, val_score: 0.025079:  45%|####5     | 9/20 [07:29<08:56, 48.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[657]\tvalid_0's binary_logloss: 0.02363\tvalid_1's binary_logloss: 0.025122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.034302 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1376\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\tvalid_0's binary_logloss: 0.023435\tvalid_1's binary_logloss: 0.0250917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.025079:  50%|#####     | 10/20 [08:20<08:15, 49.55s/it]\u001b[32m[I 2022-02-16 16:03:37,918]\u001b[0m Trial 49 finished with value: 0.025084095384882595 and parameters: {'lambda_l1': 1.232633133260087e-05, 'lambda_l2': 6.848447325760535e-08}. Best is trial 49 with value: 0.025084095384882595.\u001b[0m\n",
      "regularization_factors, val_score: 0.025079:  50%|#####     | 10/20 [08:20<08:15, 49.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1050]\tvalid_0's binary_logloss: 0.0234105\tvalid_1's binary_logloss: 0.0250841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.038966 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1376\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.025079:  55%|#####5    | 11/20 [09:00<06:57, 46.37s/it]\u001b[32m[I 2022-02-16 16:04:17,090]\u001b[0m Trial 50 finished with value: 0.025124491067735153 and parameters: {'lambda_l1': 0.03738869529060127, 'lambda_l2': 1.1788480475060541e-08}. Best is trial 49 with value: 0.025084095384882595.\u001b[0m\n",
      "regularization_factors, val_score: 0.025079:  55%|#####5    | 11/20 [09:00<06:57, 46.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[764]\tvalid_0's binary_logloss: 0.0235535\tvalid_1's binary_logloss: 0.0251245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.103001 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1376\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.025079:  60%|######    | 12/20 [09:32<05:38, 42.26s/it]\u001b[32m[I 2022-02-16 16:04:49,933]\u001b[0m Trial 51 finished with value: 0.02518537108726022 and parameters: {'lambda_l1': 2.342085805125707e-07, 'lambda_l2': 2.150734135683126e-05}. Best is trial 49 with value: 0.025084095384882595.\u001b[0m\n",
      "regularization_factors, val_score: 0.025079:  60%|######    | 12/20 [09:32<05:38, 42.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[611]\tvalid_0's binary_logloss: 0.0236383\tvalid_1's binary_logloss: 0.0251854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.039725 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1376\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.025079:  65%|######5   | 13/20 [10:07<04:39, 39.94s/it]\u001b[32m[I 2022-02-16 16:05:24,538]\u001b[0m Trial 52 finished with value: 0.02516106592359924 and parameters: {'lambda_l1': 1.2817883742562547e-06, 'lambda_l2': 1.0016656559583452e-08}. Best is trial 49 with value: 0.025084095384882595.\u001b[0m\n",
      "regularization_factors, val_score: 0.025079:  65%|######5   | 13/20 [10:07<04:39, 39.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[658]\tvalid_0's binary_logloss: 0.0236092\tvalid_1's binary_logloss: 0.0251611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.242909 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1376\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\tvalid_0's binary_logloss: 0.023435\tvalid_1's binary_logloss: 0.0250845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.025077:  70%|#######   | 14/20 [10:59<04:21, 43.60s/it]\u001b[32m[I 2022-02-16 16:06:16,601]\u001b[0m Trial 53 finished with value: 0.025076821038582994 and parameters: {'lambda_l1': 1.1333200831495417e-07, 'lambda_l2': 3.0512322584754754e-07}. Best is trial 53 with value: 0.025076821038582994.\u001b[0m\n",
      "regularization_factors, val_score: 0.025077:  70%|#######   | 14/20 [10:59<04:21, 43.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1050]\tvalid_0's binary_logloss: 0.0234105\tvalid_1's binary_logloss: 0.0250768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.038916 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1376\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\tvalid_0's binary_logloss: 0.023435\tvalid_1's binary_logloss: 0.0250913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.025077:  75%|#######5  | 15/20 [11:50<03:49, 45.87s/it]\u001b[32m[I 2022-02-16 16:07:07,729]\u001b[0m Trial 54 finished with value: 0.02508372511154825 and parameters: {'lambda_l1': 5.569356371465693e-06, 'lambda_l2': 5.765272909208299e-08}. Best is trial 53 with value: 0.025076821038582994.\u001b[0m\n",
      "regularization_factors, val_score: 0.025077:  75%|#######5  | 15/20 [11:50<03:49, 45.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1050]\tvalid_0's binary_logloss: 0.0234105\tvalid_1's binary_logloss: 0.0250837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.261165 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1376\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.025077:  80%|########  | 16/20 [12:49<03:19, 49.77s/it]\u001b[32m[I 2022-02-16 16:08:06,560]\u001b[0m Trial 55 finished with value: 0.025119013406589764 and parameters: {'lambda_l1': 1.2132258692771739e-08, 'lambda_l2': 0.00011746390237861868}. Best is trial 53 with value: 0.025076821038582994.\u001b[0m\n",
      "regularization_factors, val_score: 0.025077:  80%|########  | 16/20 [12:49<03:19, 49.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[865]\tvalid_0's binary_logloss: 0.0234957\tvalid_1's binary_logloss: 0.025119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.239981 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1376\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\tvalid_0's binary_logloss: 0.023435\tvalid_1's binary_logloss: 0.0250863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.025077:  85%|########5 | 17/20 [13:47<02:36, 52.24s/it]\u001b[32m[I 2022-02-16 16:09:04,539]\u001b[0m Trial 56 finished with value: 0.02507867467250792 and parameters: {'lambda_l1': 9.291841528413931e-07, 'lambda_l2': 5.588570962767556e-07}. Best is trial 53 with value: 0.025076821038582994.\u001b[0m\n",
      "regularization_factors, val_score: 0.025077:  85%|########5 | 17/20 [13:47<02:36, 52.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1050]\tvalid_0's binary_logloss: 0.0234105\tvalid_1's binary_logloss: 0.0250787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.036755 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1376\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\tvalid_0's binary_logloss: 0.0234444\tvalid_1's binary_logloss: 0.0250928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.025072:  90%|######### | 18/20 [14:54<01:53, 56.71s/it]\u001b[32m[I 2022-02-16 16:10:11,654]\u001b[0m Trial 57 finished with value: 0.02507213906628844 and parameters: {'lambda_l1': 2.389952606952462e-07, 'lambda_l2': 0.002375163052468583}. Best is trial 57 with value: 0.02507213906628844.\u001b[0m\n",
      "regularization_factors, val_score: 0.025072:  90%|######### | 18/20 [14:54<01:53, 56.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1275]\tvalid_0's binary_logloss: 0.0233248\tvalid_1's binary_logloss: 0.0250721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.256797 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1376\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\tvalid_0's binary_logloss: 0.0234357\tvalid_1's binary_logloss: 0.0250803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.025053:  95%|#########5| 19/20 [16:31<01:08, 68.69s/it]\u001b[32m[I 2022-02-16 16:11:48,245]\u001b[0m Trial 58 finished with value: 0.025052915029282082 and parameters: {'lambda_l1': 9.469353754507788e-08, 'lambda_l2': 0.0022280155140637654}. Best is trial 58 with value: 0.025052915029282082.\u001b[0m\n",
      "regularization_factors, val_score: 0.025053:  95%|#########5| 19/20 [16:31<01:08, 68.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1398]\tvalid_0's binary_logloss: 0.0232791\tvalid_1's binary_logloss: 0.0250529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.036058 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1376\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.025053: 100%|##########| 20/20 [17:15<00:00, 61.29s/it]\u001b[32m[I 2022-02-16 16:12:32,288]\u001b[0m Trial 59 finished with value: 0.02509551186988306 and parameters: {'lambda_l1': 0.023473923227549567, 'lambda_l2': 0.008455766482829068}. Best is trial 58 with value: 0.025052915029282082.\u001b[0m\n",
      "regularization_factors, val_score: 0.025053: 100%|##########| 20/20 [17:15<00:00, 51.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[865]\tvalid_0's binary_logloss: 0.0234916\tvalid_1's binary_logloss: 0.0250955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.025053:   0%|          | 0/5 [00:00<?, ?it/s]/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.261463 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1376\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\tvalid_0's binary_logloss: 0.0234412\tvalid_1's binary_logloss: 0.0250826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.025048:  20%|##        | 1/5 [01:21<05:26, 81.58s/it]\u001b[32m[I 2022-02-16 16:13:53,877]\u001b[0m Trial 60 finished with value: 0.025047878406542642 and parameters: {'min_child_samples': 50}. Best is trial 60 with value: 0.025047878406542642.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.025048:  20%|##        | 1/5 [01:21<05:26, 81.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1241]\tvalid_0's binary_logloss: 0.0233397\tvalid_1's binary_logloss: 0.0250479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.039658 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1376\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.025048:  40%|####      | 2/5 [02:01<02:52, 57.35s/it]\u001b[32m[I 2022-02-16 16:14:34,262]\u001b[0m Trial 61 finished with value: 0.02517758414827151 and parameters: {'min_child_samples': 100}. Best is trial 60 with value: 0.025047878406542642.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.025048:  40%|####      | 2/5 [02:01<02:52, 57.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[763]\tvalid_0's binary_logloss: 0.023552\tvalid_1's binary_logloss: 0.0251776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.239649 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1376\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\tvalid_0's binary_logloss: 0.023431\tvalid_1's binary_logloss: 0.0251071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.025048:  60%|######    | 3/5 [03:05<02:00, 60.09s/it]\u001b[32m[I 2022-02-16 16:15:37,620]\u001b[0m Trial 62 finished with value: 0.025077330702095734 and parameters: {'min_child_samples': 10}. Best is trial 60 with value: 0.025047878406542642.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.025048:  60%|######    | 3/5 [03:05<02:00, 60.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1364]\tvalid_0's binary_logloss: 0.0232815\tvalid_1's binary_logloss: 0.0250773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.260704 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1376\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.025048:  80%|########  | 4/5 [03:42<00:51, 51.13s/it]\u001b[32m[I 2022-02-16 16:16:15,009]\u001b[0m Trial 63 finished with value: 0.025276132180610596 and parameters: {'min_child_samples': 5}. Best is trial 60 with value: 0.025047878406542642.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.025048:  80%|########  | 4/5 [03:42<00:51, 51.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[477]\tvalid_0's binary_logloss: 0.0237456\tvalid_1's binary_logloss: 0.0252761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.242883 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1376\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\tvalid_0's binary_logloss: 0.0234389\tvalid_1's binary_logloss: 0.0250832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.025048: 100%|##########| 5/5 [04:41<00:00, 53.85s/it]\u001b[32m[I 2022-02-16 16:17:13,677]\u001b[0m Trial 64 finished with value: 0.025052070358567984 and parameters: {'min_child_samples': 25}. Best is trial 60 with value: 0.025047878406542642.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.025048: 100%|##########| 5/5 [04:41<00:00, 56.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1259]\tvalid_0's binary_logloss: 0.0233257\tvalid_1's binary_logloss: 0.0250521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tr_x, tr_y = ml_train[features], ml_train[target]\n",
    "vl_x, vl_y = ml_valid[features], ml_valid[target]\n",
    "\n",
    "tr_data = lgb.Dataset(tr_x, label=tr_y)\n",
    "vl_data = lgb.Dataset(vl_x, label=vl_y)\n",
    "\n",
    "model = optuna_lgb.train(params, tr_data, valid_sets=[tr_data, vl_data],\n",
    "                        num_boost_round=20000, early_stopping_rounds=100,verbose_eval=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'objective': 'binary',\n",
       " 'boosting': 'gbdt',\n",
       " 'learning_rate': 0.1,\n",
       " 'metric': 'binary_logloss',\n",
       " 'seed': 42,\n",
       " 'feature_pre_filter': False,\n",
       " 'lambda_l1': 9.469353754507788e-08,\n",
       " 'lambda_l2': 0.0022280155140637654,\n",
       " 'num_leaves': 4,\n",
       " 'feature_fraction': 0.41600000000000004,\n",
       " 'bagging_fraction': 0.8154283192468761,\n",
       " 'bagging_freq': 1,\n",
       " 'min_child_samples': 50,\n",
       " 'num_iterations': 20000,\n",
       " 'early_stopping_round': 100}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.params"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
