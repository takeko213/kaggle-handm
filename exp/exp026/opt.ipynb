{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# exp026"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import itertools\n",
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "sys.path.append(os.getenv('UTILS_PATH'))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import lightgbm as lgb\n",
    "from optuna.integration import lightgbm as optuna_lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import line_notify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import builtins\n",
    "import types\n",
    "\n",
    "def imports():\n",
    "    for name, val in globals().items():\n",
    "        # module imports\n",
    "        if isinstance(val, types.ModuleType):\n",
    "            yield name, val\n",
    "\n",
    "            # functions / callables\n",
    "        if hasattr(val, '__call__'):\n",
    "            yield name, val\n",
    "\n",
    "\n",
    "def noglobal(f):\n",
    "    '''\n",
    "    ref: https://gist.github.com/raven38/4e4c3c7a179283c441f575d6e375510c\n",
    "    '''\n",
    "    return types.FunctionType(f.__code__,\n",
    "                              dict(imports()),\n",
    "                              f.__name__,\n",
    "                              f.__defaults__,\n",
    "                              f.__closure__\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ディレクトリ設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIR = os.getenv('INPUT_DIR')\n",
    "OUTPUT_DIR = os.getenv('OUTPUT_DIR')\n",
    "#exp_name = os.path.dirname(__file__).split('/')[-1]\n",
    "exp_name = 'exp026'\n",
    "os.makedirs(OUTPUT_DIR + exp_name, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データ読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = pd.read_csv(INPUT_DIR + 'articles.csv', dtype='object')\n",
    "customers = pd.read_csv(INPUT_DIR + 'customers.csv')\n",
    "transactions = pd.read_csv(INPUT_DIR + 'transactions_train.csv', dtype={'article_id':'str'}, parse_dates=['t_dat'])\n",
    "sample = pd.read_csv(INPUT_DIR + 'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 名寄せ\n",
    "customers['fashion_news_frequency'] = customers['fashion_news_frequency'].str.replace('None','NONE')\n",
    "# transactionに紐づけ\n",
    "transactions = transactions.merge(customers, on='customer_id', how='left')\n",
    "transactions = transactions.merge(articles, on='article_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データセット作成（レコメンド→対象データセット作成→特徴量エンジニアリング）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@noglobal\n",
    "def get_customer_frequent(history, n=12, timedelta=None):\n",
    "    \"\"\"顧客ごと商品の購入数をカウントし上位の商品を抽出\n",
    "\n",
    "    Args:\n",
    "        history (dataframe): 集計対象の実績データ\n",
    "        n (int): レコメンド対象とする数\n",
    "        timedelta (dateutil.relativedelta): 指定された場合、実績データの終端からtimedelta分のデータを取得する\n",
    "\n",
    "    Returns:\n",
    "        dataframe: 抽出結果\n",
    "    \"\"\"\n",
    "    if timedelta is not None:\n",
    "        st_date = history['t_dat'].max() - timedelta\n",
    "        history = history[history['t_dat']>=st_date].copy()\n",
    "        \n",
    "    customer_agg = history.groupby(['customer_id', 'article_id'])['t_dat'].count().reset_index()\n",
    "    customer_agg = customer_agg.rename(columns={'t_dat':'cnt'})\n",
    "    customer_agg = customer_agg.sort_values(['customer_id', 'cnt'], ascending=False)\n",
    "    result = customer_agg.groupby('customer_id').head(n)\n",
    "    return result[['customer_id', 'article_id']]\n",
    "\n",
    "@noglobal\n",
    "def get_popular_article(history, n=12, timedelta=None):\n",
    "    \"\"\"全体の購入数をカウントし上位の商品を抽出\n",
    "\n",
    "    Args:\n",
    "        history (dataframe): 集計対象の実績データ\n",
    "        n (int): レコメンド対象とする数\n",
    "        timedelta (dateutil.relativedelta): 指定された場合、実績データの終端からtimedelta分のデータを取得する\n",
    "\n",
    "    Returns:\n",
    "        list: 抽出結果\n",
    "    \"\"\"\n",
    "    # 全体の購入数量\n",
    "    if timedelta is not None:\n",
    "        st_date = history['t_dat'].max() - timedelta\n",
    "        history = history[history['t_dat']>=st_date].copy()\n",
    "\n",
    "    total_agg = history.groupby('article_id')['t_dat'].count().reset_index()\n",
    "    total_agg = total_agg.rename(columns={'t_dat':'cnt'})\n",
    "    total_agg = total_agg.sort_values(['cnt'], ascending=False)\n",
    "    total_agg = total_agg.head(n)\n",
    "    result = list(total_agg['article_id'].values)\n",
    "    return result\n",
    "\n",
    "@noglobal\n",
    "def get_reccomend(target_customer_id, history):\n",
    "    \"\"\"対象のcustomer_idに対するレコメンド結果を返す\n",
    "\n",
    "    Args:\n",
    "        target_customer_id (list): 対象のcustomer_id\n",
    "        history (dataframe): レコメンドに用いる実績データ\n",
    "\n",
    "    Returns:\n",
    "        dataframe: レコメンド結果\n",
    "    \"\"\"\n",
    "    n = 12\n",
    "    result = pd.DataFrame()\n",
    "    \n",
    "    for td in [None, relativedelta(weeks=1), relativedelta(months=1), relativedelta(years=1)]:\n",
    "\n",
    "        customer_freq = get_customer_frequent(history, n, td)\n",
    "        popular_article = get_popular_article(history, n, td)\n",
    "        # customerとpopular articleの全組み合わせでdataframe作成\n",
    "        popular_article = pd.DataFrame(itertools.product(target_customer_id, popular_article), columns=['customer_id', 'article_id'])\n",
    "        tmp = pd.concat([customer_freq, popular_article])\n",
    "        result = result.append(tmp)\n",
    "    result = result.drop_duplicates()\n",
    "    result = result[result['customer_id'].isin(target_customer_id)].copy()\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@noglobal\n",
    "def add_labels(recom_result, history):\n",
    "    \"\"\"レコメンドしたデータが学習期間で購入されたかどうかのフラグを付与する\n",
    "\n",
    "    Args:\n",
    "        recom_result (_type_): レコメンド結果\n",
    "        train_tran (_type_): 学習期間のトランザクションデータ\n",
    "\n",
    "    Returns:\n",
    "        _type_: 学習期間での購入フラグを付与したレコメンド結果\n",
    "    \"\"\"\n",
    "    history = history[['customer_id', 'article_id']].drop_duplicates()\n",
    "    history['buy'] = 1\n",
    "    recom_result = recom_result.merge(history, on=['customer_id', 'article_id'], how='left')\n",
    "    recom_result['buy'] = recom_result['buy'].fillna(0)\n",
    "    return recom_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@noglobal\n",
    "def make_article_features(articles):\n",
    "    le_cols = ['product_type_name', 'product_group_name', 'graphical_appearance_name',\n",
    "               'colour_group_name', 'perceived_colour_value_name', 'department_name',\n",
    "               'index_name', 'index_group_name', 'section_name', 'garment_group_name']\n",
    "    for c in le_cols:\n",
    "        le = LabelEncoder()\n",
    "        articles[c] = le.fit_transform(articles[c].fillna(''))\n",
    "    return articles[['article_id']+le_cols]\n",
    "\n",
    "@noglobal\n",
    "def make_article_tran_features(history):\n",
    "    df = history.groupby('article_id').agg({'t_dat':['count', 'max', 'min'],\n",
    "                                            'price':['max', 'min', 'mean'], \n",
    "                                            'age':['max', 'min', 'mean', 'std']}).reset_index()\n",
    "    df.columns = ['article_id','article_total_cnt', 'article_total_latest_buy', 'article_total_1st_buy', 'article_price_max', 'article_price_min', 'article_price_mean', 'article_age_max', 'article_age_min', 'article_age_mean', 'article_age_std']\n",
    "    df['article_total_1st_buy'] = (history['t_dat'].max() - df['article_total_1st_buy']).dt.days\n",
    "    df['article_total_latest_buy'] = (history['t_dat'].max() - df['article_total_latest_buy']).dt.days\n",
    "    return df\n",
    "\n",
    "\n",
    "@noglobal\n",
    "def make_customer_features(customers):\n",
    "    le_cols = ['club_member_status', 'fashion_news_frequency', 'postal_code']\n",
    "    for c in le_cols:\n",
    "        le = LabelEncoder()\n",
    "        customers[c] = le.fit_transform(customers[c].fillna(''))\n",
    "    return customers\n",
    "\n",
    "@noglobal\n",
    "def make_customer_tran_features(history):\n",
    "    df = history.groupby('customer_id').agg({'t_dat':['count', 'max', 'min'],\n",
    "                                            'price':['max', 'min', 'mean']}).reset_index()\n",
    "    df.columns = ['customer_id','customer_total_cnt', 'customer_total_latest_buy', 'customer_total_1st_buy', 'customer_price_max', 'customer_price_min', 'customer_price_mean']\n",
    "    df['customer_total_1st_buy'] = (history['t_dat'].max() - df['customer_total_1st_buy']).dt.days\n",
    "    df['customer_total_latest_buy'] = (history['t_dat'].max() - df['customer_total_latest_buy']).dt.days\n",
    "    return df\n",
    "\n",
    "@noglobal\n",
    "def make_customer_article_features(target, history):\n",
    "    df = target.merge(history, on=['customer_id', 'article_id'], how='inner')\n",
    "    df = df.groupby(['customer_id', 'article_id']).agg({'t_dat':['count', 'min', 'max']}).reset_index()\n",
    "    df.columns = ['customer_id', 'article_id', 'count', '1st_buy_date_diff', 'latest_buy_date_diff']\n",
    "    df['1st_buy_date_diff'] = (history['t_dat'].max() - df['1st_buy_date_diff']).dt.days\n",
    "    df['latest_buy_date_diff'] = (history['t_dat'].max() - df['latest_buy_date_diff']).dt.days\n",
    "    return df\n",
    "\n",
    "@noglobal\n",
    "def add_features(df, history, articles, customers):\n",
    "    article_features = make_article_features(articles)\n",
    "    article_tran_features = make_article_tran_features(history)\n",
    "    customer_features = make_customer_features(customers)\n",
    "    customer_tran_features = make_customer_tran_features(history)\n",
    "    customer_article_features = make_customer_article_features(df[['customer_id', 'article_id']], history)\n",
    "\n",
    "    df = df.merge(article_features, on=['article_id'], how='left')\n",
    "    df = df.merge(article_tran_features, on=['article_id'], how='left')\n",
    "    df = df.merge(customer_features, on=['customer_id'], how='left')\n",
    "    df = df.merge(customer_tran_features, on=['customer_id'], how='left')\n",
    "    df = df.merge(customer_article_features, on=['article_id', 'customer_id'], how='left')\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# テストデータの作成\n",
    "target_id = sample['customer_id'].tolist()\n",
    "recom = get_reccomend(target_id, transactions)\n",
    "ml_test = add_features(recom, transactions, articles, customers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# レコメンド商品を購入するかどうかの2値分類モデル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apk(y_true, y_pred, K=12):\n",
    "    assert(len(y_true) == len(y_pred))\n",
    "    apks = []\n",
    "    for idx in range(len(y_true)):\n",
    "        y_i_true = y_true[idx]\n",
    "        y_i_pred = y_pred[idx]\n",
    "\n",
    "        # 予測値の数と重複の確認\n",
    "        assert(len(y_i_pred) <= K)\n",
    "        assert(len(np.unique(y_i_pred)) == len(y_i_pred))\n",
    "\n",
    "        sum_precision = 0.0\n",
    "        num_hits = 0.0\n",
    "\n",
    "        for i, p in enumerate(y_i_pred):\n",
    "            if p in y_i_true:\n",
    "                num_hits += 1\n",
    "                precision = num_hits / (i+1)\n",
    "                sum_precision += precision\n",
    "        apk = sum_precision / min(len(y_i_true), K)\n",
    "        apks.append(apk)\n",
    "    return apks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'buy'\n",
    "not_use_cols = ['customer_id', 'article_id', target]\n",
    "features = [c for c in ml_test.columns if c not in not_use_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"objective\": \"binary\",\n",
    "    \"boosting\" : \"gbdt\",\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"metric\": \"binary_logloss\",\n",
    "    \"seed\": SEED\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-23 11:25:07,260]\u001b[0m A new study created in memory with name: no-name-177cca2b-4309-4399-acc5-aabca976b252\u001b[0m\n",
      "feature_fraction, val_score: inf:   0%|          | 0/7 [00:00<?, ?it/s]/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.104924 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4864\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\tvalid_0's binary_logloss: 0.0215707\tvalid_1's binary_logloss: 0.0244567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.024419:  14%|#4        | 1/7 [02:17<13:45, 137.57s/it]\u001b[32m[I 2022-02-23 11:27:24,834]\u001b[0m Trial 0 finished with value: 0.024419216297994664 and parameters: {'feature_fraction': 0.7}. Best is trial 0 with value: 0.024419216297994664.\u001b[0m\n",
      "feature_fraction, val_score: 0.024419:  14%|#4        | 1/7 [02:17<13:45, 137.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1693]\tvalid_0's binary_logloss: 0.0207474\tvalid_1's binary_logloss: 0.0244192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.072707 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4864\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\tvalid_0's binary_logloss: 0.0215907\tvalid_1's binary_logloss: 0.024435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.024419:  29%|##8       | 2/7 [03:46<09:03, 108.70s/it]\u001b[32m[I 2022-02-23 11:28:53,326]\u001b[0m Trial 1 finished with value: 0.024431407570134532 and parameters: {'feature_fraction': 0.6}. Best is trial 0 with value: 0.024419216297994664.\u001b[0m\n",
      "feature_fraction, val_score: 0.024419:  29%|##8       | 2/7 [03:46<09:03, 108.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1134]\tvalid_0's binary_logloss: 0.0214201\tvalid_1's binary_logloss: 0.0244314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.103049 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4864\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.024419:  43%|####2     | 3/7 [04:56<06:04, 91.02s/it] \u001b[32m[I 2022-02-23 11:30:03,315]\u001b[0m Trial 2 finished with value: 0.02445313272777726 and parameters: {'feature_fraction': 1.0}. Best is trial 0 with value: 0.024419216297994664.\u001b[0m\n",
      "feature_fraction, val_score: 0.024419:  43%|####2     | 3/7 [04:56<06:04, 91.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[811]\tvalid_0's binary_logloss: 0.021804\tvalid_1's binary_logloss: 0.0244531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.062471 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4864\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\tvalid_0's binary_logloss: 0.021698\tvalid_1's binary_logloss: 0.0244234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.024419:  57%|#####7    | 4/7 [06:09<04:12, 84.21s/it]\u001b[32m[I 2022-02-23 11:31:17,070]\u001b[0m Trial 3 finished with value: 0.024421568809689674 and parameters: {'feature_fraction': 0.4}. Best is trial 0 with value: 0.024419216297994664.\u001b[0m\n",
      "feature_fraction, val_score: 0.024419:  57%|#####7    | 4/7 [06:09<04:12, 84.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1032]\tvalid_0's binary_logloss: 0.0216597\tvalid_1's binary_logloss: 0.0244216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.339508 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4864\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\tvalid_0's binary_logloss: 0.0215431\tvalid_1's binary_logloss: 0.0244406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.024419:  71%|#######1  | 5/7 [08:03<03:09, 94.75s/it]\u001b[32m[I 2022-02-23 11:33:10,518]\u001b[0m Trial 4 finished with value: 0.024425477711968967 and parameters: {'feature_fraction': 0.8}. Best is trial 0 with value: 0.024419216297994664.\u001b[0m\n",
      "feature_fraction, val_score: 0.024419:  71%|#######1  | 5/7 [08:03<03:09, 94.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1255]\tvalid_0's binary_logloss: 0.0212352\tvalid_1's binary_logloss: 0.0244255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.092494 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4864\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\tvalid_0's binary_logloss: 0.0215132\tvalid_1's binary_logloss: 0.0244498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.024419:  86%|########5 | 6/7 [09:41<01:35, 95.84s/it]\u001b[32m[I 2022-02-23 11:34:48,478]\u001b[0m Trial 5 finished with value: 0.024438748385271918 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 0 with value: 0.024419216297994664.\u001b[0m\n",
      "feature_fraction, val_score: 0.024419:  86%|########5 | 6/7 [09:41<01:35, 95.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1300]\tvalid_0's binary_logloss: 0.0211387\tvalid_1's binary_logloss: 0.0244387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.311866 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4864\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\tvalid_0's binary_logloss: 0.0216316\tvalid_1's binary_logloss: 0.0244466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.024419: 100%|##########| 7/7 [11:08<00:00, 93.18s/it]\u001b[32m[I 2022-02-23 11:36:16,164]\u001b[0m Trial 6 finished with value: 0.0244448161551729 and parameters: {'feature_fraction': 0.5}. Best is trial 0 with value: 0.024419216297994664.\u001b[0m\n",
      "feature_fraction, val_score: 0.024419: 100%|##########| 7/7 [11:08<00:00, 95.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[926]\tvalid_0's binary_logloss: 0.0217233\tvalid_1's binary_logloss: 0.0244448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.024419:   0%|          | 0/20 [00:00<?, ?it/s]/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.346488 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4864\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.024419:   5%|5         | 1/20 [01:23<26:32, 83.83s/it]\u001b[32m[I 2022-02-23 11:37:39,999]\u001b[0m Trial 7 finished with value: 0.024423360844425448 and parameters: {'num_leaves': 163}. Best is trial 7 with value: 0.024423360844425448.\u001b[0m\n",
      "num_leaves, val_score: 0.024419:   5%|5         | 1/20 [01:23<26:32, 83.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[553]\tvalid_0's binary_logloss: 0.01818\tvalid_1's binary_logloss: 0.0244234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.350464 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4864\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.024419:  10%|#         | 2/20 [02:45<24:49, 82.78s/it]\u001b[32m[I 2022-02-23 11:39:02,037]\u001b[0m Trial 8 finished with value: 0.02442369925915596 and parameters: {'num_leaves': 43}. Best is trial 7 with value: 0.024423360844425448.\u001b[0m\n",
      "num_leaves, val_score: 0.024419:  10%|#         | 2/20 [02:45<24:49, 82.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[725]\tvalid_0's binary_logloss: 0.0214068\tvalid_1's binary_logloss: 0.0244237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.348008 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4864\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.024393:  15%|#5        | 3/20 [04:14<24:12, 85.45s/it]\u001b[32m[I 2022-02-23 11:40:30,673]\u001b[0m Trial 9 finished with value: 0.024392927278511032 and parameters: {'num_leaves': 175}. Best is trial 9 with value: 0.024392927278511032.\u001b[0m\n",
      "num_leaves, val_score: 0.024393:  15%|#5        | 3/20 [04:14<24:12, 85.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[575]\tvalid_0's binary_logloss: 0.0177775\tvalid_1's binary_logloss: 0.0243929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.092806 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4864\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\tvalid_0's binary_logloss: 0.0234941\tvalid_1's binary_logloss: 0.0247594\n",
      "[2000]\tvalid_0's binary_logloss: 0.0232396\tvalid_1's binary_logloss: 0.0246173\n",
      "[3000]\tvalid_0's binary_logloss: 0.0230892\tvalid_1's binary_logloss: 0.0245387\n",
      "[4000]\tvalid_0's binary_logloss: 0.0229778\tvalid_1's binary_logloss: 0.0245073\n",
      "[5000]\tvalid_0's binary_logloss: 0.0228811\tvalid_1's binary_logloss: 0.0244882\n",
      "[6000]\tvalid_0's binary_logloss: 0.0227995\tvalid_1's binary_logloss: 0.0244677\n",
      "[7000]\tvalid_0's binary_logloss: 0.0227277\tvalid_1's binary_logloss: 0.0244549\n",
      "[8000]\tvalid_0's binary_logloss: 0.02266\tvalid_1's binary_logloss: 0.0244447\n",
      "[9000]\tvalid_0's binary_logloss: 0.0225985\tvalid_1's binary_logloss: 0.0244387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.024393:  20%|##        | 4/20 [12:05<1:03:19, 237.47s/it]\u001b[32m[I 2022-02-23 11:48:21,191]\u001b[0m Trial 10 finished with value: 0.024430856410499684 and parameters: {'num_leaves': 4}. Best is trial 9 with value: 0.024392927278511032.\u001b[0m\n",
      "num_leaves, val_score: 0.024393:  20%|##        | 4/20 [12:05<1:03:19, 237.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[9564]\tvalid_0's binary_logloss: 0.0225631\tvalid_1's binary_logloss: 0.0244309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.091120 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4864\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.024393:  25%|##5       | 5/20 [13:26<45:18, 181.21s/it]  \u001b[32m[I 2022-02-23 11:49:42,637]\u001b[0m Trial 11 finished with value: 0.02439436801072206 and parameters: {'num_leaves': 235}. Best is trial 9 with value: 0.024392927278511032.\u001b[0m\n",
      "num_leaves, val_score: 0.024393:  25%|##5       | 5/20 [13:26<45:18, 181.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[547]\tvalid_0's binary_logloss: 0.0166086\tvalid_1's binary_logloss: 0.0243944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.092756 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4864\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.024393:  30%|###       | 6/20 [14:44<34:05, 146.12s/it]\u001b[32m[I 2022-02-23 11:51:00,639]\u001b[0m Trial 12 finished with value: 0.024411255548268132 and parameters: {'num_leaves': 191}. Best is trial 9 with value: 0.024392927278511032.\u001b[0m\n",
      "num_leaves, val_score: 0.024393:  30%|###       | 6/20 [14:44<34:05, 146.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[555]\tvalid_0's binary_logloss: 0.0175005\tvalid_1's binary_logloss: 0.0244113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.339518 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4864\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.024393:  35%|###5      | 7/20 [16:20<28:04, 129.59s/it]\u001b[32m[I 2022-02-23 11:52:36,188]\u001b[0m Trial 13 finished with value: 0.024436447599428514 and parameters: {'num_leaves': 247}. Best is trial 9 with value: 0.024392927278511032.\u001b[0m\n",
      "num_leaves, val_score: 0.024393:  35%|###5      | 7/20 [16:20<28:04, 129.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[581]\tvalid_0's binary_logloss: 0.0161557\tvalid_1's binary_logloss: 0.0244364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.357763 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4864\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\tvalid_0's binary_logloss: 0.0203863\tvalid_1's binary_logloss: 0.0244068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.024393:  40%|####      | 8/20 [18:00<24:02, 120.18s/it]\u001b[32m[I 2022-02-23 11:54:16,232]\u001b[0m Trial 14 finished with value: 0.02440447588316906 and parameters: {'num_leaves': 55}. Best is trial 9 with value: 0.024392927278511032.\u001b[0m\n",
      "num_leaves, val_score: 0.024393:  40%|####      | 8/20 [18:00<24:02, 120.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[962]\tvalid_0's binary_logloss: 0.0204649\tvalid_1's binary_logloss: 0.0244045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.343199 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4864\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.024393:  45%|####5     | 9/20 [19:34<20:33, 112.15s/it]\u001b[32m[I 2022-02-23 11:55:50,710]\u001b[0m Trial 15 finished with value: 0.02440422630077587 and parameters: {'num_leaves': 133}. Best is trial 9 with value: 0.024392927278511032.\u001b[0m\n",
      "num_leaves, val_score: 0.024393:  45%|####5     | 9/20 [19:34<20:33, 112.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[675]\tvalid_0's binary_logloss: 0.0184774\tvalid_1's binary_logloss: 0.0244042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.337205 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4864\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.024393:  50%|#####     | 10/20 [20:59<17:18, 103.88s/it]\u001b[32m[I 2022-02-23 11:57:16,094]\u001b[0m Trial 16 finished with value: 0.024402590335897895 and parameters: {'num_leaves': 198}. Best is trial 9 with value: 0.024392927278511032.\u001b[0m\n",
      "num_leaves, val_score: 0.024393:  50%|#####     | 10/20 [20:59<17:18, 103.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[508]\tvalid_0's binary_logloss: 0.0176211\tvalid_1's binary_logloss: 0.0244026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.337883 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4864\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.024368:  55%|#####5    | 11/20 [22:22<14:36, 97.41s/it] \u001b[32m[I 2022-02-23 11:58:38,831]\u001b[0m Trial 17 finished with value: 0.024368176909803013 and parameters: {'num_leaves': 100}. Best is trial 17 with value: 0.024368176909803013.\u001b[0m\n",
      "num_leaves, val_score: 0.024368:  55%|#####5    | 11/20 [22:22<14:36, 97.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[597]\tvalid_0's binary_logloss: 0.0197127\tvalid_1's binary_logloss: 0.0243682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.093642 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4864\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.024368:  60%|######    | 12/20 [23:29<11:44, 88.04s/it]\u001b[32m[I 2022-02-23 11:59:45,428]\u001b[0m Trial 18 finished with value: 0.02439462153106917 and parameters: {'num_leaves': 105}. Best is trial 17 with value: 0.024368176909803013.\u001b[0m\n",
      "num_leaves, val_score: 0.024368:  60%|######    | 12/20 [23:29<11:44, 88.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[551]\tvalid_0's binary_logloss: 0.0197096\tvalid_1's binary_logloss: 0.0243946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.341099 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4864\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.024368:  65%|######5   | 13/20 [24:48<09:58, 85.43s/it]\u001b[32m[I 2022-02-23 12:01:04,859]\u001b[0m Trial 19 finished with value: 0.02438050943020348 and parameters: {'num_leaves': 104}. Best is trial 17 with value: 0.024368176909803013.\u001b[0m\n",
      "num_leaves, val_score: 0.024368:  65%|######5   | 13/20 [24:48<09:58, 85.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[567]\tvalid_0's binary_logloss: 0.0196914\tvalid_1's binary_logloss: 0.0243805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.342359 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4864\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.024368:  70%|#######   | 14/20 [26:22<08:47, 88.00s/it]\u001b[32m[I 2022-02-23 12:02:38,796]\u001b[0m Trial 20 finished with value: 0.0243885304550499 and parameters: {'num_leaves': 96}. Best is trial 17 with value: 0.024368176909803013.\u001b[0m\n",
      "num_leaves, val_score: 0.024368:  70%|#######   | 14/20 [26:22<08:47, 88.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[744]\tvalid_0's binary_logloss: 0.0193542\tvalid_1's binary_logloss: 0.0243885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.346499 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4864\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.024368:  75%|#######5  | 15/20 [27:47<07:14, 86.99s/it]\u001b[32m[I 2022-02-23 12:04:03,452]\u001b[0m Trial 21 finished with value: 0.02440424187915946 and parameters: {'num_leaves': 77}. Best is trial 17 with value: 0.024368176909803013.\u001b[0m\n",
      "num_leaves, val_score: 0.024368:  75%|#######5  | 15/20 [27:47<07:14, 86.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[671]\tvalid_0's binary_logloss: 0.0202076\tvalid_1's binary_logloss: 0.0244042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.089776 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4864\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.024368:  80%|########  | 16/20 [28:59<05:30, 82.60s/it]\u001b[32m[I 2022-02-23 12:05:15,855]\u001b[0m Trial 22 finished with value: 0.024406115246554692 and parameters: {'num_leaves': 123}. Best is trial 17 with value: 0.024368176909803013.\u001b[0m\n",
      "num_leaves, val_score: 0.024368:  80%|########  | 16/20 [28:59<05:30, 82.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[590]\tvalid_0's binary_logloss: 0.019094\tvalid_1's binary_logloss: 0.0244061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.343179 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4864\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.024368:  85%|########5 | 17/20 [30:33<04:17, 85.98s/it]\u001b[32m[I 2022-02-23 12:06:49,698]\u001b[0m Trial 23 finished with value: 0.024397774974191933 and parameters: {'num_leaves': 148}. Best is trial 17 with value: 0.024368176909803013.\u001b[0m\n",
      "num_leaves, val_score: 0.024368:  85%|########5 | 17/20 [30:33<04:17, 85.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[643]\tvalid_0's binary_logloss: 0.0181795\tvalid_1's binary_logloss: 0.0243978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.089857 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4864\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.024368:  90%|######### | 18/20 [31:42<02:41, 80.97s/it]\u001b[32m[I 2022-02-23 12:07:58,988]\u001b[0m Trial 24 finished with value: 0.024499348258796617 and parameters: {'num_leaves': 24}. Best is trial 17 with value: 0.024368176909803013.\u001b[0m\n",
      "num_leaves, val_score: 0.024368:  90%|######### | 18/20 [31:42<02:41, 80.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[838]\tvalid_0's binary_logloss: 0.0221519\tvalid_1's binary_logloss: 0.0244993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.348732 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4864\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.024368:  95%|#########5| 19/20 [33:09<01:22, 82.63s/it]\u001b[32m[I 2022-02-23 12:09:25,482]\u001b[0m Trial 25 finished with value: 0.02440424187915946 and parameters: {'num_leaves': 77}. Best is trial 17 with value: 0.024368176909803013.\u001b[0m\n",
      "num_leaves, val_score: 0.024368:  95%|#########5| 19/20 [33:09<01:22, 82.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[671]\tvalid_0's binary_logloss: 0.0202076\tvalid_1's binary_logloss: 0.0244042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.349073 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4864\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.024368: 100%|##########| 20/20 [34:31<00:00, 82.43s/it]\u001b[32m[I 2022-02-23 12:10:47,469]\u001b[0m Trial 26 finished with value: 0.02437900408190972 and parameters: {'num_leaves': 120}. Best is trial 17 with value: 0.024368176909803013.\u001b[0m\n",
      "num_leaves, val_score: 0.024368: 100%|##########| 20/20 [34:31<00:00, 103.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[553]\tvalid_0's binary_logloss: 0.0192978\tvalid_1's binary_logloss: 0.024379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.024368:   0%|          | 0/10 [00:00<?, ?it/s]/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.335608 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4864\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.024342:  10%|#         | 1/10 [01:32<13:49, 92.18s/it]\u001b[32m[I 2022-02-23 12:12:19,658]\u001b[0m Trial 27 finished with value: 0.02434247609211936 and parameters: {'bagging_fraction': 0.7235734670479185, 'bagging_freq': 1}. Best is trial 27 with value: 0.02434247609211936.\u001b[0m\n",
      "bagging, val_score: 0.024342:  10%|#         | 1/10 [01:32<13:49, 92.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[750]\tvalid_0's binary_logloss: 0.0188549\tvalid_1's binary_logloss: 0.0243425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.342600 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4864\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.024342:  20%|##        | 2/10 [03:05<12:22, 92.81s/it]\u001b[32m[I 2022-02-23 12:13:52,902]\u001b[0m Trial 28 finished with value: 0.02435109787302415 and parameters: {'bagging_fraction': 0.6009066611077654, 'bagging_freq': 1}. Best is trial 27 with value: 0.02434247609211936.\u001b[0m\n",
      "bagging, val_score: 0.024342:  20%|##        | 2/10 [03:05<12:22, 92.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[869]\tvalid_0's binary_logloss: 0.018283\tvalid_1's binary_logloss: 0.0243511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.338043 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4864\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.024342:  30%|###       | 3/10 [04:12<09:26, 80.89s/it]\u001b[32m[I 2022-02-23 12:14:59,613]\u001b[0m Trial 29 finished with value: 0.024385840860172876 and parameters: {'bagging_fraction': 0.49206865364722224, 'bagging_freq': 2}. Best is trial 27 with value: 0.02434247609211936.\u001b[0m\n",
      "bagging, val_score: 0.024342:  30%|###       | 3/10 [04:12<09:26, 80.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[668]\tvalid_0's binary_logloss: 0.0190355\tvalid_1's binary_logloss: 0.0243858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.351146 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4864\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.024342:  40%|####      | 4/10 [05:39<08:21, 83.55s/it]\u001b[32m[I 2022-02-23 12:16:27,240]\u001b[0m Trial 30 finished with value: 0.02443995819023783 and parameters: {'bagging_fraction': 0.6093307355472419, 'bagging_freq': 6}. Best is trial 27 with value: 0.02434247609211936.\u001b[0m\n",
      "bagging, val_score: 0.024342:  40%|####      | 4/10 [05:39<08:21, 83.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[894]\tvalid_0's binary_logloss: 0.0182345\tvalid_1's binary_logloss: 0.02444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.098750 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4864\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.024342:  50%|#####     | 5/10 [06:48<06:30, 78.15s/it]\u001b[32m[I 2022-02-23 12:17:35,815]\u001b[0m Trial 31 finished with value: 0.024368432989062844 and parameters: {'bagging_fraction': 0.8511710583480203, 'bagging_freq': 5}. Best is trial 27 with value: 0.02434247609211936.\u001b[0m\n",
      "bagging, val_score: 0.024342:  50%|#####     | 5/10 [06:48<06:30, 78.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[551]\tvalid_0's binary_logloss: 0.0197349\tvalid_1's binary_logloss: 0.0243684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.087534 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4864\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.024342:  60%|######    | 6/10 [07:56<04:58, 74.60s/it]\u001b[32m[I 2022-02-23 12:18:43,532]\u001b[0m Trial 32 finished with value: 0.024358658527162805 and parameters: {'bagging_fraction': 0.6988151714601163, 'bagging_freq': 6}. Best is trial 27 with value: 0.02434247609211936.\u001b[0m\n",
      "bagging, val_score: 0.024342:  60%|######    | 6/10 [07:56<04:58, 74.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[633]\tvalid_0's binary_logloss: 0.0193202\tvalid_1's binary_logloss: 0.0243587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.091935 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4864\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.024342:  70%|#######   | 7/10 [09:14<03:47, 75.78s/it]\u001b[32m[I 2022-02-23 12:20:01,734]\u001b[0m Trial 33 finished with value: 0.02435062295860429 and parameters: {'bagging_fraction': 0.6836070828146776, 'bagging_freq': 4}. Best is trial 27 with value: 0.02434247609211936.\u001b[0m\n",
      "bagging, val_score: 0.024342:  70%|#######   | 7/10 [09:14<03:47, 75.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[802]\tvalid_0's binary_logloss: 0.0186384\tvalid_1's binary_logloss: 0.0243506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.340246 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4864\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.024342:  80%|########  | 8/10 [10:35<02:34, 77.44s/it]\u001b[32m[I 2022-02-23 12:21:22,725]\u001b[0m Trial 34 finished with value: 0.024382888258661382 and parameters: {'bagging_fraction': 0.7539676448595583, 'bagging_freq': 7}. Best is trial 27 with value: 0.02434247609211936.\u001b[0m\n",
      "bagging, val_score: 0.024342:  80%|########  | 8/10 [10:35<02:34, 77.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[640]\tvalid_0's binary_logloss: 0.0193176\tvalid_1's binary_logloss: 0.0243829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.340030 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4864\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.024342:  90%|######### | 9/10 [12:19<01:25, 85.77s/it]\u001b[32m[I 2022-02-23 12:23:06,829]\u001b[0m Trial 35 finished with value: 0.024405820956094962 and parameters: {'bagging_fraction': 0.7879897575656343, 'bagging_freq': 3}. Best is trial 27 with value: 0.02434247609211936.\u001b[0m\n",
      "bagging, val_score: 0.024342:  90%|######### | 9/10 [12:19<01:25, 85.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[770]\tvalid_0's binary_logloss: 0.0187979\tvalid_1's binary_logloss: 0.0244058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.092965 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4864\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.024342: 100%|##########| 10/10 [13:41<00:00, 84.75s/it]\u001b[32m[I 2022-02-23 12:24:29,273]\u001b[0m Trial 36 finished with value: 0.024419759429573556 and parameters: {'bagging_fraction': 0.5475997995869051, 'bagging_freq': 2}. Best is trial 27 with value: 0.02434247609211936.\u001b[0m\n",
      "bagging, val_score: 0.024342: 100%|##########| 10/10 [13:41<00:00, 82.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[843]\tvalid_0's binary_logloss: 0.0183587\tvalid_1's binary_logloss: 0.0244198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.024342:   0%|          | 0/6 [00:00<?, ?it/s]/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.108354 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4864\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.024342:  17%|#6        | 1/6 [01:25<07:06, 85.25s/it]\u001b[32m[I 2022-02-23 12:25:54,534]\u001b[0m Trial 37 finished with value: 0.024391909248331036 and parameters: {'feature_fraction': 0.7799999999999999}. Best is trial 37 with value: 0.024391909248331036.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.024342:  17%|#6        | 1/6 [01:25<07:06, 85.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[842]\tvalid_0's binary_logloss: 0.0184363\tvalid_1's binary_logloss: 0.0243919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.087816 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4864\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.024342:  33%|###3      | 2/6 [02:47<05:32, 83.23s/it]\u001b[32m[I 2022-02-23 12:27:16,340]\u001b[0m Trial 38 finished with value: 0.0243745730072653 and parameters: {'feature_fraction': 0.748}. Best is trial 38 with value: 0.0243745730072653.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.024342:  33%|###3      | 2/6 [02:47<05:32, 83.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[824]\tvalid_0's binary_logloss: 0.01852\tvalid_1's binary_logloss: 0.0243746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.332771 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4864\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.024342:  50%|#####     | 3/6 [04:09<04:08, 82.73s/it]\u001b[32m[I 2022-02-23 12:28:38,482]\u001b[0m Trial 39 finished with value: 0.02437220387733463 and parameters: {'feature_fraction': 0.652}. Best is trial 39 with value: 0.02437220387733463.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.024342:  50%|#####     | 3/6 [04:09<04:08, 82.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[671]\tvalid_0's binary_logloss: 0.0192089\tvalid_1's binary_logloss: 0.0243722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.354283 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4864\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.024342:  67%|######6   | 4/6 [05:44<02:55, 87.86s/it]\u001b[32m[I 2022-02-23 12:30:14,209]\u001b[0m Trial 40 finished with value: 0.024356768262204228 and parameters: {'feature_fraction': 0.6839999999999999}. Best is trial 40 with value: 0.024356768262204228.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.024342:  67%|######6   | 4/6 [05:44<02:55, 87.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[781]\tvalid_0's binary_logloss: 0.0187566\tvalid_1's binary_logloss: 0.0243568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.336856 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4864\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.024342:  83%|########3 | 5/6 [07:15<01:28, 88.90s/it]\u001b[32m[I 2022-02-23 12:31:44,957]\u001b[0m Trial 41 finished with value: 0.024408253245012803 and parameters: {'feature_fraction': 0.62}. Best is trial 40 with value: 0.024356768262204228.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.024342:  83%|########3 | 5/6 [07:15<01:28, 88.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[750]\tvalid_0's binary_logloss: 0.0189501\tvalid_1's binary_logloss: 0.0244083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.346803 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4864\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.024342: 100%|##########| 6/6 [08:45<00:00, 89.30s/it]\u001b[32m[I 2022-02-23 12:33:15,015]\u001b[0m Trial 42 finished with value: 0.024342476092119363 and parameters: {'feature_fraction': 0.716}. Best is trial 42 with value: 0.024342476092119363.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.024342: 100%|##########| 6/6 [08:45<00:00, 87.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[750]\tvalid_0's binary_logloss: 0.0188549\tvalid_1's binary_logloss: 0.0243425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.024342:   0%|          | 0/20 [00:00<?, ?it/s]/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.092438 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4864\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.024342:   5%|5         | 1/20 [01:18<24:47, 78.29s/it]\u001b[32m[I 2022-02-23 12:34:33,310]\u001b[0m Trial 43 finished with value: 0.02434970723600465 and parameters: {'lambda_l1': 0.004976801386049323, 'lambda_l2': 3.6975737730464346e-07}. Best is trial 43 with value: 0.02434970723600465.\u001b[0m\n",
      "regularization_factors, val_score: 0.024342:   5%|5         | 1/20 [01:18<24:47, 78.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[771]\tvalid_0's binary_logloss: 0.0187689\tvalid_1's binary_logloss: 0.0243497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.338354 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4864\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.024342:  10%|#         | 2/20 [02:52<26:22, 87.93s/it]\u001b[32m[I 2022-02-23 12:36:07,988]\u001b[0m Trial 44 finished with value: 0.024363917829280157 and parameters: {'lambda_l1': 1.705898979238511e-07, 'lambda_l2': 1.000034951470484e-07}. Best is trial 43 with value: 0.02434970723600465.\u001b[0m\n",
      "regularization_factors, val_score: 0.024342:  10%|#         | 2/20 [02:52<26:22, 87.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[751]\tvalid_0's binary_logloss: 0.0188456\tvalid_1's binary_logloss: 0.0243639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.098880 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4864\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.024332:  15%|#5        | 3/20 [04:09<23:30, 82.95s/it]\u001b[32m[I 2022-02-23 12:37:25,005]\u001b[0m Trial 45 finished with value: 0.02433211996489611 and parameters: {'lambda_l1': 5.506472853480445e-06, 'lambda_l2': 0.02504859156083246}. Best is trial 45 with value: 0.02433211996489611.\u001b[0m\n",
      "regularization_factors, val_score: 0.024332:  15%|#5        | 3/20 [04:09<23:30, 82.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[784]\tvalid_0's binary_logloss: 0.0190265\tvalid_1's binary_logloss: 0.0243321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.355764 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4864\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.024332:  20%|##        | 4/20 [05:56<24:39, 92.44s/it]\u001b[32m[I 2022-02-23 12:39:11,992]\u001b[0m Trial 46 finished with value: 0.024397189515499653 and parameters: {'lambda_l1': 0.9086148802067959, 'lambda_l2': 2.912818501880647e-07}. Best is trial 45 with value: 0.02433211996489611.\u001b[0m\n",
      "regularization_factors, val_score: 0.024332:  20%|##        | 4/20 [05:56<24:39, 92.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[852]\tvalid_0's binary_logloss: 0.0189324\tvalid_1's binary_logloss: 0.0243972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.089796 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4864\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.024332:  25%|##5       | 5/20 [07:10<21:22, 85.49s/it]\u001b[32m[I 2022-02-23 12:40:25,152]\u001b[0m Trial 47 finished with value: 0.02435414748880942 and parameters: {'lambda_l1': 0.026607587591229078, 'lambda_l2': 1.0288719996065516e-07}. Best is trial 45 with value: 0.02433211996489611.\u001b[0m\n",
      "regularization_factors, val_score: 0.024332:  25%|##5       | 5/20 [07:10<21:22, 85.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[690]\tvalid_0's binary_logloss: 0.0190856\tvalid_1's binary_logloss: 0.0243541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.092988 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4864\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.024328:  30%|###       | 6/20 [08:27<19:20, 82.88s/it]\u001b[32m[I 2022-02-23 12:41:42,972]\u001b[0m Trial 48 finished with value: 0.024328416353054803 and parameters: {'lambda_l1': 2.652545580792273e-07, 'lambda_l2': 4.127044972448657e-07}. Best is trial 48 with value: 0.024328416353054803.\u001b[0m\n",
      "regularization_factors, val_score: 0.024328:  30%|###       | 6/20 [08:27<19:20, 82.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[764]\tvalid_0's binary_logloss: 0.0187971\tvalid_1's binary_logloss: 0.0243284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.340901 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4864\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.024328:  35%|###5      | 7/20 [10:03<18:50, 86.95s/it]\u001b[32m[I 2022-02-23 12:43:18,293]\u001b[0m Trial 49 finished with value: 0.02433128511719284 and parameters: {'lambda_l1': 9.280465055709417e-05, 'lambda_l2': 0.011513663296755959}. Best is trial 48 with value: 0.024328416353054803.\u001b[0m\n",
      "regularization_factors, val_score: 0.024328:  35%|###5      | 7/20 [10:03<18:50, 86.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[791]\tvalid_0's binary_logloss: 0.0188719\tvalid_1's binary_logloss: 0.0243313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.341139 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4864\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.024328:  40%|####      | 8/20 [11:35<17:41, 88.48s/it]\u001b[32m[I 2022-02-23 12:44:50,048]\u001b[0m Trial 50 finished with value: 0.024342127426292978 and parameters: {'lambda_l1': 0.01601041121120325, 'lambda_l2': 0.002257086288892145}. Best is trial 48 with value: 0.024328416353054803.\u001b[0m\n",
      "regularization_factors, val_score: 0.024328:  40%|####      | 8/20 [11:35<17:41, 88.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[750]\tvalid_0's binary_logloss: 0.0188723\tvalid_1's binary_logloss: 0.0243421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.097383 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4864\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.024328:  45%|####5     | 9/20 [12:52<15:35, 85.01s/it]\u001b[32m[I 2022-02-23 12:46:07,443]\u001b[0m Trial 51 finished with value: 0.024364980720272093 and parameters: {'lambda_l1': 1.3743690946107495e-07, 'lambda_l2': 9.232734394855335e-06}. Best is trial 48 with value: 0.024328416353054803.\u001b[0m\n",
      "regularization_factors, val_score: 0.024328:  45%|####5     | 9/20 [12:52<15:35, 85.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[751]\tvalid_0's binary_logloss: 0.0188321\tvalid_1's binary_logloss: 0.024365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.090829 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4864\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.024328:  50%|#####     | 10/20 [14:24<14:30, 87.05s/it]\u001b[32m[I 2022-02-23 12:47:39,046]\u001b[0m Trial 52 finished with value: 0.024416877246554003 and parameters: {'lambda_l1': 0.0036000975371223744, 'lambda_l2': 1.8758095950132456}. Best is trial 48 with value: 0.024328416353054803.\u001b[0m\n",
      "regularization_factors, val_score: 0.024328:  50%|#####     | 10/20 [14:24<14:30, 87.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[807]\tvalid_0's binary_logloss: 0.0208153\tvalid_1's binary_logloss: 0.0244169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.096893 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4864\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.024328:  55%|#####5    | 11/20 [15:46<12:49, 85.51s/it]\u001b[32m[I 2022-02-23 12:49:01,079]\u001b[0m Trial 53 finished with value: 0.024358359927866308 and parameters: {'lambda_l1': 7.569917733590331e-06, 'lambda_l2': 3.54225778149218e-05}. Best is trial 48 with value: 0.024328416353054803.\u001b[0m\n",
      "regularization_factors, val_score: 0.024328:  55%|#####5    | 11/20 [15:46<12:49, 85.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[820]\tvalid_0's binary_logloss: 0.0186024\tvalid_1's binary_logloss: 0.0243584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.095082 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4864\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.024328:  60%|######    | 12/20 [17:13<11:29, 86.20s/it]\u001b[32m[I 2022-02-23 12:50:28,846]\u001b[0m Trial 54 finished with value: 0.02437793975897554 and parameters: {'lambda_l1': 5.247813885092218e-05, 'lambda_l2': 0.11512585127618073}. Best is trial 48 with value: 0.024328416353054803.\u001b[0m\n",
      "regularization_factors, val_score: 0.024328:  60%|######    | 12/20 [17:13<11:29, 86.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[891]\tvalid_0's binary_logloss: 0.0192544\tvalid_1's binary_logloss: 0.0243779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.274536 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4864\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.024328:  65%|######5   | 13/20 [18:27<09:36, 82.38s/it]\u001b[32m[I 2022-02-23 12:51:42,427]\u001b[0m Trial 55 finished with value: 0.02434940667888221 and parameters: {'lambda_l1': 1.6600194644148547e-08, 'lambda_l2': 0.0005538835742353322}. Best is trial 48 with value: 0.024328416353054803.\u001b[0m\n",
      "regularization_factors, val_score: 0.024328:  65%|######5   | 13/20 [18:27<09:36, 82.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[702]\tvalid_0's binary_logloss: 0.0190358\tvalid_1's binary_logloss: 0.0243494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.339731 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4864\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.024328:  70%|#######   | 14/20 [20:01<08:36, 86.02s/it]\u001b[32m[I 2022-02-23 12:53:16,870]\u001b[0m Trial 56 finished with value: 0.024344539389967064 and parameters: {'lambda_l1': 0.00011778888445128869, 'lambda_l2': 1.4739634457807534e-05}. Best is trial 48 with value: 0.024328416353054803.\u001b[0m\n",
      "regularization_factors, val_score: 0.024328:  70%|#######   | 14/20 [20:01<08:36, 86.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[781]\tvalid_0's binary_logloss: 0.018721\tvalid_1's binary_logloss: 0.0243445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.357088 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4864\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.024328:  75%|#######5  | 15/20 [21:33<07:19, 87.87s/it]\u001b[32m[I 2022-02-23 12:54:49,017]\u001b[0m Trial 57 finished with value: 0.024334717625448442 and parameters: {'lambda_l1': 1.0325044196075442e-06, 'lambda_l2': 0.008413098466700342}. Best is trial 48 with value: 0.024328416353054803.\u001b[0m\n",
      "regularization_factors, val_score: 0.024328:  75%|#######5  | 15/20 [21:33<07:19, 87.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[783]\tvalid_0's binary_logloss: 0.0188568\tvalid_1's binary_logloss: 0.0243347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.332860 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4864\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.024328:  80%|########  | 16/20 [23:31<06:26, 96.69s/it]\u001b[32m[I 2022-02-23 12:56:46,181]\u001b[0m Trial 58 finished with value: 0.024415223693659102 and parameters: {'lambda_l1': 0.0004885596519296439, 'lambda_l2': 7.742691363055127}. Best is trial 48 with value: 0.024328416353054803.\u001b[0m\n",
      "regularization_factors, val_score: 0.024328:  80%|########  | 16/20 [23:31<06:26, 96.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[757]\tvalid_0's binary_logloss: 0.0213392\tvalid_1's binary_logloss: 0.0244152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.110416 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4864\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.024328:  85%|########5 | 17/20 [24:56<04:40, 93.42s/it]\u001b[32m[I 2022-02-23 12:58:12,002]\u001b[0m Trial 59 finished with value: 0.024422460606308302 and parameters: {'lambda_l1': 0.47924500925251207, 'lambda_l2': 1.524306146522353e-08}. Best is trial 48 with value: 0.024328416353054803.\u001b[0m\n",
      "regularization_factors, val_score: 0.024328:  85%|########5 | 17/20 [24:56<04:40, 93.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[795]\tvalid_0's binary_logloss: 0.0188356\tvalid_1's binary_logloss: 0.0244225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.340621 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4864\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.024328:  90%|######### | 18/20 [26:38<03:11, 95.80s/it]\u001b[32m[I 2022-02-23 12:59:53,344]\u001b[0m Trial 60 finished with value: 0.02439211214956318 and parameters: {'lambda_l1': 1.186813936768744e-08, 'lambda_l2': 0.2380541918489892}. Best is trial 48 with value: 0.024328416353054803.\u001b[0m\n",
      "regularization_factors, val_score: 0.024328:  90%|######### | 18/20 [26:38<03:11, 95.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[826]\tvalid_0's binary_logloss: 0.0198296\tvalid_1's binary_logloss: 0.0243921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.100135 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4864\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.024328:  95%|#########5| 19/20 [27:54<01:29, 89.84s/it]\u001b[32m[I 2022-02-23 13:01:09,314]\u001b[0m Trial 61 finished with value: 0.0243630351946252 and parameters: {'lambda_l1': 8.0168976644923e-06, 'lambda_l2': 9.846316670418355e-05}. Best is trial 48 with value: 0.024328416353054803.\u001b[0m\n",
      "regularization_factors, val_score: 0.024328:  95%|#########5| 19/20 [27:54<01:29, 89.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[748]\tvalid_0's binary_logloss: 0.0188475\tvalid_1's binary_logloss: 0.024363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.094304 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4864\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.024328: 100%|##########| 20/20 [29:11<00:00, 86.01s/it]\u001b[32m[I 2022-02-23 13:02:26,403]\u001b[0m Trial 62 finished with value: 0.024359196360765605 and parameters: {'lambda_l1': 0.0006620434213245456, 'lambda_l2': 0.0006507600237914236}. Best is trial 48 with value: 0.024328416353054803.\u001b[0m\n",
      "regularization_factors, val_score: 0.024328: 100%|##########| 20/20 [29:11<00:00, 87.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[751]\tvalid_0's binary_logloss: 0.0188516\tvalid_1's binary_logloss: 0.0243592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.024328:   0%|          | 0/5 [00:00<?, ?it/s]/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.099032 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4864\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.024328:  20%|##        | 1/5 [01:12<04:50, 72.63s/it]\u001b[32m[I 2022-02-23 13:03:39,037]\u001b[0m Trial 63 finished with value: 0.024347519690985753 and parameters: {'min_child_samples': 25}. Best is trial 63 with value: 0.024347519690985753.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.024328:  20%|##        | 1/5 [01:12<04:50, 72.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[708]\tvalid_0's binary_logloss: 0.0191394\tvalid_1's binary_logloss: 0.0243475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.340899 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4864\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.024328:  40%|####      | 2/5 [02:22<03:33, 71.15s/it]\u001b[32m[I 2022-02-23 13:04:49,146]\u001b[0m Trial 64 finished with value: 0.024615242131034273 and parameters: {'min_child_samples': 5}. Best is trial 63 with value: 0.024347519690985753.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.024328:  40%|####      | 2/5 [02:22<03:33, 71.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[413]\tvalid_0's binary_logloss: 0.0195996\tvalid_1's binary_logloss: 0.0246152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.096555 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4864\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.024328:  60%|######    | 3/5 [03:46<02:33, 76.82s/it]\u001b[32m[I 2022-02-23 13:06:12,728]\u001b[0m Trial 65 finished with value: 0.024331969993790854 and parameters: {'min_child_samples': 50}. Best is trial 65 with value: 0.024331969993790854.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.024328:  60%|######    | 3/5 [03:46<02:33, 76.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[787]\tvalid_0's binary_logloss: 0.0192489\tvalid_1's binary_logloss: 0.024332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.091246 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4864\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.024317:  80%|########  | 4/5 [05:09<01:19, 79.22s/it]\u001b[32m[I 2022-02-23 13:07:35,610]\u001b[0m Trial 66 finished with value: 0.024316836225889173 and parameters: {'min_child_samples': 100}. Best is trial 66 with value: 0.024316836225889173.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.024317:  80%|########  | 4/5 [05:09<01:19, 79.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[787]\tvalid_0's binary_logloss: 0.0196511\tvalid_1's binary_logloss: 0.0243168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12998, number of negative: 2977593\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.334864 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4864\n",
      "[LightGBM] [Info] Number of data points in the train set: 2990591, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004346 -> initscore=-5.434075\n",
      "[LightGBM] [Info] Start training from score -5.434075\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.024317: 100%|##########| 5/5 [06:51<00:00, 87.67s/it]\u001b[32m[I 2022-02-23 13:09:18,275]\u001b[0m Trial 67 finished with value: 0.02446794383542016 and parameters: {'min_child_samples': 10}. Best is trial 66 with value: 0.024316836225889173.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.024317: 100%|##########| 5/5 [06:51<00:00, 82.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[784]\tvalid_0's binary_logloss: 0.0182872\tvalid_1's binary_logloss: 0.0244679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 1週ずつローリングして学習データを生成し検証\n",
    "n_iter = 3\n",
    "train_start = datetime.datetime(2020,9,9)\n",
    "valid_start = datetime.datetime(2020,9,16)\n",
    "valid_end = datetime.datetime(2020,9,22)\n",
    "test_pred = np.zeros(len(ml_test))\n",
    "fi = pd.DataFrame()\n",
    "scores = []\n",
    "for i in range(n_iter):\n",
    "    # 学習データの作成\n",
    "    history_tran = transactions[transactions['t_dat'] < train_start].copy()\n",
    "    target_tran = transactions[(transactions['t_dat'] >= train_start) & (transactions['t_dat'] < valid_start)].copy()\n",
    "    target_id = target_tran['customer_id'].unique().tolist()\n",
    "    recom = get_reccomend(target_id, history_tran)\n",
    "    ml_train = add_labels(recom, target_tran)\n",
    "    ml_train = add_features(ml_train, history_tran, articles, customers)\n",
    "\n",
    "    # 評価データの作成\n",
    "    history_tran = transactions[transactions['t_dat'] < valid_start].copy()\n",
    "    target_tran = transactions[(transactions['t_dat'] >= valid_start) & (transactions['t_dat'] <= valid_end)].copy()\n",
    "    target_id = target_tran['customer_id'].unique().tolist()\n",
    "    recom = get_reccomend(target_id, history_tran)\n",
    "    ml_valid = add_labels(recom, target_tran)\n",
    "    ml_valid = add_features(ml_valid, history_tran, articles, customers)\n",
    "    \n",
    "    # 学習\n",
    "    tr_x, tr_y = ml_train[features], ml_train[target]\n",
    "    vl_x, vl_y = ml_valid[features], ml_valid[target]\n",
    "    tr_data = lgb.Dataset(tr_x, label=tr_y)\n",
    "    vl_data = lgb.Dataset(vl_x, label=vl_y)\n",
    "    break\n",
    "model = optuna_lgb.train(params, tr_data, valid_sets=[tr_data, vl_data],\n",
    "                num_boost_round=20000, early_stopping_rounds=100,verbose_eval=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'objective': 'binary',\n",
       " 'boosting': 'gbdt',\n",
       " 'learning_rate': 0.01,\n",
       " 'metric': 'binary_logloss',\n",
       " 'seed': 42,\n",
       " 'feature_pre_filter': False,\n",
       " 'lambda_l1': 2.652545580792273e-07,\n",
       " 'lambda_l2': 4.127044972448657e-07,\n",
       " 'num_leaves': 100,\n",
       " 'feature_fraction': 0.7,\n",
       " 'bagging_fraction': 0.7235734670479185,\n",
       " 'bagging_freq': 1,\n",
       " 'min_child_samples': 100,\n",
       " 'num_iterations': 20000,\n",
       " 'early_stopping_round': 100}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.params"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
