{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# exp036"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import gc\n",
    "import itertools\n",
    "import pickle\n",
    "import pathlib\n",
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "sys.path.append(os.getenv('UTILS_PATH'))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import optuna\n",
    "\n",
    "import line_notify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import builtins\n",
    "import types\n",
    "\n",
    "def imports():\n",
    "    for name, val in globals().items():\n",
    "        # module imports\n",
    "        if isinstance(val, types.ModuleType):\n",
    "            yield name, val\n",
    "\n",
    "            # functions / callables\n",
    "        if hasattr(val, '__call__'):\n",
    "            yield name, val\n",
    "\n",
    "\n",
    "def noglobal(f):\n",
    "    '''\n",
    "    ref: https://gist.github.com/raven38/4e4c3c7a179283c441f575d6e375510c\n",
    "    '''\n",
    "    return types.FunctionType(f.__code__,\n",
    "                              dict(imports()),\n",
    "                              f.__name__,\n",
    "                              f.__defaults__,\n",
    "                              f.__closure__\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "N_ITER = 1\n",
    "RUN_INF = False # 推論処理を行うか\n",
    "BATCH_SIZE = int(5e5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ns = {}\n",
    "Ns['cf_a'] = 12\n",
    "Ns['ctf_a'] = 12\n",
    "Ns['atfd_a'] = 12\n",
    "Ns['atfp_a'] = 12\n",
    "Ns['pa_a'] = 12\n",
    "\n",
    "Ns['cf_w'] = 12\n",
    "Ns['ctf_w'] = 12\n",
    "Ns['atfd_w'] = 12\n",
    "Ns['atfp_w'] = 12\n",
    "Ns['pa_w'] = 12\n",
    "\n",
    "Ns['cf_m'] = 12\n",
    "Ns['ctf_m'] = 12\n",
    "Ns['atfd_m'] = 12\n",
    "Ns['atfp_m'] = 12\n",
    "Ns['pa_m'] = 12\n",
    "\n",
    "Ns['cf_y'] = 12\n",
    "Ns['ctf_y'] = 12\n",
    "Ns['atfd_y'] = 12\n",
    "Ns['atfp_y'] = 12\n",
    "Ns['pa_y'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ディレクトリ設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIR = os.getenv('INPUT_DIR')\n",
    "OUTPUT_DIR = os.getenv('OUTPUT_DIR')\n",
    "#exp_name = os.path.dirname(__file__).split('/')[-1]\n",
    "exp_name = 'exp036'\n",
    "os.makedirs(OUTPUT_DIR + exp_name, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データ読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = pd.read_csv(INPUT_DIR + 'articles.csv', dtype='object')\n",
    "customers = pd.read_csv(INPUT_DIR + 'customers.csv')\n",
    "transactions = pd.read_csv(INPUT_DIR + 'transactions_train.csv', dtype={'article_id':'str'}, parse_dates=['t_dat'])\n",
    "sample = pd.read_csv(INPUT_DIR + 'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_CUSTOMER = customers['customer_id'].unique().tolist()\n",
    "ALL_ARTICLE = articles['article_id'].unique().tolist()\n",
    "\n",
    "customer_ids = dict(list(enumerate(ALL_CUSTOMER)))\n",
    "article_ids = dict(list(enumerate(ALL_ARTICLE)))\n",
    "\n",
    "customer_map = {u: uidx for uidx, u in customer_ids.items()}\n",
    "article_map = {i: iidx for iidx, i in article_ids.items()}\n",
    "\n",
    "articles['article_id'] = articles['article_id'].map(article_map)\n",
    "customers['customer_id'] = customers['customer_id'].map(customer_map)\n",
    "transactions['article_id'] = transactions['article_id'].map(article_map)\n",
    "transactions['customer_id'] = transactions['customer_id'].map(customer_map)\n",
    "sample['customer_id'] = sample['customer_id'].map(customer_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 名寄せ\n",
    "customers['fashion_news_frequency'] = customers['fashion_news_frequency'].str.replace('None','NONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers['age10'] = str((customers['age'] // 10) * 10)\n",
    "customers.loc[customers['age'].isnull(), 'age10'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_encoding\n",
    "le_cols = ['product_type_name', 'product_group_name', 'graphical_appearance_name',\n",
    "            'colour_group_name', 'perceived_colour_value_name', 'perceived_colour_master_name', 'department_name',\n",
    "            'index_name', 'index_group_name', 'section_name', 'garment_group_name']\n",
    "for c in le_cols:\n",
    "    le = LabelEncoder()\n",
    "    articles[c] = le.fit_transform(articles[c].fillna(''))\n",
    "\n",
    "\n",
    "le_cols = ['club_member_status', 'fashion_news_frequency', 'postal_code', 'age10']\n",
    "for c in le_cols:\n",
    "    le = LabelEncoder()\n",
    "    customers[c] = le.fit_transform(customers[c].fillna(''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers['customer_type'] = customers['FN'].fillna(0).astype(int).astype(str) + \\\n",
    "                             customers['Active'].fillna(0).astype(int).astype(str) + \\\n",
    "                             customers['club_member_status'].fillna(0).astype(int).astype(str) + \\\n",
    "                             customers['fashion_news_frequency'].fillna(0).astype(int).astype(str) + \\\n",
    "                             customers['age10'].fillna(0).astype(int).astype(str)\n",
    "\n",
    "le = LabelEncoder()\n",
    "customers['customer_type'] = le.fit_transform(customers['customer_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transactionに紐づけ\n",
    "transactions = transactions.merge(customers, on='customer_id', how='left')\n",
    "transactions = transactions.merge(articles, on='article_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データセット作成（レコメンド→対象データセット作成→特徴量エンジニアリング）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "@noglobal\n",
    "def get_customer_frequent(history, n=12, timedelta=None):\n",
    "    \"\"\"顧客ごと商品の購入数をカウントし上位の商品を抽出\n",
    "\n",
    "    Args:\n",
    "        history (dataframe): 集計対象の実績データ\n",
    "        n (int): レコメンド対象とする数\n",
    "        timedelta (dateutil.relativedelta): 指定された場合、実績データの終端からtimedelta分のデータを取得する\n",
    "\n",
    "    Returns:\n",
    "        dataframe: 抽出結果\n",
    "    \"\"\"\n",
    "    if timedelta is not None:\n",
    "        st_date = history['t_dat'].max() - timedelta\n",
    "        history = history[history['t_dat']>=st_date].copy()\n",
    "        \n",
    "    customer_agg = history.groupby(['customer_id', 'article_id'])['t_dat'].count().reset_index()\n",
    "    customer_agg = customer_agg.rename(columns={'t_dat':'cnt'})\n",
    "    customer_agg = customer_agg.sort_values(['customer_id', 'cnt'], ascending=False)\n",
    "    result = customer_agg.groupby('customer_id').head(n)\n",
    "    return result[['customer_id', 'article_id']]\n",
    "\n",
    "@noglobal\n",
    "def get_popular_article(history, n=12, timedelta=None):\n",
    "    \"\"\"全体の購入数をカウントし上位の商品を抽出\n",
    "\n",
    "    Args:\n",
    "        history (dataframe): 集計対象の実績データ\n",
    "        n (int): レコメンド対象とする数\n",
    "        timedelta (dateutil.relativedelta): 指定された場合、実績データの終端からtimedelta分のデータを取得する\n",
    "\n",
    "    Returns:\n",
    "        list: 抽出結果\n",
    "    \"\"\"\n",
    "    # 全体の購入数量\n",
    "    if timedelta is not None:\n",
    "        st_date = history['t_dat'].max() - timedelta\n",
    "        history = history[history['t_dat']>=st_date].copy()\n",
    "\n",
    "    total_agg = history.groupby('article_id')['t_dat'].count().reset_index()\n",
    "    total_agg = total_agg.rename(columns={'t_dat':'cnt'})\n",
    "    total_agg = total_agg.sort_values(['cnt'], ascending=False)\n",
    "    total_agg = total_agg.head(n)\n",
    "    result = list(total_agg['article_id'].values)\n",
    "    return result\n",
    "\n",
    "@noglobal\n",
    "def get_customer_type_frequent(history, n=12, timedelta=None):\n",
    "    if timedelta is not None:\n",
    "        st_date = history['t_dat'].max() - timedelta\n",
    "        history = history[history['t_dat']>=st_date].copy()\n",
    "\n",
    "    result = history[['customer_id', 'customer_type']].drop_duplicates().copy()\n",
    "    agg = history.groupby(['customer_type', 'article_id'])['t_dat'].count().reset_index()\n",
    "    agg = agg.rename(columns={'t_dat':'cnt'})\n",
    "    agg = agg.sort_values(['customer_type', 'cnt'], ascending=False)\n",
    "    agg = agg.groupby('customer_type').head(n)\n",
    "    result = result.merge(agg[['customer_type', 'article_id']], on='customer_type', how='left')\n",
    "    return result[['customer_id', 'article_id']]\n",
    "\n",
    "@noglobal\n",
    "def get_article_type_frequent(history, col, n=12, timedelta=None):\n",
    "    if timedelta is not None:\n",
    "        st_date = history['t_dat'].max() - timedelta\n",
    "        history = history[history['t_dat']>=st_date].copy()\n",
    "\n",
    "    result = history.groupby(['customer_id', col])['t_dat'].count().reset_index()\n",
    "    result = result.rename(columns={'t_dat':'cnt'})\n",
    "    result = result.sort_values(['customer_id', 'cnt'], ascending=False)\n",
    "    result = result.groupby(['customer_id']).head(1)[['customer_id', col]]\n",
    "\n",
    "    agg = history.groupby([col, 'article_id'])['t_dat'].count().reset_index()\n",
    "    agg = agg.rename(columns={'t_dat':'cnt'})\n",
    "    agg = agg.sort_values([col, 'cnt'], ascending=False)\n",
    "    agg = agg.groupby(col).head(n)\n",
    "    result = result.merge(agg[[col, 'article_id']], on=col, how='left')\n",
    "    return result[['customer_id', 'article_id']]\n",
    "\n",
    "@noglobal\n",
    "def get_reccomend(target_customer_id, history, Ns):\n",
    "    n = 12\n",
    "    result = pd.DataFrame()\n",
    "    \n",
    "\n",
    "    td = None\n",
    "    result = result.append(get_customer_frequent(history, Ns['cf_a'], td))\n",
    "    result = result.append(get_customer_type_frequent(history, Ns['ctf_a'], td))\n",
    "    result = result.append(get_article_type_frequent(history, 'department_name', Ns['atfd_a'], td))\n",
    "    result = result.append(get_article_type_frequent(history, 'perceived_colour_master_name', Ns['atfp_a'], td))\n",
    "    popular_article = get_popular_article(history, Ns['pa_a'], td)\n",
    "    # customerとpopular articleの全組み合わせでdataframe作成\n",
    "    popular_article = pd.DataFrame(itertools.product(target_customer_id, popular_article), columns=['customer_id', 'article_id'])\n",
    "    result = result.append(popular_article)\n",
    "    result = result.drop_duplicates()\n",
    "\n",
    "    td = relativedelta(weeks=1)\n",
    "    result = result.append(get_customer_frequent(history, Ns['cf_w'], td))\n",
    "    result = result.append(get_customer_type_frequent(history, Ns['ctf_w'], td))\n",
    "    result = result.append(get_article_type_frequent(history, 'department_name', Ns['atfd_w'], td))\n",
    "    result = result.append(get_article_type_frequent(history, 'perceived_colour_master_name', Ns['atfp_w'], td))\n",
    "    popular_article = get_popular_article(history, Ns['pa_w'], td)\n",
    "    # customerとpopular articleの全組み合わせでdataframe作成\n",
    "    popular_article = pd.DataFrame(itertools.product(target_customer_id, popular_article), columns=['customer_id', 'article_id'])\n",
    "    result = result.append(popular_article)\n",
    "    result = result.drop_duplicates()\n",
    "\n",
    "    td = relativedelta(months=1)\n",
    "    result = result.append(get_customer_frequent(history, Ns['cf_m'], td))\n",
    "    result = result.append(get_customer_type_frequent(history, Ns['ctf_m'], td))\n",
    "    result = result.append(get_article_type_frequent(history, 'department_name', Ns['atfd_m'], td))\n",
    "    result = result.append(get_article_type_frequent(history, 'perceived_colour_master_name', Ns['atfp_m'], td))\n",
    "    popular_article = get_popular_article(history, Ns['pa_m'], td)\n",
    "    # customerとpopular articleの全組み合わせでdataframe作成\n",
    "    popular_article = pd.DataFrame(itertools.product(target_customer_id, popular_article), columns=['customer_id', 'article_id'])\n",
    "    result = result.append(popular_article)\n",
    "    result = result.drop_duplicates()\n",
    "\n",
    "    td = relativedelta(years=1)\n",
    "    result = result.append(get_customer_frequent(history, Ns['cf_y'], td))\n",
    "    result = result.append(get_customer_type_frequent(history, Ns['ctf_y'], td))\n",
    "    result = result.append(get_article_type_frequent(history, 'department_name', Ns['atfd_y'], td))\n",
    "    result = result.append(get_article_type_frequent(history, 'perceived_colour_master_name', Ns['atfp_y'], td))\n",
    "    popular_article = get_popular_article(history, Ns['pa_y'], td)\n",
    "    # customerとpopular articleの全組み合わせでdataframe作成\n",
    "    popular_article = pd.DataFrame(itertools.product(target_customer_id, popular_article), columns=['customer_id', 'article_id'])\n",
    "    result = result.append(popular_article)\n",
    "    result = result.drop_duplicates()\n",
    "\n",
    "    result = result[result['customer_id'].isin(target_customer_id)].copy()\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "@noglobal\n",
    "def add_labels(recom_result, history):\n",
    "    \"\"\"レコメンドしたデータが学習期間で購入されたかどうかのフラグを付与する\n",
    "\n",
    "    Args:\n",
    "        recom_result (_type_): レコメンド結果\n",
    "        train_tran (_type_): 学習期間のトランザクションデータ\n",
    "\n",
    "    Returns:\n",
    "        _type_: 学習期間での購入フラグを付与したレコメンド結果\n",
    "    \"\"\"\n",
    "    history = history[['customer_id', 'article_id']].drop_duplicates()\n",
    "    history['buy'] = 1\n",
    "    recom_result = recom_result.merge(history, on=['customer_id', 'article_id'], how='left')\n",
    "    recom_result['buy'] = recom_result['buy'].fillna(0)\n",
    "    return recom_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "@noglobal\n",
    "def make_article_features(articles):\n",
    "    cols = ['product_type_name', 'product_group_name', 'graphical_appearance_name',\n",
    "            'colour_group_name', 'perceived_colour_value_name', 'perceived_colour_master_name', 'department_name',\n",
    "            'index_name', 'index_group_name', 'section_name', 'garment_group_name']\n",
    "    return articles[['article_id']+cols]\n",
    "\n",
    "@noglobal\n",
    "def make_article_tran_features(history):\n",
    "    df = history.groupby('article_id').agg({'t_dat':['count', 'max', 'min'],\n",
    "                                            'price':['max', 'min', 'mean'], \n",
    "                                            'age':['max', 'min', 'mean', 'std']}).reset_index()\n",
    "    df.columns = ['article_id','article_total_cnt', 'article_total_latest_buy', 'article_total_1st_buy', 'article_price_max', 'article_price_min', 'article_price_mean', 'article_age_max', 'article_age_min', 'article_age_mean', 'article_age_std']\n",
    "    df['article_total_1st_buy'] = (history['t_dat'].max() - df['article_total_1st_buy']).dt.days\n",
    "    df['article_total_latest_buy'] = (history['t_dat'].max() - df['article_total_latest_buy']).dt.days\n",
    "\n",
    "    for i in range(2):\n",
    "        istr = str(i+1)\n",
    "\n",
    "        history_weekago = history.loc[(history['t_dat'] > history['t_dat'].max() - relativedelta(days=(i+1)*7)) & \n",
    "                                    (history['t_dat'] <= history['t_dat'].max() - relativedelta(days=i*7))]\n",
    "\n",
    "        history_weekago_df = history_weekago.groupby('article_id').agg({'t_dat':['count', 'max', 'min'],\n",
    "                                                'price':['max', 'min', 'mean'], \n",
    "                                                'age':['max', 'min', 'mean', 'std', 'median']}).reset_index()\n",
    "        history_weekago_df.columns = ['article_id',f'article_total_cnt_{istr}weekago', f'article_total_latest_buy_{istr}weekago', f'article_total_1st_buy_{istr}weekago', f'article_price_max_{istr}weekago', f'article_price_min_{istr}weekago', \n",
    "                                      f'article_price_mean_{istr}weekago', f'article_age_max_{istr}weekago', f'article_age_min_{istr}weekago', f'article_age_mean_{istr}weekago', f'article_age_std_{istr}weekago', f'article_age_median_{istr}weekago']\n",
    "        history_weekago_df[f'article_total_1st_buy_{istr}weekago'] = (history_weekago['t_dat'].max() - history_weekago_df[f'article_total_1st_buy_{istr}weekago']).dt.days\n",
    "        history_weekago_df[f'article_total_latest_buy_{istr}weekago'] = (history_weekago['t_dat'].max() - history_weekago_df[f'article_total_latest_buy_{istr}weekago']).dt.days\n",
    "\n",
    "        df = pd.merge(df,history_weekago_df,how='left',on='article_id')\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "@noglobal\n",
    "def make_customer_features(customers):\n",
    "    return customers\n",
    "\n",
    "@noglobal\n",
    "def make_customer_tran_features(history):\n",
    "    group = ['Ladieswear', 'Divided', 'Menswear', 'Sport', 'Baby/Children']\n",
    "    for g in group:\n",
    "        history[g] = 0\n",
    "        history.loc[history['index_group_name']==g, g] = 1\n",
    "\n",
    "\n",
    "    df = history.groupby('customer_id').agg({'t_dat':['count', 'max', 'min'],\n",
    "                                            'price':['max', 'min', 'mean'],\n",
    "                                            'Ladieswear':'sum',\n",
    "                                            'Divided':'sum',\n",
    "                                            'Menswear':'sum',\n",
    "                                            'Sport':'sum',\n",
    "                                            'Baby/Children':'sum'}).reset_index()\n",
    "    df.columns = ['customer_id','customer_total_cnt', 'customer_total_latest_buy', 'customer_total_1st_buy', \n",
    "                  'customer_price_max', 'customer_price_min', 'customer_price_mean',\n",
    "                  'Ladieswear', 'Divided', 'Menswear', 'Sport', 'Baby/Children']\n",
    "    df['customer_total_1st_buy'] = (history['t_dat'].max() - df['customer_total_1st_buy']).dt.days\n",
    "    df['customer_total_latest_buy'] = (history['t_dat'].max() - df['customer_total_latest_buy']).dt.days\n",
    "\n",
    "    for g in group:\n",
    "        df[g] = df[g] / df['customer_total_cnt']\n",
    "\n",
    "#####################iida_exp24#########################\n",
    "    for i in range(2):\n",
    "        istr = str(i+1)\n",
    "        history_weekago = history.loc[(history['t_dat'] > history['t_dat'].max() - relativedelta(days=(i+1)*7)) & \n",
    "                                    (history['t_dat'] <= history['t_dat'].max() - relativedelta(days=i*7))]\n",
    "        history_weekago_df =  history_weekago.groupby('customer_id').agg({'t_dat':['count', 'max', 'min'],\n",
    "                                                'price':['max', 'min', 'mean'],\n",
    "                                                'Ladieswear':'sum',\n",
    "                                                'Divided':'sum',\n",
    "                                                'Menswear':'sum',\n",
    "                                                'Sport':'sum',\n",
    "                                                'Baby/Children':'sum'}).reset_index() \n",
    "        history_weekago_df.columns = ['customer_id',f'customer_total_cnt_{istr}weekago', f'customer_total_latest_buy_{istr}weekago', f'customer_total_1st_buy_{istr}weekago', \n",
    "                                    f'customer_price_max_{istr}weekago', f'customer_price_min_{istr}weekago', f'customer_price_mean_{istr}weekago',\n",
    "                                    f'Ladieswear_{istr}weekago', f'Divided_{istr}weekago', f'Menswear_{istr}weekago', f'Sport_{istr}weekago', f'Baby/Children_{istr}weekago']\n",
    "\n",
    "        history_weekago_df[f'customer_total_1st_buy_{istr}weekago'] = (history_weekago['t_dat'].max() - history_weekago_df[f'customer_total_1st_buy_{istr}weekago']).dt.days\n",
    "        history_weekago_df[f'customer_total_latest_buy_{istr}weekago'] = (history_weekago['t_dat'].max() - history_weekago_df[f'customer_total_latest_buy_{istr}weekago']).dt.days\n",
    "\n",
    "        for g in group:\n",
    "            history_weekago_df[g+f'_{istr}weekago'] = history_weekago_df[g+f'_{istr}weekago'] / history_weekago_df[f'customer_total_cnt_{istr}weekago']\n",
    "\n",
    "        df = pd.merge(df,history_weekago_df,how='left',on='customer_id')\n",
    "\n",
    "    return df\n",
    "\n",
    "@noglobal\n",
    "def make_customer_article_features(target, history):\n",
    "    df = target.merge(history, on=['customer_id', 'article_id'], how='inner')\n",
    "    df = df.groupby(['customer_id', 'article_id']).agg({'t_dat':['count', 'min', 'max']}).reset_index()\n",
    "    df.columns = ['customer_id', 'article_id', 'count', '1st_buy_date_diff', 'latest_buy_date_diff']\n",
    "    df['1st_buy_date_diff'] = (history['t_dat'].max() - df['1st_buy_date_diff']).dt.days\n",
    "    df['latest_buy_date_diff'] = (history['t_dat'].max() - df['latest_buy_date_diff']).dt.days\n",
    "    return df\n",
    "\n",
    "@noglobal\n",
    "def add_same_article_type_rate(target, history, col):\n",
    "    add_data = history[['customer_id', col]].copy()\n",
    "    add_data['total'] = add_data.groupby('customer_id').transform('count')\n",
    "    add_data = add_data.groupby(['customer_id', col])['total'].agg(['max', 'count']).reset_index()\n",
    "    add_data[f'{col}_customer_buy_rate'] = add_data['count'] / add_data['max']\n",
    "    target = target.merge(add_data[['customer_id', col, f'{col}_customer_buy_rate']], on=['customer_id', col], how='left')\n",
    "    return target\n",
    "\n",
    "    \n",
    "\n",
    "@noglobal\n",
    "def add_features(df, history, articles, customers):\n",
    "    df = df.merge(make_article_features(articles), on=['article_id'], how='left')\n",
    "    df = df.merge(make_article_tran_features(history), on=['article_id'], how='left')\n",
    "    df = df.merge(make_customer_features(customers), on=['customer_id'], how='left')\n",
    "    df = df.merge(make_customer_tran_features(history), on=['customer_id'], how='left')\n",
    "    df = df.merge(make_customer_article_features(df[['customer_id', 'article_id']], history), on=['article_id', 'customer_id'], how='left')\n",
    "\n",
    "    cols = ['product_type_name', 'product_group_name', 'graphical_appearance_name',\n",
    "            'colour_group_name', 'perceived_colour_value_name', 'perceived_colour_master_name', 'department_name',\n",
    "            'index_name', 'index_group_name', 'section_name', 'garment_group_name']\n",
    "\n",
    "    for c in cols:\n",
    "        df = add_same_article_type_rate(df, history, c)\n",
    "\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# レコメンド商品を購入するかどうかの2値分類モデル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apk(y_true, y_pred, K=12):\n",
    "    assert(len(y_true) == len(y_pred))\n",
    "    apks = []\n",
    "    for idx in range(len(y_true)):\n",
    "        y_i_true = y_true[idx]\n",
    "        y_i_pred = y_pred[idx]\n",
    "\n",
    "        # 予測値の数と重複の確認\n",
    "        assert(len(y_i_pred) <= K)\n",
    "        assert(len(np.unique(y_i_pred)) == len(y_i_pred))\n",
    "\n",
    "        sum_precision = 0.0\n",
    "        num_hits = 0.0\n",
    "\n",
    "        for i, p in enumerate(y_i_pred):\n",
    "            if p in y_i_true:\n",
    "                num_hits += 1\n",
    "                precision = num_hits / (i+1)\n",
    "                sum_precision += precision\n",
    "        apk = sum_precision / min(len(y_i_true), K)\n",
    "        apks.append(apk)\n",
    "    return apks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "@noglobal\n",
    "def run_train(transactions, articles, customers, Ns):\n",
    "\n",
    "    # 1週ずつローリングして学習データを生成し検証\n",
    "    train_start = datetime.datetime(2020,9,9)\n",
    "    valid_start = datetime.datetime(2020,9,16)\n",
    "    valid_end = datetime.datetime(2020,9,22)\n",
    "\n",
    "    # 学習データの作成\n",
    "    history_tran = transactions[transactions['t_dat'] < train_start].copy()\n",
    "    target_tran = transactions[(transactions['t_dat'] >= train_start) & (transactions['t_dat'] < valid_start)].copy()\n",
    "    target_id = target_tran['customer_id'].unique().tolist()\n",
    "    recom = get_reccomend(target_id, history_tran, Ns)\n",
    "    ml_train = add_labels(recom, target_tran)\n",
    "    ml_train = add_features(ml_train, history_tran, articles, customers)\n",
    "\n",
    "    # 評価データの作成\n",
    "    history_tran = transactions[transactions['t_dat'] < valid_start].copy()\n",
    "    target_tran = transactions[(transactions['t_dat'] >= valid_start) & (transactions['t_dat'] <= valid_end)].copy()\n",
    "    target_id = target_tran['customer_id'].unique().tolist()\n",
    "    recom = get_reccomend(target_id, history_tran, Ns)\n",
    "    ml_valid = add_labels(recom, target_tran)\n",
    "    ml_valid = add_features(ml_valid, history_tran, articles, customers)\n",
    "    \n",
    "    target = 'buy'\n",
    "    not_use_cols = ['customer_id', 'article_id', target]\n",
    "    features = [c for c in ml_train.columns if c not in not_use_cols]\n",
    "\n",
    "    params = {\n",
    "    \"objective\": \"binary\",\n",
    "    \"boosting\" : \"gbdt\",\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"metric\": \"binary_logloss\",\n",
    "    \"seed\": 42\n",
    "    }  \n",
    "\n",
    "    # 学習\n",
    "    tr_x, tr_y = ml_train[features], ml_train[target]\n",
    "    vl_x, vl_y = ml_valid[features], ml_valid[target]\n",
    "    tr_data = lgb.Dataset(tr_x, label=tr_y)\n",
    "    vl_data = lgb.Dataset(vl_x, label=vl_y)\n",
    "    model = lgb.train(params, tr_data, valid_sets=[tr_data, vl_data],\n",
    "                    num_boost_round=20000, early_stopping_rounds=100,verbose_eval=1000)\n",
    "\n",
    "    # cv\n",
    "    vl_pred = model.predict(vl_x, num_iteration=model.best_iteration)\n",
    "    # 正解データ作成\n",
    "    valid = transactions[(transactions['t_dat'] >= valid_start) & (transactions['t_dat'] <= valid_end)].copy()\n",
    "    valid = valid[['customer_id', 'article_id']].drop_duplicates()\n",
    "    valid = valid.groupby('customer_id')['article_id'].apply(list).reset_index()\n",
    "    valid = valid.sort_values('customer_id').reset_index(drop=True)\n",
    "    # 2値分類の出力を元に12個選定\n",
    "    valid_pred = ml_valid[['customer_id', 'article_id']].copy()\n",
    "    valid_pred['prob'] = vl_pred\n",
    "    valid_pred = valid_pred.sort_values(['customer_id', 'prob'], ascending=False)\n",
    "    valid_pred = valid_pred.groupby('customer_id').head(12)\n",
    "    valid_pred = valid_pred.groupby('customer_id')['article_id'].apply(list).reset_index()\n",
    "    valid_pred = valid_pred.sort_values('customer_id').reset_index(drop=True)\n",
    "    assert(valid['customer_id'].tolist() == valid_pred['customer_id'].tolist())\n",
    "    # MAP@12\n",
    "    score = np.mean(apk(valid['article_id'].tolist(), valid_pred['article_id'].tolist()))\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    cf_a = trial.suggest_int('cf_a', 0, 24)\n",
    "    ctf_a = trial.suggest_int('ctf_a', 0, 24)\n",
    "    atfd_a = trial.suggest_int('atfd_a', 0, 24)\n",
    "    atfp_a = trial.suggest_int('atfp_a', 0, 24)\n",
    "    pa_a = trial.suggest_int('pa_a', 0, 24)\n",
    "\n",
    "    cf_w = trial.suggest_int('cf_w', 0, 24)\n",
    "    ctf_w = trial.suggest_int('ctf_w', 0, 24)\n",
    "    atfd_w = trial.suggest_int('atfd_w', 0, 24)\n",
    "    atfp_w = trial.suggest_int('atfp_w', 0, 24)\n",
    "    pa_w = trial.suggest_int('pa_w', 0, 24)\n",
    "\n",
    "    cf_m = trial.suggest_int('cf_m', 0, 24)\n",
    "    ctf_m = trial.suggest_int('ctf_m', 0, 24)\n",
    "    atfd_m = trial.suggest_int('atfd_m', 0, 24)\n",
    "    atfp_m = trial.suggest_int('atfp_m', 0, 24)\n",
    "    pa_m = trial.suggest_int('pa_m', 0, 24)\n",
    "\n",
    "    cf_y = trial.suggest_int('cf_y', 0, 24)\n",
    "    ctf_y = trial.suggest_int('ctf_y', 0, 24)\n",
    "    atfd_y = trial.suggest_int('atfd_y', 0, 24)\n",
    "    atfp_y = trial.suggest_int('atfp_y', 0, 24)\n",
    "    pa_y = trial.suggest_int('pa_y', 0, 24)\n",
    "\n",
    "    Ns['cf_a'] = cf_a\n",
    "    Ns['ctf_a'] = ctf_a\n",
    "    Ns['atfd_a'] = atfd_a\n",
    "    Ns['atfp_a'] = atfp_a\n",
    "    Ns['pa_a'] = pa_a\n",
    "\n",
    "    Ns['cf_w'] = cf_w\n",
    "    Ns['ctf_w'] = ctf_w\n",
    "    Ns['atfd_w'] = atfd_w\n",
    "    Ns['atfp_w'] = atfp_w\n",
    "    Ns['pa_w'] = pa_w\n",
    "\n",
    "    Ns['cf_m'] = cf_m\n",
    "    Ns['ctf_m'] = ctf_m\n",
    "    Ns['atfd_m'] = atfd_m\n",
    "    Ns['atfp_m'] = atfp_m\n",
    "    Ns['pa_m'] = pa_m\n",
    "\n",
    "    Ns['cf_y'] = cf_y\n",
    "    Ns['ctf_y'] = ctf_y\n",
    "    Ns['atfd_y'] = atfd_y\n",
    "    Ns['atfp_y'] = atfp_y\n",
    "    Ns['pa_y'] = pa_y\n",
    "\n",
    "    total_n = ctf_a + pa_a + \\\n",
    "              ctf_w + pa_w + \\\n",
    "              ctf_m + pa_m + \\\n",
    "              ctf_y + pa_y\n",
    "\n",
    "    if total_n > 12:\n",
    "        score = run_train(transactions, articles, customers, Ns)\n",
    "    else:\n",
    "        score = 0.0\n",
    "    message = f'{Ns}\\n{score}'\n",
    "    line_notify.send(message)\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-07 00:48:36,209]\u001b[0m A new study created in memory with name: no-name-5fd0d51e-50f9-4096-99eb-f48303976df1\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 16604, number of negative: 5158704\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.488675 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12454\n",
      "[LightGBM] [Info] Number of data points in the train set: 5175308, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.003208 -> initscore=-5.738797\n",
      "[LightGBM] [Info] Start training from score -5.738797\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.0168993\tvalid_1's binary_logloss: 0.0198174\n",
      "Early stopping, best iteration is:\n",
      "[1084]\ttraining's binary_logloss: 0.0168016\tvalid_1's binary_logloss: 0.0198157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-07 01:06:23,526]\u001b[0m Trial 0 finished with value: 0.029945630398482054 and parameters: {'cf_a': 13, 'ctf_a': 4, 'atfd_a': 2, 'atfp_a': 6, 'pa_a': 2, 'cf_w': 2, 'ctf_w': 14, 'atfd_w': 3, 'atfp_w': 11, 'pa_w': 20, 'cf_m': 4, 'ctf_m': 7, 'atfd_m': 0, 'atfp_m': 12, 'pa_m': 15, 'cf_y': 24, 'ctf_y': 23, 'atfd_y': 5, 'atfp_y': 3, 'pa_y': 0}. Best is trial 0 with value: 0.029945630398482054.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 20565, number of negative: 7755649\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.799833 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12436\n",
      "[LightGBM] [Info] Number of data points in the train set: 7776214, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002645 -> initscore=-5.932586\n",
      "[LightGBM] [Info] Start training from score -5.932586\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.0142973\tvalid_1's binary_logloss: 0.0162176\n",
      "Early stopping, best iteration is:\n",
      "[1099]\ttraining's binary_logloss: 0.0142039\tvalid_1's binary_logloss: 0.0162155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-07 01:30:44,729]\u001b[0m Trial 1 finished with value: 0.031803011799666825 and parameters: {'cf_a': 21, 'ctf_a': 16, 'atfd_a': 18, 'atfp_a': 17, 'pa_a': 23, 'cf_w': 12, 'ctf_w': 17, 'atfd_w': 20, 'atfp_w': 19, 'pa_w': 23, 'cf_m': 20, 'ctf_m': 17, 'atfd_m': 1, 'atfp_m': 1, 'pa_m': 0, 'cf_y': 23, 'ctf_y': 17, 'atfd_y': 18, 'atfp_y': 12, 'pa_y': 0}. Best is trial 1 with value: 0.031803011799666825.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 21849, number of negative: 8118703\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.881718 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12448\n",
      "[LightGBM] [Info] Number of data points in the train set: 8140552, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002684 -> initscore=-5.917771\n",
      "[LightGBM] [Info] Start training from score -5.917771\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[869]\ttraining's binary_logloss: 0.0148313\tvalid_1's binary_logloss: 0.0167878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-07 01:47:48,610]\u001b[0m Trial 2 finished with value: 0.0315802080915337 and parameters: {'cf_a': 20, 'ctf_a': 23, 'atfd_a': 5, 'atfp_a': 11, 'pa_a': 13, 'cf_w': 19, 'ctf_w': 19, 'atfd_w': 3, 'atfp_w': 9, 'pa_w': 24, 'cf_m': 17, 'ctf_m': 15, 'atfd_m': 22, 'atfp_m': 24, 'pa_m': 2, 'cf_y': 24, 'ctf_y': 17, 'atfd_y': 22, 'atfp_y': 13, 'pa_y': 12}. Best is trial 1 with value: 0.031803011799666825.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 17467, number of negative: 5732896\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.948282 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12208\n",
      "[LightGBM] [Info] Number of data points in the train set: 5750363, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.003038 -> initscore=-5.793663\n",
      "[LightGBM] [Info] Start training from score -5.793663\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.0158629\tvalid_1's binary_logloss: 0.0173162\n",
      "Early stopping, best iteration is:\n",
      "[941]\ttraining's binary_logloss: 0.0159313\tvalid_1's binary_logloss: 0.0173146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-07 02:03:34,503]\u001b[0m Trial 3 finished with value: 0.03128464555183846 and parameters: {'cf_a': 3, 'ctf_a': 15, 'atfd_a': 22, 'atfp_a': 3, 'pa_a': 3, 'cf_w': 17, 'ctf_w': 15, 'atfd_w': 13, 'atfp_w': 7, 'pa_w': 1, 'cf_m': 18, 'ctf_m': 21, 'atfd_m': 6, 'atfp_m': 3, 'pa_m': 17, 'cf_y': 6, 'ctf_y': 4, 'atfd_y': 4, 'atfp_y': 21, 'pa_y': 19}. Best is trial 1 with value: 0.031803011799666825.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 17384, number of negative: 6585327\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.738404 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12474\n",
      "[LightGBM] [Info] Number of data points in the train set: 6602711, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002633 -> initscore=-5.937049\n",
      "[LightGBM] [Info] Start training from score -5.937049\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.0135774\tvalid_1's binary_logloss: 0.0160893\n",
      "Early stopping, best iteration is:\n",
      "[1541]\ttraining's binary_logloss: 0.0130569\tvalid_1's binary_logloss: 0.0160854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-07 02:21:27,813]\u001b[0m Trial 4 finished with value: 0.03190743085190008 and parameters: {'cf_a': 20, 'ctf_a': 7, 'atfd_a': 22, 'atfp_a': 9, 'pa_a': 1, 'cf_w': 19, 'ctf_w': 17, 'atfd_w': 24, 'atfp_w': 17, 'pa_w': 4, 'cf_m': 12, 'ctf_m': 0, 'atfd_m': 13, 'atfp_m': 17, 'pa_m': 10, 'cf_y': 22, 'ctf_y': 12, 'atfd_y': 18, 'atfp_y': 3, 'pa_y': 5}. Best is trial 4 with value: 0.03190743085190008.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 15875, number of negative: 4766387\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.482329 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12353\n",
      "[LightGBM] [Info] Number of data points in the train set: 4782262, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.003320 -> initscore=-5.704598\n",
      "[LightGBM] [Info] Start training from score -5.704598\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.0167038\tvalid_1's binary_logloss: 0.0196101\n",
      "Early stopping, best iteration is:\n",
      "[1625]\ttraining's binary_logloss: 0.0159855\tvalid_1's binary_logloss: 0.0195987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-07 02:41:57,897]\u001b[0m Trial 5 finished with value: 0.031078798658627817 and parameters: {'cf_a': 7, 'ctf_a': 12, 'atfd_a': 15, 'atfp_a': 7, 'pa_a': 12, 'cf_w': 16, 'ctf_w': 11, 'atfd_w': 7, 'atfp_w': 16, 'pa_w': 11, 'cf_m': 21, 'ctf_m': 13, 'atfd_m': 4, 'atfp_m': 7, 'pa_m': 12, 'cf_y': 14, 'ctf_y': 1, 'atfd_y': 10, 'atfp_y': 1, 'pa_y': 0}. Best is trial 4 with value: 0.03190743085190008.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 16465, number of negative: 5751640\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.699631 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12350\n",
      "[LightGBM] [Info] Number of data points in the train set: 5768105, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002854 -> initscore=-5.856003\n",
      "[LightGBM] [Info] Start training from score -5.856003\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[728]\ttraining's binary_logloss: 0.01519\tvalid_1's binary_logloss: 0.0172965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-07 02:56:07,938]\u001b[0m Trial 6 finished with value: 0.03127034217065081 and parameters: {'cf_a': 11, 'ctf_a': 19, 'atfd_a': 9, 'atfp_a': 12, 'pa_a': 12, 'cf_w': 6, 'ctf_w': 21, 'atfd_w': 22, 'atfp_w': 21, 'pa_w': 6, 'cf_m': 10, 'ctf_m': 11, 'atfd_m': 8, 'atfp_m': 0, 'pa_m': 3, 'cf_y': 7, 'ctf_y': 4, 'atfd_y': 13, 'atfp_y': 24, 'pa_y': 14}. Best is trial 4 with value: 0.03190743085190008.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 18553, number of negative: 6198316\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.710758 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12410\n",
      "[LightGBM] [Info] Number of data points in the train set: 6216869, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002984 -> initscore=-5.811401\n",
      "[LightGBM] [Info] Start training from score -5.811401\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.0157883\tvalid_1's binary_logloss: 0.0182768\n",
      "[2000]\ttraining's binary_logloss: 0.0148575\tvalid_1's binary_logloss: 0.0182677\n",
      "Early stopping, best iteration is:\n",
      "[1931]\ttraining's binary_logloss: 0.0149185\tvalid_1's binary_logloss: 0.0182667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-07 03:14:18,528]\u001b[0m Trial 7 finished with value: 0.031477929266707644 and parameters: {'cf_a': 9, 'ctf_a': 22, 'atfd_a': 3, 'atfp_a': 9, 'pa_a': 8, 'cf_w': 16, 'ctf_w': 13, 'atfd_w': 16, 'atfp_w': 0, 'pa_w': 12, 'cf_m': 10, 'ctf_m': 21, 'atfd_m': 20, 'atfp_m': 16, 'pa_m': 10, 'cf_y': 14, 'ctf_y': 11, 'atfd_y': 16, 'atfp_y': 6, 'pa_y': 20}. Best is trial 4 with value: 0.03190743085190008.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 18814, number of negative: 6995939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.834271 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12367\n",
      "[LightGBM] [Info] Number of data points in the train set: 7014753, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002682 -> initscore=-5.918484\n",
      "[LightGBM] [Info] Start training from score -5.918484\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.0145015\tvalid_1's binary_logloss: 0.0164103\n",
      "Early stopping, best iteration is:\n",
      "[1077]\ttraining's binary_logloss: 0.0144236\tvalid_1's binary_logloss: 0.0164089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-07 03:30:04,532]\u001b[0m Trial 8 finished with value: 0.03074801171396163 and parameters: {'cf_a': 11, 'ctf_a': 4, 'atfd_a': 3, 'atfp_a': 18, 'pa_a': 20, 'cf_w': 5, 'ctf_w': 3, 'atfd_w': 4, 'atfp_w': 8, 'pa_w': 17, 'cf_m': 5, 'ctf_m': 23, 'atfd_m': 19, 'atfp_m': 9, 'pa_m': 7, 'cf_y': 11, 'ctf_y': 10, 'atfd_y': 24, 'atfp_y': 21, 'pa_y': 13}. Best is trial 4 with value: 0.03190743085190008.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 16448, number of negative: 5783882\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.725087 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12435\n",
      "[LightGBM] [Info] Number of data points in the train set: 5800330, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002836 -> initscore=-5.862626\n",
      "[LightGBM] [Info] Start training from score -5.862626\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.0145628\tvalid_1's binary_logloss: 0.0162646\n",
      "Early stopping, best iteration is:\n",
      "[1449]\ttraining's binary_logloss: 0.0140834\tvalid_1's binary_logloss: 0.0162582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-07 03:45:50,992]\u001b[0m Trial 9 finished with value: 0.03132697095784139 and parameters: {'cf_a': 23, 'ctf_a': 12, 'atfd_a': 0, 'atfp_a': 9, 'pa_a': 22, 'cf_w': 8, 'ctf_w': 3, 'atfd_w': 7, 'atfp_w': 3, 'pa_w': 3, 'cf_m': 21, 'ctf_m': 9, 'atfd_m': 9, 'atfp_m': 19, 'pa_m': 5, 'cf_y': 8, 'ctf_y': 16, 'atfd_y': 16, 'atfp_y': 17, 'pa_y': 3}. Best is trial 4 with value: 0.03190743085190008.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 19163, number of negative: 7440023\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.806869 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12335\n",
      "[LightGBM] [Info] Number of data points in the train set: 7459186, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002569 -> initscore=-5.961648\n",
      "[LightGBM] [Info] Start training from score -5.961648\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.0138549\tvalid_1's binary_logloss: 0.0163002\n",
      "Early stopping, best iteration is:\n",
      "[1475]\ttraining's binary_logloss: 0.0134315\tvalid_1's binary_logloss: 0.0162943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-07 04:10:05,280]\u001b[0m Trial 10 finished with value: 0.03060381185123604 and parameters: {'cf_a': 16, 'ctf_a': 0, 'atfd_a': 21, 'atfp_a': 23, 'pa_a': 0, 'cf_w': 24, 'ctf_w': 23, 'atfd_w': 24, 'atfp_w': 24, 'pa_w': 8, 'cf_m': 0, 'ctf_m': 0, 'atfd_m': 13, 'atfp_m': 19, 'pa_m': 22, 'cf_y': 1, 'ctf_y': 24, 'atfd_y': 9, 'atfp_y': 7, 'pa_y': 8}. Best is trial 4 with value: 0.03190743085190008.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 19563, number of negative: 7536159\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.966265 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12431\n",
      "[LightGBM] [Info] Number of data points in the train set: 7555722, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002589 -> initscore=-5.953828\n",
      "[LightGBM] [Info] Start training from score -5.953828\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[505]\ttraining's binary_logloss: 0.0143985\tvalid_1's binary_logloss: 0.0156537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-07 04:30:37,053]\u001b[0m Trial 11 finished with value: 0.03167903736212055 and parameters: {'cf_a': 24, 'ctf_a': 7, 'atfd_a': 16, 'atfp_a': 17, 'pa_a': 18, 'cf_w': 10, 'ctf_w': 18, 'atfd_w': 20, 'atfp_w': 17, 'pa_w': 16, 'cf_m': 14, 'ctf_m': 0, 'atfd_m': 14, 'atfp_m': 15, 'pa_m': 0, 'cf_y': 19, 'ctf_y': 17, 'atfd_y': 19, 'atfp_y': 11, 'pa_y': 6}. Best is trial 4 with value: 0.03190743085190008.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 21054, number of negative: 8217863\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.728047 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12420\n",
      "[LightGBM] [Info] Number of data points in the train set: 8238917, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002555 -> initscore=-5.966975\n",
      "[LightGBM] [Info] Start training from score -5.966975\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[499]\ttraining's binary_logloss: 0.0144127\tvalid_1's binary_logloss: 0.0157142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-07 04:46:35,902]\u001b[0m Trial 12 finished with value: 0.0316470135981433 and parameters: {'cf_a': 18, 'ctf_a': 16, 'atfd_a': 24, 'atfp_a': 16, 'pa_a': 24, 'cf_w': 13, 'ctf_w': 8, 'atfd_w': 18, 'atfp_w': 16, 'pa_w': 23, 'cf_m': 14, 'ctf_m': 17, 'atfd_m': 15, 'atfp_m': 5, 'pa_m': 7, 'cf_y': 19, 'ctf_y': 14, 'atfd_y': 20, 'atfp_y': 11, 'pa_y': 6}. Best is trial 4 with value: 0.03190743085190008.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 19077, number of negative: 7451951\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.704315 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12404\n",
      "[LightGBM] [Info] Number of data points in the train set: 7471028, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002553 -> initscore=-5.967748\n",
      "[LightGBM] [Info] Start training from score -5.967748\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.0136042\tvalid_1's binary_logloss: 0.0158661\n",
      "Early stopping, best iteration is:\n",
      "[1062]\ttraining's binary_logloss: 0.0135433\tvalid_1's binary_logloss: 0.0158649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-07 05:04:12,508]\u001b[0m Trial 13 finished with value: 0.03168495694476709 and parameters: {'cf_a': 20, 'ctf_a': 8, 'atfd_a': 19, 'atfp_a': 23, 'pa_a': 7, 'cf_w': 23, 'ctf_w': 18, 'atfd_w': 24, 'atfp_w': 19, 'pa_w': 6, 'cf_m': 24, 'ctf_m': 5, 'atfd_m': 0, 'atfp_m': 12, 'pa_m': 20, 'cf_y': 19, 'ctf_y': 20, 'atfd_y': 16, 'atfp_y': 6, 'pa_y': 3}. Best is trial 4 with value: 0.03190743085190008.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 19242, number of negative: 7280261\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.724932 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12464\n",
      "[LightGBM] [Info] Number of data points in the train set: 7299503, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002636 -> initscore=-5.935827\n",
      "[LightGBM] [Info] Start training from score -5.935827\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[491]\ttraining's binary_logloss: 0.0146678\tvalid_1's binary_logloss: 0.0163962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-07 05:19:14,929]\u001b[0m Trial 14 finished with value: 0.031335668024098866 and parameters: {'cf_a': 15, 'ctf_a': 9, 'atfd_a': 17, 'atfp_a': 14, 'pa_a': 16, 'cf_w': 12, 'ctf_w': 9, 'atfd_w': 15, 'atfp_w': 13, 'pa_w': 16, 'cf_m': 8, 'ctf_m': 18, 'atfd_m': 17, 'atfp_m': 23, 'pa_m': 10, 'cf_y': 21, 'ctf_y': 8, 'atfd_y': 19, 'atfp_y': 0, 'pa_y': 9}. Best is trial 4 with value: 0.03190743085190008.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 17325, number of negative: 5934708\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.931025 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12472\n",
      "[LightGBM] [Info] Number of data points in the train set: 5952033, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002911 -> initscore=-5.836423\n",
      "[LightGBM] [Info] Start training from score -5.836423\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.0150291\tvalid_1's binary_logloss: 0.017229\n",
      "Early stopping, best iteration is:\n",
      "[1038]\ttraining's binary_logloss: 0.0149898\tvalid_1's binary_logloss: 0.0172274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-07 05:40:19,452]\u001b[0m Trial 15 finished with value: 0.03167896335184734 and parameters: {'cf_a': 21, 'ctf_a': 15, 'atfd_a': 12, 'atfp_a': 1, 'pa_a': 6, 'cf_w': 21, 'ctf_w': 24, 'atfd_w': 19, 'atfp_w': 24, 'pa_w': 9, 'cf_m': 16, 'ctf_m': 4, 'atfd_m': 10, 'atfp_m': 0, 'pa_m': 0, 'cf_y': 17, 'ctf_y': 13, 'atfd_y': 13, 'atfp_y': 15, 'pa_y': 3}. Best is trial 4 with value: 0.03190743085190008.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 16937, number of negative: 5685841\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.909423 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12323\n",
      "[LightGBM] [Info] Number of data points in the train set: 5702778, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002970 -> initscore=-5.816234\n",
      "[LightGBM] [Info] Start training from score -5.816234\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.0154201\tvalid_1's binary_logloss: 0.0168236\n",
      "Early stopping, best iteration is:\n",
      "[1827]\ttraining's binary_logloss: 0.0145933\tvalid_1's binary_logloss: 0.0168153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-07 06:04:19,668]\u001b[0m Trial 16 finished with value: 0.031056312399641135 and parameters: {'cf_a': 0, 'ctf_a': 18, 'atfd_a': 12, 'atfp_a': 20, 'pa_a': 9, 'cf_w': 14, 'ctf_w': 16, 'atfd_w': 11, 'atfp_w': 20, 'pa_w': 0, 'cf_m': 12, 'ctf_m': 12, 'atfd_m': 4, 'atfp_m': 9, 'pa_m': 13, 'cf_y': 22, 'ctf_y': 20, 'atfd_y': 0, 'atfp_y': 9, 'pa_y': 24}. Best is trial 4 with value: 0.03190743085190008.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 19561, number of negative: 7633082\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.779071 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12427\n",
      "[LightGBM] [Info] Number of data points in the train set: 7652643, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002556 -> initscore=-5.966709\n",
      "[LightGBM] [Info] Start training from score -5.966709\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.0136778\tvalid_1's binary_logloss: 0.015899\n",
      "Early stopping, best iteration is:\n",
      "[1548]\ttraining's binary_logloss: 0.0132177\tvalid_1's binary_logloss: 0.0158867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-07 06:29:06,604]\u001b[0m Trial 17 finished with value: 0.03175322660396333 and parameters: {'cf_a': 17, 'ctf_a': 10, 'atfd_a': 24, 'atfp_a': 20, 'pa_a': 15, 'cf_w': 20, 'ctf_w': 7, 'atfd_w': 21, 'atfp_w': 13, 'pa_w': 4, 'cf_m': 24, 'ctf_m': 17, 'atfd_m': 12, 'atfp_m': 17, 'pa_m': 24, 'cf_y': 16, 'ctf_y': 8, 'atfd_y': 17, 'atfp_y': 3, 'pa_y': 0}. Best is trial 4 with value: 0.03190743085190008.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 18896, number of negative: 7693121\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.915004 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12456\n",
      "[LightGBM] [Info] Number of data points in the train set: 7712017, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002450 -> initscore=-6.009132\n",
      "[LightGBM] [Info] Start training from score -6.009132\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[560]\ttraining's binary_logloss: 0.0135042\tvalid_1's binary_logloss: 0.0149558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-07 06:44:59,126]\u001b[0m Trial 18 finished with value: 0.03153248616100647 and parameters: {'cf_a': 22, 'ctf_a': 4, 'atfd_a': 19, 'atfp_a': 13, 'pa_a': 5, 'cf_w': 10, 'ctf_w': 0, 'atfd_w': 17, 'atfp_w': 22, 'pa_w': 13, 'cf_m': 19, 'ctf_m': 4, 'atfd_m': 3, 'atfp_m': 21, 'pa_m': 7, 'cf_y': 22, 'ctf_y': 19, 'atfd_y': 24, 'atfp_y': 17, 'pa_y': 6}. Best is trial 4 with value: 0.03190743085190008.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 19642, number of negative: 7254487\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.716326 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12383\n",
      "[LightGBM] [Info] Number of data points in the train set: 7274129, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002700 -> initscore=-5.911705\n",
      "[LightGBM] [Info] Start training from score -5.911705\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.0147124\tvalid_1's binary_logloss: 0.017038\n",
      "Early stopping, best iteration is:\n",
      "[1416]\ttraining's binary_logloss: 0.0143406\tvalid_1's binary_logloss: 0.0170323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-07 07:02:32,642]\u001b[0m Trial 19 finished with value: 0.030653321693264676 and parameters: {'cf_a': 19, 'ctf_a': 20, 'atfd_a': 14, 'atfp_a': 4, 'pa_a': 24, 'cf_w': 0, 'ctf_w': 21, 'atfd_w': 22, 'atfp_w': 17, 'pa_w': 19, 'cf_m': 7, 'ctf_m': 15, 'atfd_m': 11, 'atfp_m': 13, 'pa_m': 18, 'cf_y': 0, 'ctf_y': 15, 'atfd_y': 21, 'atfp_y': 4, 'pa_y': 10}. Best is trial 4 with value: 0.03190743085190008.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 19095, number of negative: 6421572\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.886832 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12404\n",
      "[LightGBM] [Info] Number of data points in the train set: 6440667, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002965 -> initscore=-5.817992\n",
      "[LightGBM] [Info] Start training from score -5.817992\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.0157069\tvalid_1's binary_logloss: 0.0181406\n",
      "[2000]\ttraining's binary_logloss: 0.0147993\tvalid_1's binary_logloss: 0.0181302\n",
      "Early stopping, best iteration is:\n",
      "[1914]\ttraining's binary_logloss: 0.0148698\tvalid_1's binary_logloss: 0.0181292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-07 07:23:01,744]\u001b[0m Trial 20 finished with value: 0.03133555287971188 and parameters: {'cf_a': 14, 'ctf_a': 1, 'atfd_a': 20, 'atfp_a': 15, 'pa_a': 10, 'cf_w': 18, 'ctf_w': 11, 'atfd_w': 13, 'atfp_w': 19, 'pa_w': 21, 'cf_m': 14, 'ctf_m': 9, 'atfd_m': 16, 'atfp_m': 2, 'pa_m': 4, 'cf_y': 11, 'ctf_y': 9, 'atfd_y': 11, 'atfp_y': 9, 'pa_y': 3}. Best is trial 4 with value: 0.03190743085190008.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 19533, number of negative: 7603790\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.853295 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12394\n",
      "[LightGBM] [Info] Number of data points in the train set: 7623323, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002562 -> initscore=-5.964297\n",
      "[LightGBM] [Info] Start training from score -5.964297\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[792]\ttraining's binary_logloss: 0.0139067\tvalid_1's binary_logloss: 0.0159404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-07 07:39:26,800]\u001b[0m Trial 21 finished with value: 0.031627826515905295 and parameters: {'cf_a': 17, 'ctf_a': 11, 'atfd_a': 24, 'atfp_a': 20, 'pa_a': 15, 'cf_w': 21, 'ctf_w': 7, 'atfd_w': 21, 'atfp_w': 13, 'pa_w': 4, 'cf_m': 24, 'ctf_m': 18, 'atfd_m': 12, 'atfp_m': 17, 'pa_m': 24, 'cf_y': 15, 'ctf_y': 7, 'atfd_y': 17, 'atfp_y': 3, 'pa_y': 1}. Best is trial 4 with value: 0.03190743085190008.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 18870, number of negative: 7182251\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.842959 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12416\n",
      "[LightGBM] [Info] Number of data points in the train set: 7201121, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002620 -> initscore=-5.941795\n",
      "[LightGBM] [Info] Start training from score -5.941795\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.0138897\tvalid_1's binary_logloss: 0.0154912\n",
      "Early stopping, best iteration is:\n",
      "[1152]\ttraining's binary_logloss: 0.0137478\tvalid_1's binary_logloss: 0.0154855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-07 07:56:23,846]\u001b[0m Trial 22 finished with value: 0.031611892175795325 and parameters: {'cf_a': 18, 'ctf_a': 10, 'atfd_a': 22, 'atfp_a': 19, 'pa_a': 19, 'cf_w': 20, 'ctf_w': 6, 'atfd_w': 23, 'atfp_w': 14, 'pa_w': 3, 'cf_m': 21, 'ctf_m': 20, 'atfd_m': 7, 'atfp_m': 18, 'pa_m': 15, 'cf_y': 16, 'ctf_y': 12, 'atfd_y': 18, 'atfp_y': 2, 'pa_y': 2}. Best is trial 4 with value: 0.03190743085190008.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 18626, number of negative: 7616020\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.781271 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12444\n",
      "[LightGBM] [Info] Number of data points in the train set: 7634646, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002440 -> initscore=-6.013451\n",
      "[LightGBM] [Info] Start training from score -6.013451\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[743]\ttraining's binary_logloss: 0.0131329\tvalid_1's binary_logloss: 0.0150379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-07 08:12:51,390]\u001b[0m Trial 23 finished with value: 0.03158298785860821 and parameters: {'cf_a': 24, 'ctf_a': 13, 'atfd_a': 24, 'atfp_a': 21, 'pa_a': 16, 'cf_w': 15, 'ctf_w': 12, 'atfd_w': 19, 'atfp_w': 15, 'pa_w': 7, 'cf_m': 24, 'ctf_m': 15, 'atfd_m': 24, 'atfp_m': 15, 'pa_m': 10, 'cf_y': 20, 'ctf_y': 6, 'atfd_y': 15, 'atfp_y': 5, 'pa_y': 5}. Best is trial 4 with value: 0.03190743085190008.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 19826, number of negative: 7774137\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.851291 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12359\n",
      "[LightGBM] [Info] Number of data points in the train set: 7793963, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002544 -> initscore=-5.971564\n",
      "[LightGBM] [Info] Start training from score -5.971564\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[679]\ttraining's binary_logloss: 0.0140291\tvalid_1's binary_logloss: 0.0159974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-07 08:34:28,327]\u001b[0m Trial 24 finished with value: 0.03133174625072234 and parameters: {'cf_a': 21, 'ctf_a': 7, 'atfd_a': 18, 'atfp_a': 24, 'pa_a': 21, 'cf_w': 11, 'ctf_w': 16, 'atfd_w': 0, 'atfp_w': 11, 'pa_w': 10, 'cf_m': 22, 'ctf_m': 23, 'atfd_m': 18, 'atfp_m': 22, 'pa_m': 20, 'cf_y': 17, 'ctf_y': 12, 'atfd_y': 14, 'atfp_y': 8, 'pa_y': 0}. Best is trial 4 with value: 0.03190743085190008.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 19275, number of negative: 7616884\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.800328 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12440\n",
      "[LightGBM] [Info] Number of data points in the train set: 7636159, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002524 -> initscore=-5.979314\n",
      "[LightGBM] [Info] Start training from score -5.979314\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[826]\ttraining's binary_logloss: 0.0136136\tvalid_1's binary_logloss: 0.0156818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-07 08:51:22,519]\u001b[0m Trial 25 finished with value: 0.03179474265899385 and parameters: {'cf_a': 15, 'ctf_a': 14, 'atfd_a': 22, 'atfp_a': 17, 'pa_a': 14, 'cf_w': 22, 'ctf_w': 4, 'atfd_w': 20, 'atfp_w': 18, 'pa_w': 14, 'cf_m': 16, 'ctf_m': 17, 'atfd_m': 2, 'atfp_m': 20, 'pa_m': 14, 'cf_y': 24, 'ctf_y': 5, 'atfd_y': 22, 'atfp_y': 0, 'pa_y': 4}. Best is trial 4 with value: 0.03190743085190008.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 18664, number of negative: 7188708\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.783578 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12478\n",
      "[LightGBM] [Info] Number of data points in the train set: 7207372, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002590 -> initscore=-5.953670\n",
      "[LightGBM] [Info] Start training from score -5.953670\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[739]\ttraining's binary_logloss: 0.0139427\tvalid_1's binary_logloss: 0.0161703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-07 09:14:16,551]\u001b[0m Trial 26 finished with value: 0.0320875228289302 and parameters: {'cf_a': 15, 'ctf_a': 17, 'atfd_a': 21, 'atfp_a': 10, 'pa_a': 0, 'cf_w': 23, 'ctf_w': 20, 'atfd_w': 15, 'atfp_w': 18, 'pa_w': 14, 'cf_m': 16, 'ctf_m': 2, 'atfd_m': 2, 'atfp_m': 21, 'pa_m': 14, 'cf_y': 24, 'ctf_y': 0, 'atfd_y': 22, 'atfp_y': 1, 'pa_y': 5}. Best is trial 26 with value: 0.0320875228289302.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 18504, number of negative: 7016991\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.784766 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12471\n",
      "[LightGBM] [Info] Number of data points in the train set: 7035495, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002630 -> initscore=-5.938103\n",
      "[LightGBM] [Info] Start training from score -5.938103\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[487]\ttraining's binary_logloss: 0.0144652\tvalid_1's binary_logloss: 0.0161866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-07 09:35:54,625]\u001b[0m Trial 27 finished with value: 0.03180676795545195 and parameters: {'cf_a': 22, 'ctf_a': 17, 'atfd_a': 14, 'atfp_a': 10, 'pa_a': 0, 'cf_w': 24, 'ctf_w': 20, 'atfd_w': 15, 'atfp_w': 21, 'pa_w': 14, 'cf_m': 19, 'ctf_m': 2, 'atfd_m': 6, 'atfp_m': 14, 'pa_m': 9, 'cf_y': 22, 'ctf_y': 1, 'atfd_y': 22, 'atfp_y': 13, 'pa_y': 8}. Best is trial 26 with value: 0.0320875228289302.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 18560, number of negative: 6931253\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.653612 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12443\n",
      "[LightGBM] [Info] Number of data points in the train set: 6949813, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002671 -> initscore=-5.922787\n",
      "[LightGBM] [Info] Start training from score -5.922787\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[606]\ttraining's binary_logloss: 0.0145574\tvalid_1's binary_logloss: 0.0165597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-07 09:57:31,120]\u001b[0m Trial 28 finished with value: 0.031807069849825585 and parameters: {'cf_a': 19, 'ctf_a': 18, 'atfd_a': 9, 'atfp_a': 10, 'pa_a': 0, 'cf_w': 24, 'ctf_w': 21, 'atfd_w': 10, 'atfp_w': 22, 'pa_w': 14, 'cf_m': 13, 'ctf_m': 2, 'atfd_m': 6, 'atfp_m': 14, 'pa_m': 11, 'cf_y': 21, 'ctf_y': 0, 'atfd_y': 23, 'atfp_y': 14, 'pa_y': 8}. Best is trial 26 with value: 0.0320875228289302.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 19766, number of negative: 7250569\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.966373 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12419\n",
      "[LightGBM] [Info] Number of data points in the train set: 7270335, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002719 -> initscore=-5.904872\n",
      "[LightGBM] [Info] Start training from score -5.904872\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.0145854\tvalid_1's binary_logloss: 0.0167082\n",
      "Early stopping, best iteration is:\n",
      "[1653]\ttraining's binary_logloss: 0.0140074\tvalid_1's binary_logloss: 0.0167011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-07 10:16:25,088]\u001b[0m Trial 29 finished with value: 0.03179423529902347 and parameters: {'cf_a': 12, 'ctf_a': 21, 'atfd_a': 9, 'atfp_a': 7, 'pa_a': 3, 'cf_w': 22, 'ctf_w': 22, 'atfd_w': 11, 'atfp_w': 22, 'pa_w': 18, 'cf_m': 12, 'ctf_m': 2, 'atfd_m': 5, 'atfp_m': 11, 'pa_m': 16, 'cf_y': 24, 'ctf_y': 0, 'atfd_y': 24, 'atfp_y': 16, 'pa_y': 10}. Best is trial 26 with value: 0.0320875228289302.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 18961, number of negative: 6771041\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.778760 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12432\n",
      "[LightGBM] [Info] Number of data points in the train set: 6790002, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002792 -> initscore=-5.878026\n",
      "[LightGBM] [Info] Start training from score -5.878026\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[801]\ttraining's binary_logloss: 0.0150645\tvalid_1's binary_logloss: 0.0171605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-07 10:31:33,993]\u001b[0m Trial 30 finished with value: 0.03163521722930435 and parameters: {'cf_a': 13, 'ctf_a': 24, 'atfd_a': 9, 'atfp_a': 6, 'pa_a': 2, 'cf_w': 24, 'ctf_w': 14, 'atfd_w': 9, 'atfp_w': 23, 'pa_w': 15, 'cf_m': 10, 'ctf_m': 6, 'atfd_m': 9, 'atfp_m': 21, 'pa_m': 13, 'cf_y': 20, 'ctf_y': 3, 'atfd_y': 21, 'atfp_y': 2, 'pa_y': 15}. Best is trial 26 with value: 0.0320875228289302.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 18351, number of negative: 6739617\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.632763 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12444\n",
      "[LightGBM] [Info] Number of data points in the train set: 6757968, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002715 -> initscore=-5.906074\n",
      "[LightGBM] [Info] Start training from score -5.906074\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.0142723\tvalid_1's binary_logloss: 0.016872\n",
      "Early stopping, best iteration is:\n",
      "[1467]\ttraining's binary_logloss: 0.0138068\tvalid_1's binary_logloss: 0.0168655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-07 10:55:25,300]\u001b[0m Trial 31 finished with value: 0.03173602206716189 and parameters: {'cf_a': 19, 'ctf_a': 18, 'atfd_a': 8, 'atfp_a': 10, 'pa_a': 0, 'cf_w': 24, 'ctf_w': 21, 'atfd_w': 15, 'atfp_w': 21, 'pa_w': 13, 'cf_m': 15, 'ctf_m': 2, 'atfd_m': 6, 'atfp_m': 14, 'pa_m': 10, 'cf_y': 22, 'ctf_y': 2, 'atfd_y': 22, 'atfp_y': 14, 'pa_y': 8}. Best is trial 26 with value: 0.0320875228289302.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 17593, number of negative: 6568414\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.724265 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12444\n",
      "[LightGBM] [Info] Number of data points in the train set: 6586007, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002671 -> initscore=-5.922527\n",
      "[LightGBM] [Info] Start training from score -5.922527\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[726]\ttraining's binary_logloss: 0.0141947\tvalid_1's binary_logloss: 0.0162106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-07 11:16:16,289]\u001b[0m Trial 32 finished with value: 0.031637504028775326 and parameters: {'cf_a': 22, 'ctf_a': 17, 'atfd_a': 6, 'atfp_a': 8, 'pa_a': 0, 'cf_w': 22, 'ctf_w': 19, 'atfd_w': 9, 'atfp_w': 21, 'pa_w': 11, 'cf_m': 18, 'ctf_m': 2, 'atfd_m': 1, 'atfp_m': 10, 'pa_m': 8, 'cf_y': 22, 'ctf_y': 0, 'atfd_y': 23, 'atfp_y': 18, 'pa_y': 7}. Best is trial 26 with value: 0.0320875228289302.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 18348, number of negative: 6848915\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.811212 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12415\n",
      "[LightGBM] [Info] Number of data points in the train set: 6867263, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002672 -> initscore=-5.922325\n",
      "[LightGBM] [Info] Start training from score -5.922325\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.0140585\tvalid_1's binary_logloss: 0.016513\n",
      "[2000]\ttraining's binary_logloss: 0.0131649\tvalid_1's binary_logloss: 0.016504\n",
      "Early stopping, best iteration is:\n",
      "[2038]\ttraining's binary_logloss: 0.0131378\tvalid_1's binary_logloss: 0.0165036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-07 11:35:22,570]\u001b[0m Trial 33 finished with value: 0.03193739194101715 and parameters: {'cf_a': 19, 'ctf_a': 19, 'atfd_a': 14, 'atfp_a': 11, 'pa_a': 4, 'cf_w': 19, 'ctf_w': 20, 'atfd_w': 14, 'atfp_w': 18, 'pa_w': 14, 'cf_m': 13, 'ctf_m': 1, 'atfd_m': 2, 'atfp_m': 13, 'pa_m': 11, 'cf_y': 24, 'ctf_y': 2, 'atfd_y': 20, 'atfp_y': 12, 'pa_y': 11}. Best is trial 26 with value: 0.0320875228289302.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 20309, number of negative: 7508252\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.822159 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12410\n",
      "[LightGBM] [Info] Number of data points in the train set: 7528561, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002698 -> initscore=-5.912694\n",
      "[LightGBM] [Info] Start training from score -5.912694\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.0145869\tvalid_1's binary_logloss: 0.0167212\n",
      "Early stopping, best iteration is:\n",
      "[1884]\ttraining's binary_logloss: 0.0138481\tvalid_1's binary_logloss: 0.0167126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-07 11:55:23,156]\u001b[0m Trial 34 finished with value: 0.031769516867376155 and parameters: {'cf_a': 16, 'ctf_a': 20, 'atfd_a': 6, 'atfp_a': 12, 'pa_a': 4, 'cf_w': 18, 'ctf_w': 23, 'atfd_w': 13, 'atfp_w': 18, 'pa_w': 20, 'cf_m': 12, 'ctf_m': 0, 'atfd_m': 3, 'atfp_m': 24, 'pa_m': 12, 'cf_y': 24, 'ctf_y': 3, 'atfd_y': 20, 'atfp_y': 19, 'pa_y': 16}. Best is trial 26 with value: 0.0320875228289302.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 18195, number of negative: 6602663\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.769307 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12418\n",
      "[LightGBM] [Info] Number of data points in the train set: 6620858, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002748 -> initscore=-5.894082\n",
      "[LightGBM] [Info] Start training from score -5.894082\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.0144395\tvalid_1's binary_logloss: 0.0168411\n",
      "Early stopping, best iteration is:\n",
      "[1079]\ttraining's binary_logloss: 0.0143547\tvalid_1's binary_logloss: 0.0168398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-07 12:11:20,690]\u001b[0m Trial 35 finished with value: 0.031653218592514354 and parameters: {'cf_a': 19, 'ctf_a': 22, 'atfd_a': 11, 'atfp_a': 4, 'pa_a': 2, 'cf_w': 19, 'ctf_w': 17, 'atfd_w': 9, 'atfp_w': 19, 'pa_w': 15, 'cf_m': 13, 'ctf_m': 8, 'atfd_m': 1, 'atfp_m': 12, 'pa_m': 12, 'cf_y': 24, 'ctf_y': 2, 'atfd_y': 20, 'atfp_y': 10, 'pa_y': 11}. Best is trial 26 with value: 0.0320875228289302.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 17933, number of negative: 6693845\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 2.051236 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12405\n",
      "[LightGBM] [Info] Number of data points in the train set: 6711778, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002672 -> initscore=-5.922301\n",
      "[LightGBM] [Info] Start training from score -5.922301\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.0139904\tvalid_1's binary_logloss: 0.0164715\n",
      "Early stopping, best iteration is:\n",
      "[955]\ttraining's binary_logloss: 0.0140403\tvalid_1's binary_logloss: 0.0164669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-07 12:29:15,159]\u001b[0m Trial 36 finished with value: 0.03165959931191594 and parameters: {'cf_a': 17, 'ctf_a': 19, 'atfd_a': 16, 'atfp_a': 11, 'pa_a': 5, 'cf_w': 19, 'ctf_w': 19, 'atfd_w': 5, 'atfp_w': 15, 'pa_w': 12, 'cf_m': 8, 'ctf_m': 4, 'atfd_m': 0, 'atfp_m': 17, 'pa_m': 15, 'cf_y': 20, 'ctf_y': 0, 'atfd_y': 18, 'atfp_y': 13, 'pa_y': 12}. Best is trial 26 with value: 0.0320875228289302.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 15897, number of negative: 4808267\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.513415 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12394\n",
      "[LightGBM] [Info] Number of data points in the train set: 4824164, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.003295 -> initscore=-5.711962\n",
      "[LightGBM] [Info] Start training from score -5.711962\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.0166613\tvalid_1's binary_logloss: 0.0196234\n",
      "Early stopping, best iteration is:\n",
      "[1596]\ttraining's binary_logloss: 0.0159629\tvalid_1's binary_logloss: 0.0196099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-07 12:43:56,207]\u001b[0m Trial 37 finished with value: 0.03124941146054102 and parameters: {'cf_a': 6, 'ctf_a': 14, 'atfd_a': 14, 'atfp_a': 12, 'pa_a': 2, 'cf_w': 16, 'ctf_w': 24, 'atfd_w': 11, 'atfp_w': 10, 'pa_w': 10, 'cf_m': 11, 'ctf_m': 1, 'atfd_m': 4, 'atfp_m': 7, 'pa_m': 11, 'cf_y': 18, 'ctf_y': 4, 'atfd_y': 5, 'atfp_y': 5, 'pa_y': 5}. Best is trial 26 with value: 0.0320875228289302.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 20205, number of negative: 7765540\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.869509 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12427\n",
      "[LightGBM] [Info] Number of data points in the train set: 7785745, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002595 -> initscore=-5.951521\n",
      "[LightGBM] [Info] Start training from score -5.951521\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[492]\ttraining's binary_logloss: 0.0145376\tvalid_1's binary_logloss: 0.0159216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-07 12:58:58,908]\u001b[0m Trial 38 finished with value: 0.03195195728943285 and parameters: {'cf_a': 20, 'ctf_a': 24, 'atfd_a': 11, 'atfp_a': 8, 'pa_a': 4, 'cf_w': 17, 'ctf_w': 15, 'atfd_w': 14, 'atfp_w': 17, 'pa_w': 18, 'cf_m': 16, 'ctf_m': 6, 'atfd_m': 2, 'atfp_m': 15, 'pa_m': 17, 'cf_y': 23, 'ctf_y': 6, 'atfd_y': 23, 'atfp_y': 21, 'pa_y': 11}. Best is trial 26 with value: 0.0320875228289302.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 20528, number of negative: 7897514\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.880110 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12420\n",
      "[LightGBM] [Info] Number of data points in the train set: 7918042, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002593 -> initscore=-5.952513\n",
      "[LightGBM] [Info] Start training from score -5.952513\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[493]\ttraining's binary_logloss: 0.0145916\tvalid_1's binary_logloss: 0.0160671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-07 13:14:13,269]\u001b[0m Trial 39 finished with value: 0.031969149514301964 and parameters: {'cf_a': 20, 'ctf_a': 24, 'atfd_a': 11, 'atfp_a': 6, 'pa_a': 4, 'cf_w': 17, 'ctf_w': 15, 'atfd_w': 14, 'atfp_w': 17, 'pa_w': 18, 'cf_m': 17, 'ctf_m': 6, 'atfd_m': 2, 'atfp_m': 19, 'pa_m': 18, 'cf_y': 23, 'ctf_y': 6, 'atfd_y': 21, 'atfp_y': 23, 'pa_y': 16}. Best is trial 26 with value: 0.0320875228289302.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 20112, number of negative: 7137752\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.867097 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12283\n",
      "[LightGBM] [Info] Number of data points in the train set: 7157864, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002810 -> initscore=-5.871837\n",
      "[LightGBM] [Info] Start training from score -5.871837\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[692]\ttraining's binary_logloss: 0.0155305\tvalid_1's binary_logloss: 0.0173763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-07 13:29:14,203]\u001b[0m Trial 40 finished with value: 0.03169580802393761 and parameters: {'cf_a': 9, 'ctf_a': 24, 'atfd_a': 11, 'atfp_a': 6, 'pa_a': 4, 'cf_w': 17, 'ctf_w': 14, 'atfd_w': 14, 'atfp_w': 5, 'pa_w': 21, 'cf_m': 17, 'ctf_m': 7, 'atfd_m': 2, 'atfp_m': 19, 'pa_m': 18, 'cf_y': 4, 'ctf_y': 6, 'atfd_y': 21, 'atfp_y': 24, 'pa_y': 17}. Best is trial 26 with value: 0.0320875228289302.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 20321, number of negative: 7632517\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.809171 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12427\n",
      "[LightGBM] [Info] Number of data points in the train set: 7652838, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002655 -> initscore=-5.928518\n",
      "[LightGBM] [Info] Start training from score -5.928518\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.0143605\tvalid_1's binary_logloss: 0.0162916\n",
      "Early stopping, best iteration is:\n",
      "[1350]\ttraining's binary_logloss: 0.0140503\tvalid_1's binary_logloss: 0.0162851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-07 13:47:20,322]\u001b[0m Trial 41 finished with value: 0.03189453464775099 and parameters: {'cf_a': 20, 'ctf_a': 22, 'atfd_a': 11, 'atfp_a': 5, 'pa_a': 2, 'cf_w': 17, 'ctf_w': 15, 'atfd_w': 17, 'atfp_w': 17, 'pa_w': 18, 'cf_m': 16, 'ctf_m': 5, 'atfd_m': 2, 'atfp_m': 16, 'pa_m': 17, 'cf_y': 23, 'ctf_y': 5, 'atfd_y': 19, 'atfp_y': 21, 'pa_y': 18}. Best is trial 26 with value: 0.0320875228289302.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 20316, number of negative: 8066241\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.897663 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12446\n",
      "[LightGBM] [Info] Number of data points in the train set: 8086557, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002512 -> initscore=-5.984034\n",
      "[LightGBM] [Info] Start training from score -5.984034\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.0135917\tvalid_1's binary_logloss: 0.0155386\n",
      "Early stopping, best iteration is:\n",
      "[1569]\ttraining's binary_logloss: 0.013111\tvalid_1's binary_logloss: 0.0155299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-07 14:07:36,195]\u001b[0m Trial 42 finished with value: 0.03206648461350956 and parameters: {'cf_a': 23, 'ctf_a': 23, 'atfd_a': 13, 'atfp_a': 8, 'pa_a': 6, 'cf_w': 15, 'ctf_w': 16, 'atfd_w': 13, 'atfp_w': 16, 'pa_w': 17, 'cf_m': 17, 'ctf_m': 3, 'atfd_m': 0, 'atfp_m': 18, 'pa_m': 20, 'cf_y': 23, 'ctf_y': 10, 'atfd_y': 23, 'atfp_y': 22, 'pa_y': 14}. Best is trial 26 with value: 0.0320875228289302.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 20693, number of negative: 8192096\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.856327 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12448\n",
      "[LightGBM] [Info] Number of data points in the train set: 8212789, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002520 -> initscore=-5.981130\n",
      "[LightGBM] [Info] Start training from score -5.981130\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[485]\ttraining's binary_logloss: 0.0142279\tvalid_1's binary_logloss: 0.0155746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-07 14:23:32,982]\u001b[0m Trial 43 finished with value: 0.031939638487650926 and parameters: {'cf_a': 23, 'ctf_a': 23, 'atfd_a': 13, 'atfp_a': 8, 'pa_a': 7, 'cf_w': 14, 'ctf_w': 16, 'atfd_w': 14, 'atfp_w': 15, 'pa_w': 17, 'cf_m': 18, 'ctf_m': 10, 'atfd_m': 0, 'atfp_m': 20, 'pa_m': 21, 'cf_y': 23, 'ctf_y': 10, 'atfd_y': 23, 'atfp_y': 22, 'pa_y': 13}. Best is trial 26 with value: 0.0320875228289302.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 20325, number of negative: 7885790\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.976017 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12438\n",
      "[LightGBM] [Info] Number of data points in the train set: 7906115, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002571 -> initscore=-5.960966\n",
      "[LightGBM] [Info] Start training from score -5.960966\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.0139166\tvalid_1's binary_logloss: 0.0158177\n",
      "Early stopping, best iteration is:\n",
      "[1505]\ttraining's binary_logloss: 0.0134887\tvalid_1's binary_logloss: 0.0158112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-07 14:43:01,245]\u001b[0m Trial 44 finished with value: 0.03184898911100404 and parameters: {'cf_a': 23, 'ctf_a': 23, 'atfd_a': 7, 'atfp_a': 8, 'pa_a': 7, 'cf_w': 14, 'ctf_w': 13, 'atfd_w': 13, 'atfp_w': 15, 'pa_w': 17, 'cf_m': 18, 'ctf_m': 10, 'atfd_m': 0, 'atfp_m': 21, 'pa_m': 20, 'cf_y': 23, 'ctf_y': 10, 'atfd_y': 23, 'atfp_y': 22, 'pa_y': 14}. Best is trial 26 with value: 0.0320875228289302.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 22064, number of negative: 8783762\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.852634 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12449\n",
      "[LightGBM] [Info] Number of data points in the train set: 8805826, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002506 -> initscore=-5.986713\n",
      "[LightGBM] [Info] Start training from score -5.986713\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[493]\ttraining's binary_logloss: 0.0143158\tvalid_1's binary_logloss: 0.0157651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-07 14:59:33,142]\u001b[0m Trial 45 finished with value: 0.031613915417631526 and parameters: {'cf_a': 23, 'ctf_a': 23, 'atfd_a': 13, 'atfp_a': 0, 'pa_a': 10, 'cf_w': 14, 'ctf_w': 16, 'atfd_w': 16, 'atfp_w': 16, 'pa_w': 22, 'cf_m': 19, 'ctf_m': 7, 'atfd_m': 3, 'atfp_m': 19, 'pa_m': 22, 'cf_y': 21, 'ctf_y': 10, 'atfd_y': 24, 'atfp_y': 23, 'pa_y': 20}. Best is trial 26 with value: 0.0320875228289302.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 19851, number of negative: 7129988\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 2.365754 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12436\n",
      "[LightGBM] [Info] Number of data points in the train set: 7149839, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002776 -> initscore=-5.883810\n",
      "[LightGBM] [Info] Start training from score -5.883810\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.0149174\tvalid_1's binary_logloss: 0.0169937\n",
      "Early stopping, best iteration is:\n",
      "[1207]\ttraining's binary_logloss: 0.0147239\tvalid_1's binary_logloss: 0.0169904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-07 15:18:36,526]\u001b[0m Trial 46 finished with value: 0.03182401105762158 and parameters: {'cf_a': 24, 'ctf_a': 24, 'atfd_a': 10, 'atfp_a': 8, 'pa_a': 8, 'cf_w': 15, 'ctf_w': 11, 'atfd_w': 12, 'atfp_w': 12, 'pa_w': 19, 'cf_m': 17, 'ctf_m': 6, 'atfd_m': 0, 'atfp_m': 20, 'pa_m': 19, 'cf_y': 23, 'ctf_y': 8, 'atfd_y': 8, 'atfp_y': 19, 'pa_y': 13}. Best is trial 26 with value: 0.0320875228289302.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 20918, number of negative: 8255043\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.864048 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12401\n",
      "[LightGBM] [Info] Number of data points in the train set: 8275961, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002528 -> initscore=-5.977970\n",
      "[LightGBM] [Info] Start training from score -5.977970\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[501]\ttraining's binary_logloss: 0.014306\tvalid_1's binary_logloss: 0.015837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-07 15:34:31,236]\u001b[0m Trial 47 finished with value: 0.03161105530163492 and parameters: {'cf_a': 21, 'ctf_a': 21, 'atfd_a': 16, 'atfp_a': 2, 'pa_a': 7, 'cf_w': 12, 'ctf_w': 15, 'atfd_w': 17, 'atfp_w': 14, 'pa_w': 17, 'cf_m': 20, 'ctf_m': 11, 'atfd_m': 1, 'atfp_m': 23, 'pa_m': 22, 'cf_y': 21, 'ctf_y': 11, 'atfd_y': 23, 'atfp_y': 20, 'pa_y': 15}. Best is trial 26 with value: 0.0320875228289302.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 21553, number of negative: 7928227\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.977860 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12355\n",
      "[LightGBM] [Info] Number of data points in the train set: 7949780, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002711 -> initscore=-5.907670\n",
      "[LightGBM] [Info] Start training from score -5.907670\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.0148619\tvalid_1's binary_logloss: 0.0170088\n",
      "Early stopping, best iteration is:\n",
      "[1323]\ttraining's binary_logloss: 0.0145914\tvalid_1's binary_logloss: 0.0170034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-07 15:52:44,954]\u001b[0m Trial 48 finished with value: 0.031849326108027265 and parameters: {'cf_a': 22, 'ctf_a': 22, 'atfd_a': 4, 'atfp_a': 7, 'pa_a': 6, 'cf_w': 16, 'ctf_w': 17, 'atfd_w': 14, 'atfp_w': 16, 'pa_w': 24, 'cf_m': 15, 'ctf_m': 8, 'atfd_m': 4, 'atfp_m': 18, 'pa_m': 21, 'cf_y': 12, 'ctf_y': 6, 'atfd_y': 22, 'atfp_y': 23, 'pa_y': 19}. Best is trial 26 with value: 0.0320875228289302.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 20146, number of negative: 7682640\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.855096 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12418\n",
      "[LightGBM] [Info] Number of data points in the train set: 7702786, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002615 -> initscore=-5.943713\n",
      "[LightGBM] [Info] Start training from score -5.943713\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[494]\ttraining's binary_logloss: 0.0146454\tvalid_1's binary_logloss: 0.0161549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-07 16:08:04,449]\u001b[0m Trial 49 finished with value: 0.03194977590868806 and parameters: {'cf_a': 23, 'ctf_a': 21, 'atfd_a': 13, 'atfp_a': 5, 'pa_a': 10, 'cf_w': 6, 'ctf_w': 18, 'atfd_w': 18, 'atfp_w': 14, 'pa_w': 16, 'cf_m': 22, 'ctf_m': 3, 'atfd_m': 5, 'atfp_m': 16, 'pa_m': 17, 'cf_y': 19, 'ctf_y': 9, 'atfd_y': 21, 'atfp_y': 22, 'pa_y': 13}. Best is trial 26 with value: 0.0320875228289302.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 20194, number of negative: 7572934\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.718522 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12427\n",
      "[LightGBM] [Info] Number of data points in the train set: 7593128, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002660 -> initscore=-5.926950\n",
      "[LightGBM] [Info] Start training from score -5.926950\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[499]\ttraining's binary_logloss: 0.0149142\tvalid_1's binary_logloss: 0.0164112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-07 16:23:05,385]\u001b[0m Trial 50 finished with value: 0.03171451377586015 and parameters: {'cf_a': 20, 'ctf_a': 21, 'atfd_a': 10, 'atfp_a': 3, 'pa_a': 10, 'cf_w': 5, 'ctf_w': 13, 'atfd_w': 16, 'atfp_w': 9, 'pa_w': 16, 'cf_m': 22, 'ctf_m': 3, 'atfd_m': 8, 'atfp_m': 16, 'pa_m': 17, 'cf_y': 18, 'ctf_y': 7, 'atfd_y': 21, 'atfp_y': 24, 'pa_y': 16}. Best is trial 26 with value: 0.0320875228289302.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 20707, number of negative: 8131630\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.900087 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12419\n",
      "[LightGBM] [Info] Number of data points in the train set: 8152337, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002540 -> initscore=-5.973045\n",
      "[LightGBM] [Info] Start training from score -5.973045\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.0138105\tvalid_1's binary_logloss: 0.0157017\n",
      "[2000]\ttraining's binary_logloss: 0.0130164\tvalid_1's binary_logloss: 0.0156948\n",
      "Early stopping, best iteration is:\n",
      "[2105]\ttraining's binary_logloss: 0.0129424\tvalid_1's binary_logloss: 0.0156936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-07 16:45:02,891]\u001b[0m Trial 51 finished with value: 0.03210657663946859 and parameters: {'cf_a': 23, 'ctf_a': 23, 'atfd_a': 13, 'atfp_a': 5, 'pa_a': 12, 'cf_w': 8, 'ctf_w': 17, 'atfd_w': 18, 'atfp_w': 14, 'pa_w': 18, 'cf_m': 20, 'ctf_m': 5, 'atfd_m': 5, 'atfp_m': 18, 'pa_m': 18, 'cf_y': 23, 'ctf_y': 9, 'atfd_y': 24, 'atfp_y': 22, 'pa_y': 13}. Best is trial 51 with value: 0.03210657663946859.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 20625, number of negative: 8035851\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.793565 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12422\n",
      "[LightGBM] [Info] Number of data points in the train set: 8056476, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002560 -> initscore=-5.965164\n",
      "[LightGBM] [Info] Start training from score -5.965164\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[489]\ttraining's binary_logloss: 0.0144227\tvalid_1's binary_logloss: 0.0158425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-07 17:00:55,615]\u001b[0m Trial 52 finished with value: 0.03166386638433955 and parameters: {'cf_a': 24, 'ctf_a': 24, 'atfd_a': 13, 'atfp_a': 5, 'pa_a': 12, 'cf_w': 7, 'ctf_w': 18, 'atfd_w': 18, 'atfp_w': 12, 'pa_w': 19, 'cf_m': 22, 'ctf_m': 4, 'atfd_m': 5, 'atfp_m': 18, 'pa_m': 16, 'cf_y': 20, 'ctf_y': 9, 'atfd_y': 24, 'atfp_y': 20, 'pa_y': 14}. Best is trial 51 with value: 0.03210657663946859.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 20356, number of negative: 7841284\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.814199 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12421\n",
      "[LightGBM] [Info] Number of data points in the train set: 7861640, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002589 -> initscore=-5.953782\n",
      "[LightGBM] [Info] Start training from score -5.953782\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[500]\ttraining's binary_logloss: 0.0145381\tvalid_1's binary_logloss: 0.0160697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-07 17:16:21,060]\u001b[0m Trial 53 finished with value: 0.0321293428107754 and parameters: {'cf_a': 21, 'ctf_a': 20, 'atfd_a': 15, 'atfp_a': 6, 'pa_a': 11, 'cf_w': 4, 'ctf_w': 18, 'atfd_w': 18, 'atfp_w': 14, 'pa_w': 18, 'cf_m': 20, 'ctf_m': 5, 'atfd_m': 5, 'atfp_m': 15, 'pa_m': 18, 'cf_y': 23, 'ctf_y': 9, 'atfd_y': 21, 'atfp_y': 22, 'pa_y': 12}. Best is trial 53 with value: 0.0321293428107754.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 20377, number of negative: 7852678\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.867362 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12426\n",
      "[LightGBM] [Info] Number of data points in the train set: 7873055, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002588 -> initscore=-5.954203\n",
      "[LightGBM] [Info] Start training from score -5.954203\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[505]\ttraining's binary_logloss: 0.0145453\tvalid_1's binary_logloss: 0.0161123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-07 17:31:51,874]\u001b[0m Trial 54 finished with value: 0.03186549892789353 and parameters: {'cf_a': 21, 'ctf_a': 20, 'atfd_a': 17, 'atfp_a': 9, 'pa_a': 13, 'cf_w': 2, 'ctf_w': 15, 'atfd_w': 12, 'atfp_w': 17, 'pa_w': 20, 'cf_m': 20, 'ctf_m': 5, 'atfd_m': 3, 'atfp_m': 15, 'pa_m': 19, 'cf_y': 23, 'ctf_y': 7, 'atfd_y': 19, 'atfp_y': 21, 'pa_y': 11}. Best is trial 53 with value: 0.0321293428107754.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 19952, number of negative: 8120871\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.826755 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12402\n",
      "[LightGBM] [Info] Number of data points in the train set: 8140823, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002451 -> initscore=-6.008863\n",
      "[LightGBM] [Info] Start training from score -6.008863\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[729]\ttraining's binary_logloss: 0.0137822\tvalid_1's binary_logloss: 0.0154406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-07 17:48:30,868]\u001b[0m Trial 55 finished with value: 0.030554330753437213 and parameters: {'cf_a': 18, 'ctf_a': 23, 'atfd_a': 11, 'atfp_a': 3, 'pa_a': 5, 'cf_w': 3, 'ctf_w': 19, 'atfd_w': 16, 'atfp_w': 20, 'pa_w': 18, 'cf_m': 1, 'ctf_m': 6, 'atfd_m': 7, 'atfp_m': 22, 'pa_m': 18, 'cf_y': 22, 'ctf_y': 14, 'atfd_y': 23, 'atfp_y': 20, 'pa_y': 21}. Best is trial 53 with value: 0.0321293428107754.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 20504, number of negative: 7996558\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 2.205418 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12390\n",
      "[LightGBM] [Info] Number of data points in the train set: 8017062, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002558 -> initscore=-5.966146\n",
      "[LightGBM] [Info] Start training from score -5.966146\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[514]\ttraining's binary_logloss: 0.0143873\tvalid_1's binary_logloss: 0.0159102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-07 18:05:54,224]\u001b[0m Trial 56 finished with value: 0.03187050035352776 and parameters: {'cf_a': 20, 'ctf_a': 22, 'atfd_a': 15, 'atfp_a': 7, 'pa_a': 12, 'cf_w': 9, 'ctf_w': 17, 'atfd_w': 19, 'atfp_w': 16, 'pa_w': 20, 'cf_m': 15, 'ctf_m': 3, 'atfd_m': 2, 'atfp_m': 18, 'pa_m': 14, 'cf_y': 21, 'ctf_y': 11, 'atfd_y': 22, 'atfp_y': 23, 'pa_y': 15}. Best is trial 53 with value: 0.0321293428107754.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 20554, number of negative: 7517243\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.818012 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12411\n",
      "[LightGBM] [Info] Number of data points in the train set: 7537797, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002727 -> initscore=-5.901899\n",
      "[LightGBM] [Info] Start training from score -5.901899\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.0147956\tvalid_1's binary_logloss: 0.0167801\n",
      "Early stopping, best iteration is:\n",
      "[1475]\ttraining's binary_logloss: 0.0143619\tvalid_1's binary_logloss: 0.0167759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-07 18:25:01,246]\u001b[0m Trial 57 finished with value: 0.031994245656822594 and parameters: {'cf_a': 10, 'ctf_a': 23, 'atfd_a': 15, 'atfp_a': 6, 'pa_a': 11, 'cf_w': 3, 'ctf_w': 12, 'atfd_w': 15, 'atfp_w': 0, 'pa_w': 22, 'cf_m': 17, 'ctf_m': 5, 'atfd_m': 3, 'atfp_m': 19, 'pa_m': 16, 'cf_y': 23, 'ctf_y': 13, 'atfd_y': 20, 'atfp_y': 18, 'pa_y': 10}. Best is trial 53 with value: 0.0321293428107754.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 20259, number of negative: 7066462\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 2.300765 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12288\n",
      "[LightGBM] [Info] Number of data points in the train set: 7086721, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002859 -> initscore=-5.854516\n",
      "[LightGBM] [Info] Start training from score -5.854516\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.0155161\tvalid_1's binary_logloss: 0.017706\n",
      "Early stopping, best iteration is:\n",
      "[1075]\ttraining's binary_logloss: 0.0154445\tvalid_1's binary_logloss: 0.0177048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-07 18:42:50,252]\u001b[0m Trial 58 finished with value: 0.031731940575128986 and parameters: {'cf_a': 9, 'ctf_a': 19, 'atfd_a': 15, 'atfp_a': 4, 'pa_a': 9, 'cf_w': 4, 'ctf_w': 10, 'atfd_w': 17, 'atfp_w': 1, 'pa_w': 22, 'cf_m': 17, 'ctf_m': 5, 'atfd_m': 4, 'atfp_m': 22, 'pa_m': 19, 'cf_y': 3, 'ctf_y': 13, 'atfd_y': 20, 'atfp_y': 18, 'pa_y': 17}. Best is trial 53 with value: 0.0321293428107754.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 20384, number of negative: 7290882\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 2.188328 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12323\n",
      "[LightGBM] [Info] Number of data points in the train set: 7311266, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002788 -> initscore=-5.879630\n",
      "[LightGBM] [Info] Start training from score -5.879630\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[569]\ttraining's binary_logloss: 0.0155883\tvalid_1's binary_logloss: 0.0172681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-07 18:59:01,371]\u001b[0m Trial 59 finished with value: 0.031568623148444636 and parameters: {'cf_a': 10, 'ctf_a': 20, 'atfd_a': 17, 'atfp_a': 6, 'pa_a': 11, 'cf_w': 1, 'ctf_w': 13, 'atfd_w': 15, 'atfp_w': 5, 'pa_w': 23, 'cf_m': 21, 'ctf_m': 8, 'atfd_m': 5, 'atfp_m': 20, 'pa_m': 16, 'cf_y': 8, 'ctf_y': 16, 'atfd_y': 18, 'atfp_y': 24, 'pa_y': 9}. Best is trial 53 with value: 0.0321293428107754.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 20896, number of negative: 8079733\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.845045 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12391\n",
      "[LightGBM] [Info] Number of data points in the train set: 8100629, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002580 -> initscore=-5.957556\n",
      "[LightGBM] [Info] Start training from score -5.957556\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.0140561\tvalid_1's binary_logloss: 0.0159955\n",
      "Early stopping, best iteration is:\n",
      "[906]\ttraining's binary_logloss: 0.0141402\tvalid_1's binary_logloss: 0.0159912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-07 19:16:36,658]\u001b[0m Trial 60 finished with value: 0.03183429970759973 and parameters: {'cf_a': 6, 'ctf_a': 23, 'atfd_a': 20, 'atfp_a': 6, 'pa_a': 17, 'cf_w': 8, 'ctf_w': 18, 'atfd_w': 20, 'atfp_w': 7, 'pa_w': 21, 'cf_m': 19, 'ctf_m': 1, 'atfd_m': 7, 'atfp_m': 17, 'pa_m': 14, 'cf_y': 24, 'ctf_y': 13, 'atfd_y': 24, 'atfp_y': 23, 'pa_y': 12}. Best is trial 53 with value: 0.0321293428107754.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 20264, number of negative: 7607387\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.711580 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12385\n",
      "[LightGBM] [Info] Number of data points in the train set: 7627651, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002657 -> initscore=-5.928029\n",
      "[LightGBM] [Info] Start training from score -5.928029\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.0143919\tvalid_1's binary_logloss: 0.0163891\n",
      "Early stopping, best iteration is:\n",
      "[1432]\ttraining's binary_logloss: 0.0140134\tvalid_1's binary_logloss: 0.0163837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-07 19:35:10,111]\u001b[0m Trial 61 finished with value: 0.03201132879768952 and parameters: {'cf_a': 8, 'ctf_a': 24, 'atfd_a': 12, 'atfp_a': 9, 'pa_a': 13, 'cf_w': 3, 'ctf_w': 12, 'atfd_w': 13, 'atfp_w': 18, 'pa_w': 18, 'cf_m': 16, 'ctf_m': 6, 'atfd_m': 3, 'atfp_m': 19, 'pa_m': 18, 'cf_y': 23, 'ctf_y': 11, 'atfd_y': 22, 'atfp_y': 22, 'pa_y': 10}. Best is trial 53 with value: 0.0321293428107754.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 20401, number of negative: 7528464\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 2.333119 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12378\n",
      "[LightGBM] [Info] Number of data points in the train set: 7548865, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002703 -> initscore=-5.910862\n",
      "[LightGBM] [Info] Start training from score -5.910862\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.01466\tvalid_1's binary_logloss: 0.0167398\n",
      "Early stopping, best iteration is:\n",
      "[1179]\ttraining's binary_logloss: 0.0145016\tvalid_1's binary_logloss: 0.0167368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-07 19:54:16,528]\u001b[0m Trial 62 finished with value: 0.0316694568511571 and parameters: {'cf_a': 8, 'ctf_a': 22, 'atfd_a': 12, 'atfp_a': 9, 'pa_a': 14, 'cf_w': 3, 'ctf_w': 10, 'atfd_w': 13, 'atfp_w': 11, 'pa_w': 19, 'cf_m': 18, 'ctf_m': 4, 'atfd_m': 3, 'atfp_m': 21, 'pa_m': 18, 'cf_y': 22, 'ctf_y': 11, 'atfd_y': 21, 'atfp_y': 22, 'pa_y': 10}. Best is trial 53 with value: 0.0321293428107754.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 19583, number of negative: 7223682\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.663553 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12384\n",
      "[LightGBM] [Info] Number of data points in the train set: 7243265, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002704 -> initscore=-5.910458\n",
      "[LightGBM] [Info] Start training from score -5.910458\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.0145156\tvalid_1's binary_logloss: 0.0167598\n",
      "Early stopping, best iteration is:\n",
      "[1626]\ttraining's binary_logloss: 0.0139628\tvalid_1's binary_logloss: 0.0167505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-07 20:12:43,265]\u001b[0m Trial 63 finished with value: 0.031639917418136064 and parameters: {'cf_a': 4, 'ctf_a': 21, 'atfd_a': 16, 'atfp_a': 5, 'pa_a': 14, 'cf_w': 0, 'ctf_w': 12, 'atfd_w': 18, 'atfp_w': 13, 'pa_w': 15, 'cf_m': 20, 'ctf_m': 7, 'atfd_m': 3, 'atfp_m': 19, 'pa_m': 15, 'cf_y': 21, 'ctf_y': 14, 'atfd_y': 22, 'atfp_y': 19, 'pa_y': 12}. Best is trial 53 with value: 0.0321293428107754.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 20105, number of negative: 7518238\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.847504 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12384\n",
      "[LightGBM] [Info] Number of data points in the train set: 7538343, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002667 -> initscore=-5.924119\n",
      "[LightGBM] [Info] Start training from score -5.924119\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.0144183\tvalid_1's binary_logloss: 0.0165115\n",
      "Early stopping, best iteration is:\n",
      "[1009]\ttraining's binary_logloss: 0.0144077\tvalid_1's binary_logloss: 0.0165111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-07 20:29:27,959]\u001b[0m Trial 64 finished with value: 0.031613699896211246 and parameters: {'cf_a': 10, 'ctf_a': 23, 'atfd_a': 18, 'atfp_a': 10, 'pa_a': 9, 'cf_w': 5, 'ctf_w': 12, 'atfd_w': 15, 'atfp_w': 18, 'pa_w': 16, 'cf_m': 15, 'ctf_m': 3, 'atfd_m': 1, 'atfp_m': 18, 'pa_m': 21, 'cf_y': 24, 'ctf_y': 9, 'atfd_y': 17, 'atfp_y': 17, 'pa_y': 14}. Best is trial 53 with value: 0.0321293428107754.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 20381, number of negative: 7246602\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.764473 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12399\n",
      "[LightGBM] [Info] Number of data points in the train set: 7266983, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002805 -> initscore=-5.873685\n",
      "[LightGBM] [Info] Start training from score -5.873685\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.015201\tvalid_1's binary_logloss: 0.0173635\n",
      "Early stopping, best iteration is:\n",
      "[1073]\ttraining's binary_logloss: 0.0151329\tvalid_1's binary_logloss: 0.0173617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-07 20:46:02,466]\u001b[0m Trial 65 finished with value: 0.031727895513414484 and parameters: {'cf_a': 12, 'ctf_a': 24, 'atfd_a': 15, 'atfp_a': 13, 'pa_a': 11, 'cf_w': 3, 'ctf_w': 14, 'atfd_w': 12, 'atfp_w': 20, 'pa_w': 22, 'cf_m': 17, 'ctf_m': 5, 'atfd_m': 4, 'atfp_m': 20, 'pa_m': 19, 'cf_y': 23, 'ctf_y': 8, 'atfd_y': 0, 'atfp_y': 20, 'pa_y': 9}. Best is trial 53 with value: 0.0321293428107754.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 19769, number of negative: 7011609\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.600169 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12393\n",
      "[LightGBM] [Info] Number of data points in the train set: 7031378, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002812 -> initscore=-5.871207\n",
      "[LightGBM] [Info] Start training from score -5.871207\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.0151072\tvalid_1's binary_logloss: 0.0172124\n",
      "Early stopping, best iteration is:\n",
      "[1041]\ttraining's binary_logloss: 0.0150646\tvalid_1's binary_logloss: 0.017211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-07 21:01:32,032]\u001b[0m Trial 66 finished with value: 0.03187945915983659 and parameters: {'cf_a': 11, 'ctf_a': 20, 'atfd_a': 10, 'atfp_a': 7, 'pa_a': 13, 'cf_w': 2, 'ctf_w': 20, 'atfd_w': 16, 'atfp_w': 14, 'pa_w': 18, 'cf_m': 23, 'ctf_m': 4, 'atfd_m': 1, 'atfp_m': 17, 'pa_m': 16, 'cf_y': 19, 'ctf_y': 12, 'atfd_y': 19, 'atfp_y': 22, 'pa_y': 7}. Best is trial 53 with value: 0.0321293428107754.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 21206, number of negative: 8464397\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.752317 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12385\n",
      "[LightGBM] [Info] Number of data points in the train set: 8485603, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002499 -> initscore=-5.989340\n",
      "[LightGBM] [Info] Start training from score -5.989340\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.0136893\tvalid_1's binary_logloss: 0.0155934\n",
      "Early stopping, best iteration is:\n",
      "[1183]\ttraining's binary_logloss: 0.0135257\tvalid_1's binary_logloss: 0.0155909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-07 21:19:29,672]\u001b[0m Trial 67 finished with value: 0.0315845774755393 and parameters: {'cf_a': 8, 'ctf_a': 16, 'atfd_a': 23, 'atfp_a': 11, 'pa_a': 1, 'cf_w': 4, 'ctf_w': 9, 'atfd_w': 10, 'atfp_w': 2, 'pa_w': 17, 'cf_m': 19, 'ctf_m': 9, 'atfd_m': 21, 'atfp_m': 23, 'pa_m': 20, 'cf_y': 22, 'ctf_y': 13, 'atfd_y': 22, 'atfp_y': 21, 'pa_y': 16}. Best is trial 53 with value: 0.0321293428107754.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 19838, number of negative: 7547704\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.791673 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12436\n",
      "[LightGBM] [Info] Number of data points in the train set: 7567542, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002621 -> initscore=-5.941399\n",
      "[LightGBM] [Info] Start training from score -5.941399\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[508]\ttraining's binary_logloss: 0.0146712\tvalid_1's binary_logloss: 0.0165226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-07 21:33:53,267]\u001b[0m Trial 68 finished with value: 0.03175902125524969 and parameters: {'cf_a': 14, 'ctf_a': 22, 'atfd_a': 12, 'atfp_a': 4, 'pa_a': 11, 'cf_w': 10, 'ctf_w': 16, 'atfd_w': 21, 'atfp_w': 19, 'pa_w': 13, 'cf_m': 14, 'ctf_m': 6, 'atfd_m': 8, 'atfp_m': 19, 'pa_m': 18, 'cf_y': 20, 'ctf_y': 18, 'atfd_y': 24, 'atfp_y': 16, 'pa_y': 12}. Best is trial 53 with value: 0.0321293428107754.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 21164, number of negative: 7899039\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.648821 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12366\n",
      "[LightGBM] [Info] Number of data points in the train set: 7920203, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002672 -> initscore=-5.922195\n",
      "[LightGBM] [Info] Start training from score -5.922195\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.0146384\tvalid_1's binary_logloss: 0.0169691\n",
      "Early stopping, best iteration is:\n",
      "[1696]\ttraining's binary_logloss: 0.0140637\tvalid_1's binary_logloss: 0.0169623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-07 21:52:25,252]\u001b[0m Trial 69 finished with value: 0.03154367361166248 and parameters: {'cf_a': 5, 'ctf_a': 23, 'atfd_a': 14, 'atfp_a': 9, 'pa_a': 15, 'cf_w': 6, 'ctf_w': 19, 'atfd_w': 17, 'atfp_w': 13, 'pa_w': 20, 'cf_m': 16, 'ctf_m': 14, 'atfd_m': 6, 'atfp_m': 16, 'pa_m': 23, 'cf_y': 21, 'ctf_y': 15, 'atfd_y': 20, 'atfp_y': 23, 'pa_y': 10}. Best is trial 53 with value: 0.0321293428107754.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 18569, number of negative: 5953030\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.559148 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12342\n",
      "[LightGBM] [Info] Number of data points in the train set: 5971599, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.003110 -> initscore=-5.770162\n",
      "[LightGBM] [Info] Start training from score -5.770162\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.016472\tvalid_1's binary_logloss: 0.0190836\n",
      "Early stopping, best iteration is:\n",
      "[1318]\ttraining's binary_logloss: 0.0161293\tvalid_1's binary_logloss: 0.0190794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-07 22:06:24,873]\u001b[0m Trial 70 finished with value: 0.03174468767891601 and parameters: {'cf_a': 1, 'ctf_a': 17, 'atfd_a': 8, 'atfp_a': 2, 'pa_a': 8, 'cf_w': 7, 'ctf_w': 12, 'atfd_w': 19, 'atfp_w': 18, 'pa_w': 15, 'cf_m': 21, 'ctf_m': 1, 'atfd_m': 5, 'atfp_m': 22, 'pa_m': 13, 'cf_y': 14, 'ctf_y': 11, 'atfd_y': 15, 'atfp_y': 18, 'pa_y': 13}. Best is trial 53 with value: 0.0321293428107754.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 20104, number of negative: 7860772\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.960789 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12421\n",
      "[LightGBM] [Info] Number of data points in the train set: 7880876, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002551 -> initscore=-5.968721\n",
      "[LightGBM] [Info] Start training from score -5.968721\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[699]\ttraining's binary_logloss: 0.0140899\tvalid_1's binary_logloss: 0.015684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-07 22:21:53,920]\u001b[0m Trial 71 finished with value: 0.03204436109290054 and parameters: {'cf_a': 22, 'ctf_a': 24, 'atfd_a': 12, 'atfp_a': 8, 'pa_a': 3, 'cf_w': 1, 'ctf_w': 15, 'atfd_w': 14, 'atfp_w': 17, 'pa_w': 18, 'cf_m': 16, 'ctf_m': 6, 'atfd_m': 2, 'atfp_m': 15, 'pa_m': 17, 'cf_y': 23, 'ctf_y': 5, 'atfd_y': 23, 'atfp_y': 21, 'pa_y': 11}. Best is trial 53 with value: 0.0321293428107754.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 20188, number of negative: 7754572\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.761743 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12421\n",
      "[LightGBM] [Info] Number of data points in the train set: 7774760, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002597 -> initscore=-5.950950\n",
      "[LightGBM] [Info] Start training from score -5.950950\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[498]\ttraining's binary_logloss: 0.0145737\tvalid_1's binary_logloss: 0.0160765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-07 22:36:22,652]\u001b[0m Trial 72 finished with value: 0.03194541277340019 and parameters: {'cf_a': 21, 'ctf_a': 24, 'atfd_a': 12, 'atfp_a': 7, 'pa_a': 1, 'cf_w': 1, 'ctf_w': 17, 'atfd_w': 13, 'atfp_w': 16, 'pa_w': 19, 'cf_m': 17, 'ctf_m': 5, 'atfd_m': 1, 'atfp_m': 13, 'pa_m': 17, 'cf_y': 24, 'ctf_y': 5, 'atfd_y': 21, 'atfp_y': 21, 'pa_y': 14}. Best is trial 53 with value: 0.0321293428107754.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 20225, number of negative: 7902535\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.816641 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12424\n",
      "[LightGBM] [Info] Number of data points in the train set: 7922760, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002553 -> initscore=-5.968019\n",
      "[LightGBM] [Info] Start training from score -5.968019\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[532]\ttraining's binary_logloss: 0.0142912\tvalid_1's binary_logloss: 0.0157462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-07 22:51:15,510]\u001b[0m Trial 73 finished with value: 0.031922687683214365 and parameters: {'cf_a': 22, 'ctf_a': 22, 'atfd_a': 13, 'atfp_a': 6, 'pa_a': 3, 'cf_w': 1, 'ctf_w': 14, 'atfd_w': 15, 'atfp_w': 15, 'pa_w': 18, 'cf_m': 19, 'ctf_m': 3, 'atfd_m': 4, 'atfp_m': 17, 'pa_m': 16, 'cf_y': 23, 'ctf_y': 10, 'atfd_y': 22, 'atfp_y': 24, 'pa_y': 9}. Best is trial 53 with value: 0.0321293428107754.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 20147, number of negative: 8103620\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.766034 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12434\n",
      "[LightGBM] [Info] Number of data points in the train set: 8123767, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002480 -> initscore=-5.997011\n",
      "[LightGBM] [Info] Start training from score -5.997011\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.0134452\tvalid_1's binary_logloss: 0.0154429\n",
      "Early stopping, best iteration is:\n",
      "[1403]\ttraining's binary_logloss: 0.0130891\tvalid_1's binary_logloss: 0.015435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-07 23:09:38,650]\u001b[0m Trial 74 finished with value: 0.03188853182444284 and parameters: {'cf_a': 24, 'ctf_a': 21, 'atfd_a': 12, 'atfp_a': 10, 'pa_a': 3, 'cf_w': 4, 'ctf_w': 13, 'atfd_w': 14, 'atfp_w': 19, 'pa_w': 16, 'cf_m': 14, 'ctf_m': 7, 'atfd_m': 2, 'atfp_m': 14, 'pa_m': 20, 'cf_y': 22, 'ctf_y': 22, 'atfd_y': 23, 'atfp_y': 22, 'pa_y': 11}. Best is trial 53 with value: 0.0321293428107754.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 20193, number of negative: 7763311\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.806278 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12386\n",
      "[LightGBM] [Info] Number of data points in the train set: 7783504, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002594 -> initscore=-5.951828\n",
      "[LightGBM] [Info] Start training from score -5.951828\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.0140296\tvalid_1's binary_logloss: 0.0160301\n",
      "Early stopping, best iteration is:\n",
      "[1419]\ttraining's binary_logloss: 0.0136617\tvalid_1's binary_logloss: 0.0160277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-07 23:27:19,010]\u001b[0m Trial 75 finished with value: 0.031865798040908895 and parameters: {'cf_a': 7, 'ctf_a': 24, 'atfd_a': 14, 'atfp_a': 8, 'pa_a': 6, 'cf_w': 12, 'ctf_w': 22, 'atfd_w': 11, 'atfp_w': 17, 'pa_w': 17, 'cf_m': 16, 'ctf_m': 8, 'atfd_m': 3, 'atfp_m': 21, 'pa_m': 15, 'cf_y': 24, 'ctf_y': 8, 'atfd_y': 24, 'atfp_y': 23, 'pa_y': 7}. Best is trial 53 with value: 0.0321293428107754.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 20619, number of negative: 8028079\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.831061 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12436\n",
      "[LightGBM] [Info] Number of data points in the train set: 8048698, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002562 -> initscore=-5.964488\n",
      "[LightGBM] [Info] Start training from score -5.964488\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[530]\ttraining's binary_logloss: 0.0143992\tvalid_1's binary_logloss: 0.0159718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-07 23:42:36,150]\u001b[0m Trial 76 finished with value: 0.03153709373343056 and parameters: {'cf_a': 22, 'ctf_a': 23, 'atfd_a': 15, 'atfp_a': 7, 'pa_a': 13, 'cf_w': 2, 'ctf_w': 11, 'atfd_w': 16, 'atfp_w': 16, 'pa_w': 21, 'cf_m': 18, 'ctf_m': 4, 'atfd_m': 0, 'atfp_m': 18, 'pa_m': 18, 'cf_y': 23, 'ctf_y': 4, 'atfd_y': 21, 'atfp_y': 19, 'pa_y': 13}. Best is trial 53 with value: 0.0321293428107754.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 19325, number of negative: 6709426\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.636022 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12370\n",
      "[LightGBM] [Info] Number of data points in the train set: 6728751, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002872 -> initscore=-5.849869\n",
      "[LightGBM] [Info] Start training from score -5.849869\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.0153792\tvalid_1's binary_logloss: 0.0175362\n",
      "Early stopping, best iteration is:\n",
      "[940]\ttraining's binary_logloss: 0.0154451\tvalid_1's binary_logloss: 0.0175352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-07 23:57:33,981]\u001b[0m Trial 77 finished with value: 0.03145888342412526 and parameters: {'cf_a': 11, 'ctf_a': 24, 'atfd_a': 10, 'atfp_a': 5, 'pa_a': 1, 'cf_w': 0, 'ctf_w': 15, 'atfd_w': 12, 'atfp_w': 14, 'pa_w': 19, 'cf_m': 15, 'ctf_m': 6, 'atfd_m': 2, 'atfp_m': 19, 'pa_m': 14, 'cf_y': 22, 'ctf_y': 12, 'atfd_y': 12, 'atfp_y': 20, 'pa_y': 4}. Best is trial 53 with value: 0.0321293428107754.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 21136, number of negative: 8252196\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.821292 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12403\n",
      "[LightGBM] [Info] Number of data points in the train set: 8273332, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002555 -> initscore=-5.967257\n",
      "[LightGBM] [Info] Start training from score -5.967257\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[507]\ttraining's binary_logloss: 0.014444\tvalid_1's binary_logloss: 0.0160389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-08 00:12:26,973]\u001b[0m Trial 78 finished with value: 0.031916703681822665 and parameters: {'cf_a': 22, 'ctf_a': 18, 'atfd_a': 18, 'atfp_a': 4, 'pa_a': 12, 'cf_w': 13, 'ctf_w': 16, 'atfd_w': 13, 'atfp_w': 20, 'pa_w': 23, 'cf_m': 20, 'ctf_m': 5, 'atfd_m': 1, 'atfp_m': 20, 'pa_m': 19, 'cf_y': 21, 'ctf_y': 7, 'atfd_y': 20, 'atfp_y': 24, 'pa_y': 10}. Best is trial 53 with value: 0.0321293428107754.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 19443, number of negative: 7996585\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.002278 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12444\n",
      "[LightGBM] [Info] Number of data points in the train set: 8016028, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002426 -> initscore=-6.019283\n",
      "[LightGBM] [Info] Start training from score -6.019283\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[555]\ttraining's binary_logloss: 0.0134704\tvalid_1's binary_logloss: 0.0151014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-08 00:28:36,450]\u001b[0m Trial 79 finished with value: 0.0315960419308536 and parameters: {'cf_a': 23, 'ctf_a': 19, 'atfd_a': 21, 'atfp_a': 6, 'pa_a': 16, 'cf_w': 3, 'ctf_w': 20, 'atfd_w': 10, 'atfp_w': 17, 'pa_w': 12, 'cf_m': 17, 'ctf_m': 0, 'atfd_m': 10, 'atfp_m': 11, 'pa_m': 15, 'cf_y': 24, 'ctf_y': 1, 'atfd_y': 22, 'atfp_y': 21, 'pa_y': 17}. Best is trial 53 with value: 0.0321293428107754.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 18785, number of negative: 6562822\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.609568 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12374\n",
      "[LightGBM] [Info] Number of data points in the train set: 6581607, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002854 -> initscore=-5.856117\n",
      "[LightGBM] [Info] Start training from score -5.856117\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.0152836\tvalid_1's binary_logloss: 0.0174865\n",
      "Early stopping, best iteration is:\n",
      "[1324]\ttraining's binary_logloss: 0.0149611\tvalid_1's binary_logloss: 0.0174823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-08 00:44:40,844]\u001b[0m Trial 80 finished with value: 0.03141142228258981 and parameters: {'cf_a': 16, 'ctf_a': 22, 'atfd_a': 1, 'atfp_a': 9, 'pa_a': 5, 'cf_w': 1, 'ctf_w': 14, 'atfd_w': 15, 'atfp_w': 0, 'pa_w': 16, 'cf_m': 11, 'ctf_m': 2, 'atfd_m': 5, 'atfp_m': 15, 'pa_m': 17, 'cf_y': 10, 'ctf_y': 8, 'atfd_y': 19, 'atfp_y': 22, 'pa_y': 15}. Best is trial 53 with value: 0.0321293428107754.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 20220, number of negative: 7783857\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.774017 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12427\n",
      "[LightGBM] [Info] Number of data points in the train set: 7804077, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002591 -> initscore=-5.953135\n",
      "[LightGBM] [Info] Start training from score -5.953135\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.0139881\tvalid_1's binary_logloss: 0.0158506\n",
      "Early stopping, best iteration is:\n",
      "[1165]\ttraining's binary_logloss: 0.0138396\tvalid_1's binary_logloss: 0.0158479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-08 01:01:44,687]\u001b[0m Trial 81 finished with value: 0.03197133681948774 and parameters: {'cf_a': 21, 'ctf_a': 24, 'atfd_a': 11, 'atfp_a': 8, 'pa_a': 4, 'cf_w': 18, 'ctf_w': 17, 'atfd_w': 14, 'atfp_w': 15, 'pa_w': 18, 'cf_m': 16, 'ctf_m': 6, 'atfd_m': 2, 'atfp_m': 15, 'pa_m': 17, 'cf_y': 23, 'ctf_y': 6, 'atfd_y': 23, 'atfp_y': 21, 'pa_y': 11}. Best is trial 53 with value: 0.0321293428107754.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 19609, number of negative: 7280275\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.632811 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12420\n",
      "[LightGBM] [Info] Number of data points in the train set: 7299884, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002686 -> initscore=-5.916935\n",
      "[LightGBM] [Info] Start training from score -5.916935\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[489]\ttraining's binary_logloss: 0.0149368\tvalid_1's binary_logloss: 0.0166283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-08 01:15:46,769]\u001b[0m Trial 82 finished with value: 0.031550840086315264 and parameters: {'cf_a': 21, 'ctf_a': 23, 'atfd_a': 11, 'atfp_a': 8, 'pa_a': 3, 'cf_w': 18, 'ctf_w': 17, 'atfd_w': 14, 'atfp_w': 15, 'pa_w': 17, 'cf_m': 16, 'ctf_m': 7, 'atfd_m': 2, 'atfp_m': 16, 'pa_m': 18, 'cf_y': 23, 'ctf_y': 3, 'atfd_y': 23, 'atfp_y': 7, 'pa_y': 12}. Best is trial 53 with value: 0.0321293428107754.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 20234, number of negative: 7762539\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.741950 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12412\n",
      "[LightGBM] [Info] Number of data points in the train set: 7782773, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002600 -> initscore=-5.949700\n",
      "[LightGBM] [Info] Start training from score -5.949700\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.0140368\tvalid_1's binary_logloss: 0.016017\n",
      "Early stopping, best iteration is:\n",
      "[1571]\ttraining's binary_logloss: 0.0135457\tvalid_1's binary_logloss: 0.0160108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-08 01:34:14,598]\u001b[0m Trial 83 finished with value: 0.03183659906270579 and parameters: {'cf_a': 13, 'ctf_a': 24, 'atfd_a': 13, 'atfp_a': 9, 'pa_a': 4, 'cf_w': 21, 'ctf_w': 17, 'atfd_w': 13, 'atfp_w': 18, 'pa_w': 18, 'cf_m': 18, 'ctf_m': 5, 'atfd_m': 4, 'atfp_m': 14, 'pa_m': 16, 'cf_y': 22, 'ctf_y': 5, 'atfd_y': 24, 'atfp_y': 23, 'pa_y': 11}. Best is trial 53 with value: 0.0321293428107754.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 20527, number of negative: 7506570\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.785255 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12400\n",
      "[LightGBM] [Info] Number of data points in the train set: 7527097, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002727 -> initscore=-5.901793\n",
      "[LightGBM] [Info] Start training from score -5.901793\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[852]\ttraining's binary_logloss: 0.0149286\tvalid_1's binary_logloss: 0.0168522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-08 01:49:55,565]\u001b[0m Trial 84 finished with value: 0.031778924011781326 and parameters: {'cf_a': 8, 'ctf_a': 23, 'atfd_a': 10, 'atfp_a': 11, 'pa_a': 6, 'cf_w': 15, 'ctf_w': 18, 'atfd_w': 15, 'atfp_w': 12, 'pa_w': 20, 'cf_m': 14, 'ctf_m': 4, 'atfd_m': 3, 'atfp_m': 17, 'pa_m': 19, 'cf_y': 24, 'ctf_y': 7, 'atfd_y': 22, 'atfp_y': 21, 'pa_y': 8}. Best is trial 53 with value: 0.0321293428107754.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 18738, number of negative: 6472427\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.872372 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12474\n",
      "[LightGBM] [Info] Number of data points in the train set: 6491165, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002887 -> initscore=-5.844753\n",
      "[LightGBM] [Info] Start training from score -5.844753\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.0152971\tvalid_1's binary_logloss: 0.0177875\n",
      "Early stopping, best iteration is:\n",
      "[1119]\ttraining's binary_logloss: 0.0151775\tvalid_1's binary_logloss: 0.0177841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-08 02:05:57,184]\u001b[0m Trial 85 finished with value: 0.03170220576893349 and parameters: {'cf_a': 23, 'ctf_a': 21, 'atfd_a': 8, 'atfp_a': 7, 'pa_a': 2, 'cf_w': 20, 'ctf_w': 19, 'atfd_w': 18, 'atfp_w': 15, 'pa_w': 15, 'cf_m': 13, 'ctf_m': 6, 'atfd_m': 0, 'atfp_m': 19, 'pa_m': 17, 'cf_y': 23, 'ctf_y': 9, 'atfd_y': 2, 'atfp_y': 20, 'pa_y': 10}. Best is trial 53 with value: 0.0321293428107754.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 19990, number of negative: 7508504\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.727723 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12414\n",
      "[LightGBM] [Info] Number of data points in the train set: 7528494, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002655 -> initscore=-5.928559\n",
      "[LightGBM] [Info] Start training from score -5.928559\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.0143043\tvalid_1's binary_logloss: 0.0164179\n",
      "Early stopping, best iteration is:\n",
      "[1207]\ttraining's binary_logloss: 0.014108\tvalid_1's binary_logloss: 0.0164146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-08 02:22:21,565]\u001b[0m Trial 86 finished with value: 0.031587822263615103 and parameters: {'cf_a': 20, 'ctf_a': 3, 'atfd_a': 9, 'atfp_a': 10, 'pa_a': 11, 'cf_w': 11, 'ctf_w': 15, 'atfd_w': 16, 'atfp_w': 4, 'pa_w': 18, 'cf_m': 17, 'ctf_m': 3, 'atfd_m': 2, 'atfp_m': 18, 'pa_m': 20, 'cf_y': 20, 'ctf_y': 10, 'atfd_y': 23, 'atfp_y': 22, 'pa_y': 1}. Best is trial 53 with value: 0.0321293428107754.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 20659, number of negative: 7615517\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.788920 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12443\n",
      "[LightGBM] [Info] Number of data points in the train set: 7636176, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002705 -> initscore=-5.909792\n",
      "[LightGBM] [Info] Start training from score -5.909792\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.0146656\tvalid_1's binary_logloss: 0.0168498\n",
      "Early stopping, best iteration is:\n",
      "[1205]\ttraining's binary_logloss: 0.0144726\tvalid_1's binary_logloss: 0.0168474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-08 02:39:03,453]\u001b[0m Trial 87 finished with value: 0.03165660727726244 and parameters: {'cf_a': 18, 'ctf_a': 15, 'atfd_a': 13, 'atfp_a': 5, 'pa_a': 1, 'cf_w': 16, 'ctf_w': 18, 'atfd_w': 22, 'atfp_w': 16, 'pa_w': 19, 'cf_m': 15, 'ctf_m': 8, 'atfd_m': 1, 'atfp_m': 13, 'pa_m': 21, 'cf_y': 21, 'ctf_y': 6, 'atfd_y': 21, 'atfp_y': 19, 'pa_y': 14}. Best is trial 53 with value: 0.0321293428107754.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 19530, number of negative: 7213477\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.681039 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12406\n",
      "[LightGBM] [Info] Number of data points in the train set: 7233007, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002700 -> initscore=-5.911755\n",
      "[LightGBM] [Info] Start training from score -5.911755\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.0144692\tvalid_1's binary_logloss: 0.0168368\n",
      "Early stopping, best iteration is:\n",
      "[1629]\ttraining's binary_logloss: 0.0139031\tvalid_1's binary_logloss: 0.0168304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-08 02:56:52,077]\u001b[0m Trial 88 finished with value: 0.03191864957468797 and parameters: {'cf_a': 10, 'ctf_a': 22, 'atfd_a': 12, 'atfp_a': 8, 'pa_a': 5, 'cf_w': 23, 'ctf_w': 16, 'atfd_w': 14, 'atfp_w': 17, 'pa_w': 14, 'cf_m': 23, 'ctf_m': 9, 'atfd_m': 3, 'atfp_m': 15, 'pa_m': 18, 'cf_y': 22, 'ctf_y': 4, 'atfd_y': 20, 'atfp_y': 23, 'pa_y': 13}. Best is trial 53 with value: 0.0321293428107754.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 20300, number of negative: 8191236\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.839946 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12445\n",
      "[LightGBM] [Info] Number of data points in the train set: 8211536, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002472 -> initscore=-6.000199\n",
      "[LightGBM] [Info] Start training from score -6.000199\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[859]\ttraining's binary_logloss: 0.0135255\tvalid_1's binary_logloss: 0.0152043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-08 03:14:24,582]\u001b[0m Trial 89 finished with value: 0.03212678142137493 and parameters: {'cf_a': 24, 'ctf_a': 24, 'atfd_a': 14, 'atfp_a': 13, 'pa_a': 13, 'cf_w': 4, 'ctf_w': 10, 'atfd_w': 0, 'atfp_w': 19, 'pa_w': 20, 'cf_m': 19, 'ctf_m': 6, 'atfd_m': 6, 'atfp_m': 21, 'pa_m': 13, 'cf_y': 23, 'ctf_y': 12, 'atfd_y': 23, 'atfp_y': 22, 'pa_y': 9}. Best is trial 53 with value: 0.0321293428107754.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 20604, number of negative: 8250005\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.725845 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12410\n",
      "[LightGBM] [Info] Number of data points in the train set: 8270609, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002491 -> initscore=-5.992484\n",
      "[LightGBM] [Info] Start training from score -5.992484\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[512]\ttraining's binary_logloss: 0.01403\tvalid_1's binary_logloss: 0.0152644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-08 03:30:02,618]\u001b[0m Trial 90 finished with value: 0.03200760686680523 and parameters: {'cf_a': 23, 'ctf_a': 23, 'atfd_a': 15, 'atfp_a': 11, 'pa_a': 14, 'cf_w': 4, 'ctf_w': 10, 'atfd_w': 1, 'atfp_w': 20, 'pa_w': 21, 'cf_m': 19, 'ctf_m': 7, 'atfd_m': 6, 'atfp_m': 21, 'pa_m': 13, 'cf_y': 24, 'ctf_y': 12, 'atfd_y': 24, 'atfp_y': 21, 'pa_y': 9}. Best is trial 53 with value: 0.0321293428107754.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 20622, number of negative: 8300623\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.801078 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12399\n",
      "[LightGBM] [Info] Number of data points in the train set: 8321245, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002478 -> initscore=-5.997727\n",
      "[LightGBM] [Info] Start training from score -5.997727\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[517]\ttraining's binary_logloss: 0.0139458\tvalid_1's binary_logloss: 0.0151863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-08 03:45:31,320]\u001b[0m Trial 91 finished with value: 0.031871005347536334 and parameters: {'cf_a': 24, 'ctf_a': 23, 'atfd_a': 15, 'atfp_a': 13, 'pa_a': 14, 'cf_w': 4, 'ctf_w': 9, 'atfd_w': 1, 'atfp_w': 20, 'pa_w': 21, 'cf_m': 20, 'ctf_m': 7, 'atfd_m': 6, 'atfp_m': 21, 'pa_m': 13, 'cf_y': 24, 'ctf_y': 12, 'atfd_y': 24, 'atfp_y': 21, 'pa_y': 9}. Best is trial 53 with value: 0.0321293428107754.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 20890, number of negative: 8471265\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.724122 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12405\n",
      "[LightGBM] [Info] Number of data points in the train set: 8492155, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002460 -> initscore=-6.005165\n",
      "[LightGBM] [Info] Start training from score -6.005165\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[553]\ttraining's binary_logloss: 0.0138639\tvalid_1's binary_logloss: 0.0153243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-08 04:01:17,883]\u001b[0m Trial 92 finished with value: 0.03151091078971711 and parameters: {'cf_a': 24, 'ctf_a': 24, 'atfd_a': 14, 'atfp_a': 15, 'pa_a': 13, 'cf_w': 5, 'ctf_w': 10, 'atfd_w': 2, 'atfp_w': 19, 'pa_w': 20, 'cf_m': 19, 'ctf_m': 24, 'atfd_m': 7, 'atfp_m': 23, 'pa_m': 13, 'cf_y': 23, 'ctf_y': 11, 'atfd_y': 23, 'atfp_y': 22, 'pa_y': 6}. Best is trial 53 with value: 0.0321293428107754.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 20574, number of negative: 8289001\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.803971 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12420\n",
      "[LightGBM] [Info] Number of data points in the train set: 8309575, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002476 -> initscore=-5.998657\n",
      "[LightGBM] [Info] Start training from score -5.998657\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[505]\ttraining's binary_logloss: 0.0139526\tvalid_1's binary_logloss: 0.0153798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-08 04:17:07,671]\u001b[0m Trial 93 finished with value: 0.03204500304214641 and parameters: {'cf_a': 23, 'ctf_a': 23, 'atfd_a': 16, 'atfp_a': 12, 'pa_a': 17, 'cf_w': 6, 'ctf_w': 8, 'atfd_w': 0, 'atfp_w': 18, 'pa_w': 22, 'cf_m': 18, 'ctf_m': 5, 'atfd_m': 4, 'atfp_m': 22, 'pa_m': 14, 'cf_y': 24, 'ctf_y': 15, 'atfd_y': 23, 'atfp_y': 20, 'pa_y': 8}. Best is trial 53 with value: 0.0321293428107754.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 20730, number of negative: 8413741\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.852312 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12436\n",
      "[LightGBM] [Info] Number of data points in the train set: 8434471, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002458 -> initscore=-6.006040\n",
      "[LightGBM] [Info] Start training from score -6.006040\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[511]\ttraining's binary_logloss: 0.0138675\tvalid_1's binary_logloss: 0.0153093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-08 04:33:09,609]\u001b[0m Trial 94 finished with value: 0.03171082828591547 and parameters: {'cf_a': 23, 'ctf_a': 22, 'atfd_a': 17, 'atfp_a': 12, 'pa_a': 17, 'cf_w': 6, 'ctf_w': 8, 'atfd_w': 0, 'atfp_w': 21, 'pa_w': 22, 'cf_m': 18, 'ctf_m': 4, 'atfd_m': 5, 'atfp_m': 22, 'pa_m': 14, 'cf_y': 24, 'ctf_y': 15, 'atfd_y': 24, 'atfp_y': 20, 'pa_y': 7}. Best is trial 53 with value: 0.0321293428107754.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 21070, number of negative: 8051322\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.717867 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12405\n",
      "[LightGBM] [Info] Number of data points in the train set: 8072392, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002610 -> initscore=-5.945741\n",
      "[LightGBM] [Info] Start training from score -5.945741\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[504]\ttraining's binary_logloss: 0.0147239\tvalid_1's binary_logloss: 0.0163362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-08 04:48:00,968]\u001b[0m Trial 95 finished with value: 0.03193336552909153 and parameters: {'cf_a': 22, 'ctf_a': 20, 'atfd_a': 16, 'atfp_a': 14, 'pa_a': 15, 'cf_w': 3, 'ctf_w': 5, 'atfd_w': 4, 'atfp_w': 18, 'pa_w': 24, 'cf_m': 20, 'ctf_m': 5, 'atfd_m': 6, 'atfp_m': 24, 'pa_m': 11, 'cf_y': 22, 'ctf_y': 14, 'atfd_y': 22, 'atfp_y': 11, 'pa_y': 8}. Best is trial 53 with value: 0.0321293428107754.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 20808, number of negative: 8314025\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.883692 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12424\n",
      "[LightGBM] [Info] Number of data points in the train set: 8334833, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002497 -> initscore=-5.990362\n",
      "[LightGBM] [Info] Start training from score -5.990362\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[509]\ttraining's binary_logloss: 0.0140789\tvalid_1's binary_logloss: 0.0154515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-08 05:03:53,582]\u001b[0m Trial 96 finished with value: 0.031790562207980426 and parameters: {'cf_a': 24, 'ctf_a': 21, 'atfd_a': 15, 'atfp_a': 14, 'pa_a': 18, 'cf_w': 7, 'ctf_w': 8, 'atfd_w': 0, 'atfp_w': 23, 'pa_w': 22, 'cf_m': 21, 'ctf_m': 2, 'atfd_m': 8, 'atfp_m': 20, 'pa_m': 12, 'cf_y': 24, 'ctf_y': 13, 'atfd_y': 24, 'atfp_y': 18, 'pa_y': 9}. Best is trial 53 with value: 0.0321293428107754.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 20817, number of negative: 7711430\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.840854 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12408\n",
      "[LightGBM] [Info] Number of data points in the train set: 7732247, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002692 -> initscore=-5.914689\n",
      "[LightGBM] [Info] Start training from score -5.914689\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[856]\ttraining's binary_logloss: 0.0147818\tvalid_1's binary_logloss: 0.0167261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-08 05:19:48,370]\u001b[0m Trial 97 finished with value: 0.0316157111011344 and parameters: {'cf_a': 23, 'ctf_a': 23, 'atfd_a': 16, 'atfp_a': 12, 'pa_a': 12, 'cf_w': 2, 'ctf_w': 11, 'atfd_w': 3, 'atfp_w': 19, 'pa_w': 23, 'cf_m': 19, 'ctf_m': 3, 'atfd_m': 13, 'atfp_m': 21, 'pa_m': 15, 'cf_y': 23, 'ctf_y': 16, 'atfd_y': 7, 'atfp_y': 19, 'pa_y': 10}. Best is trial 53 with value: 0.0321293428107754.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 20410, number of negative: 7947586\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.936736 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12411\n",
      "[LightGBM] [Info] Number of data points in the train set: 7967996, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002561 -> initscore=-5.964599\n",
      "[LightGBM] [Info] Start training from score -5.964599\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[494]\ttraining's binary_logloss: 0.0144172\tvalid_1's binary_logloss: 0.0158706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-08 05:34:47,383]\u001b[0m Trial 98 finished with value: 0.031931836061221075 and parameters: {'cf_a': 22, 'ctf_a': 22, 'atfd_a': 14, 'atfp_a': 11, 'pa_a': 21, 'cf_w': 4, 'ctf_w': 6, 'atfd_w': 6, 'atfp_w': 18, 'pa_w': 21, 'cf_m': 18, 'ctf_m': 7, 'atfd_m': 4, 'atfp_m': 23, 'pa_m': 14, 'cf_y': 21, 'ctf_y': 15, 'atfd_y': 23, 'atfp_y': 16, 'pa_y': 5}. Best is trial 53 with value: 0.0321293428107754.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 20436, number of negative: 8280823\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.743416 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12429\n",
      "[LightGBM] [Info] Number of data points in the train set: 8301259, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002462 -> initscore=-6.004400\n",
      "[LightGBM] [Info] Start training from score -6.004400\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[588]\ttraining's binary_logloss: 0.0137457\tvalid_1's binary_logloss: 0.0151915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-08 05:50:29,630]\u001b[0m Trial 99 finished with value: 0.03174320113429383 and parameters: {'cf_a': 24, 'ctf_a': 20, 'atfd_a': 19, 'atfp_a': 13, 'pa_a': 14, 'cf_w': 5, 'ctf_w': 9, 'atfd_w': 1, 'atfp_w': 19, 'pa_w': 21, 'cf_m': 18, 'ctf_m': 1, 'atfd_m': 7, 'atfp_m': 21, 'pa_m': 12, 'cf_y': 24, 'ctf_y': 12, 'atfd_y': 22, 'atfp_y': 20, 'pa_y': 6}. Best is trial 53 with value: 0.0321293428107754.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 20716, number of negative: 8181278\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.754187 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12421\n",
      "[LightGBM] [Info] Number of data points in the train set: 8201994, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002526 -> initscore=-5.978697\n",
      "[LightGBM] [Info] Start training from score -5.978697\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[501]\ttraining's binary_logloss: 0.0142349\tvalid_1's binary_logloss: 0.0157092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-08 06:05:39,029]\u001b[0m Trial 100 finished with value: 0.03153643451575546 and parameters: {'cf_a': 23, 'ctf_a': 23, 'atfd_a': 16, 'atfp_a': 10, 'pa_a': 9, 'cf_w': 6, 'ctf_w': 10, 'atfd_w': 1, 'atfp_w': 20, 'pa_w': 20, 'cf_m': 21, 'ctf_m': 5, 'atfd_m': 9, 'atfp_m': 22, 'pa_m': 16, 'cf_y': 22, 'ctf_y': 10, 'atfd_y': 21, 'atfp_y': 21, 'pa_y': 8}. Best is trial 53 with value: 0.0321293428107754.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 19124, number of negative: 7280770\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.680836 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12400\n",
      "[LightGBM] [Info] Number of data points in the train set: 7299894, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002620 -> initscore=-5.942048\n",
      "[LightGBM] [Info] Start training from score -5.942048\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.0139632\tvalid_1's binary_logloss: 0.0159697\n",
      "Early stopping, best iteration is:\n",
      "[1658]\ttraining's binary_logloss: 0.0133852\tvalid_1's binary_logloss: 0.0159596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-08 06:23:22,233]\u001b[0m Trial 101 finished with value: 0.0316232941875303 and parameters: {'cf_a': 21, 'ctf_a': 24, 'atfd_a': 13, 'atfp_a': 10, 'pa_a': 13, 'cf_w': 9, 'ctf_w': 7, 'atfd_w': 2, 'atfp_w': 14, 'pa_w': 19, 'cf_m': 16, 'ctf_m': 6, 'atfd_m': 3, 'atfp_m': 20, 'pa_m': 13, 'cf_y': 23, 'ctf_y': 13, 'atfd_y': 23, 'atfp_y': 1, 'pa_y': 12}. Best is trial 53 with value: 0.0321293428107754.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 20488, number of negative: 8343553\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.820125 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12404\n",
      "[LightGBM] [Info] Number of data points in the train set: 8364041, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002450 -> initscore=-6.009405\n",
      "[LightGBM] [Info] Start training from score -6.009405\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[497]\ttraining's binary_logloss: 0.0138169\tvalid_1's binary_logloss: 0.0151585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-08 06:39:12,728]\u001b[0m Trial 102 finished with value: 0.03169046486318756 and parameters: {'cf_a': 22, 'ctf_a': 24, 'atfd_a': 17, 'atfp_a': 9, 'pa_a': 15, 'cf_w': 4, 'ctf_w': 12, 'atfd_w': 0, 'atfp_w': 16, 'pa_w': 19, 'cf_m': 16, 'ctf_m': 4, 'atfd_m': 5, 'atfp_m': 24, 'pa_m': 15, 'cf_y': 23, 'ctf_y': 11, 'atfd_y': 23, 'atfp_y': 22, 'pa_y': 11}. Best is trial 53 with value: 0.0321293428107754.\u001b[0m\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 19188, number of negative: 7596686\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.701233 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12405\n",
      "[LightGBM] [Info] Number of data points in the train set: 7615874, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002519 -> initscore=-5.981182\n",
      "[LightGBM] [Info] Start training from score -5.981182\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[475]\ttraining's binary_logloss: 0.0140294\tvalid_1's binary_logloss: 0.0154752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-08 06:53:30,306]\u001b[0m Trial 103 finished with value: 0.03165038522262257 and parameters: {'cf_a': 21, 'ctf_a': 13, 'atfd_a': 14, 'atfp_a': 12, 'pa_a': 11, 'cf_w': 2, 'ctf_w': 8, 'atfd_w': 2, 'atfp_w': 13, 'pa_w': 17, 'cf_m': 17, 'ctf_m': 6, 'atfd_m': 4, 'atfp_m': 19, 'pa_m': 14, 'cf_y': 24, 'ctf_y': 9, 'atfd_y': 24, 'atfp_y': 22, 'pa_y': 10}. Best is trial 53 with value: 0.0321293428107754.\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_14270/3653606818.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'maximize'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    398\u001b[0m             )\n\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    401\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             _optimize_sequential(\n\u001b[0m\u001b[1;32m     67\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_14270/2503583711.py\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtotal_n\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marticles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustomers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_14270/3270927863.py\u001b[0m in \u001b[0;36mrun_train\u001b[0;34m(transactions, articles, customers, Ns)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mtarget_tran\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m't_dat'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mvalid_start\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtransactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m't_dat'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mvalid_end\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mtarget_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_tran\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'customer_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mrecom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_reccomend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory_tran\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mml_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_tran\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mml_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mml_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory_tran\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marticles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustomers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_14270/2911346655.py\u001b[0m in \u001b[0;36mget_reccomend\u001b[0;34m(target_customer_id, history, Ns)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_customer_frequent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cf_a'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_customer_type_frequent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ctf_a'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_article_type_frequent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'department_name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'atfd_a'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_article_type_frequent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'perceived_colour_master_name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'atfp_a'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mpopular_article\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_popular_article\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pa_a'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_14270/2911346655.py\u001b[0m in \u001b[0;36mget_article_type_frequent\u001b[0;34m(history, col, n, timedelta)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m't_dat'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>=\u001b[0m\u001b[0mst_date\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'customer_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m't_dat'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m't_dat'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'cnt'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'customer_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cnt'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/groupby/generic.py\u001b[0m in \u001b[0;36mcount\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    839\u001b[0m             \u001b[0mCount\u001b[0m \u001b[0mof\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0mwithin\u001b[0m \u001b[0meach\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m         \"\"\"\n\u001b[0;32m--> 841\u001b[0;31m         \u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mngroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrouper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup_info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m         \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/_libs/properties.pyx\u001b[0m in \u001b[0;36mpandas._libs.properties.CachedProperty.__get__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/groupby/ops.py\u001b[0m in \u001b[0;36mgroup_info\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    909\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mcache_readonly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgroup_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 911\u001b[0;31m         \u001b[0mcomp_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs_group_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_compressed_codes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m         \u001b[0mngroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs_group_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/groupby/ops.py\u001b[0m in \u001b[0;36m_get_compressed_codes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    930\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupings\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0mgroup_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_group_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxnull\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 932\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcompress_group_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sort\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    933\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m         \u001b[0mping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/sorting.py\u001b[0m in \u001b[0;36mcompress_group_index\u001b[0;34m(group_index, sort)\u001b[0m\n\u001b[1;32m    662\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msort\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs_group_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m         \u001b[0mobs_group_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomp_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_reorder_by_uniques\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs_group_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomp_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mensure_int64\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomp_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_int64\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs_group_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/sorting.py\u001b[0m in \u001b[0;36m_reorder_by_uniques\u001b[0;34m(uniques, labels)\u001b[0m\n\u001b[1;32m    682\u001b[0m     \"\"\"\n\u001b[1;32m    683\u001b[0m     \u001b[0;31m# sorter is index where elements ought to go\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 684\u001b[0;31m     \u001b[0msorter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muniques\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m     \u001b[0;31m# reverse_indexer is where elements came from\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cf_a': 21,\n",
       " 'ctf_a': 20,\n",
       " 'atfd_a': 15,\n",
       " 'atfp_a': 6,\n",
       " 'pa_a': 11,\n",
       " 'cf_w': 4,\n",
       " 'ctf_w': 18,\n",
       " 'atfd_w': 18,\n",
       " 'atfp_w': 14,\n",
       " 'pa_w': 18,\n",
       " 'cf_m': 20,\n",
       " 'ctf_m': 5,\n",
       " 'atfd_m': 5,\n",
       " 'atfp_m': 15,\n",
       " 'pa_m': 18,\n",
       " 'cf_y': 23,\n",
       " 'ctf_y': 9,\n",
       " 'atfd_y': 21,\n",
       " 'atfp_y': 22,\n",
       " 'pa_y': 12}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
